<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Architectural Biases in Deep Learning | ML Fundamentals</title>
    <meta name="description" content="How CNN, RNN, Transformer, and GNN architectures encode inductive biases through weight sharing, equivariance, and structural constraints.">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Playfair+Display:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}, {left: '\\\\[', right: '\\\\]', display: true}, {left: '\\\\(', right: '\\\\)', display: false}], throwOnError: false});"></script>

    <!-- Styles -->
    <link rel="stylesheet" href="../../../css/main.css">
    <link rel="stylesheet" href="../../../css/components.css">
    <link rel="stylesheet" href="../../../css/sidebar.css">

    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>&#x221E;</text></svg>">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar" id="navbar">
        <div class="nav-container">
            <a href="../../../index.html" class="nav-logo">
                <span class="logo-symbol">&#x2207;</span>
                <span class="logo-text">ML Fundamentals</span>
            </a>

            <button class="nav-toggle" id="navToggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>

            <div class="nav-menu" id="navMenu">
                <div class="nav-links">
                    <a href="../../../tutorials/ml/index.html" class="nav-link active">Machine Learning</a>
                    <a href="../../../tutorials/linear-algebra/index.html" class="nav-link">Linear Algebra</a>
                    <a href="../../../tutorials/calculus/index.html" class="nav-link">Calculus</a>
                    <a href="../../../tutorials/physics/index.html" class="nav-link">Physics</a>
                    <a href="../../../index.html#philosophy" class="nav-link">Philosophy</a>
                    <a href="../../../index.html#roadmap" class="nav-link">Roadmap</a>
                    <a href="https://github.com/ml-entropy/ml-entropy.github.io" class="nav-link" target="_blank">GitHub</a>
                </div>

                <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
                    <svg class="sun-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <circle cx="12" cy="12" r="5"/>
                        <path d="M12 1v2M12 21v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M1 12h2M21 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42"/>
                    </svg>
                    <svg class="moon-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                    </svg>
                </button>
            </div>
        </div>
    </nav>

    <!-- Tutorial Header -->
    <header class="tutorial-content-header">
        <div class="container">
            <nav class="breadcrumb">
                <a href="../../../index.html">Home</a>
                <span class="breadcrumb-separator">&rarr;</span>
                <a href="../index.html">Machine Learning</a>
                <span class="breadcrumb-separator">&rarr;</span>
                <span>Architectural Biases</span>
            </nav>

            <div class="tutorial-tabs">
                <a href="#theory" class="tutorial-tab active" onclick="switchTab('theory', this)">Theory</a>
                <a href="#code" class="tutorial-tab" onclick="switchTab('code', this)">Code</a>
                <a href="#exercises" class="tutorial-tab" onclick="switchTab('exercises', this)">Exercises</a>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    <div class="tutorial-wrapper">
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <aside class="tutorial-sidebar">
            <div class="sidebar-section">
                <h3 class="sidebar-section-title">Machine Learning</h3>
                <nav class="sidebar-nav">
                        <a href="../00-probability/index.html" class="sidebar-link">00. Probability Foundations</a>
                    <a href="../01-logarithms/index.html" class="sidebar-link">01. Why Logarithms?</a>
                    <a href="../02-combinatorics/index.html" class="sidebar-link">02. Combinatorics</a>
                    <a href="../03-distributions/index.html" class="sidebar-link">03. Normal Distributions</a>
                    <a href="../04-entropy/index.html" class="sidebar-link">04. Entropy Fundamentals</a>
                    <a href="../05-cross-entropy/index.html" class="sidebar-link">05. Cross-Entropy</a>
                    <a href="../06-kl-divergence/index.html" class="sidebar-link">06. KL Divergence</a>
                    <a href="../07-entropy-connections/index.html" class="sidebar-link">07. Entropy Connections</a>
                    <a href="../08-backpropagation/index.html" class="sidebar-link">08. Backpropagation</a>
                    <a href="../09-regularization/index.html" class="sidebar-link">09. Regularization</a>
                    <a href="../10-batch-normalization/index.html" class="sidebar-link">10. Batch Normalization</a>
                    <a href="../11-learning-rate/index.html" class="sidebar-link">11. Learning Rate</a>
                    <a href="../12-cnn/index.html" class="sidebar-link">12. CNNs</a>
                    <a href="../13-rnn/index.html" class="sidebar-link">13. RNNs</a>
                    <a href="../14-rate-distortion/index.html" class="sidebar-link">14. Rate-Distortion Theory</a>
                    <a href="../15-autoencoder/index.html" class="sidebar-link">15. Autoencoders</a>
                    <a href="../16-variational-inference/index.html" class="sidebar-link">16. Variational Inference</a>
                    <a href="../17-vae/index.html" class="sidebar-link">17. VAE</a>
                    <a href="../18-inductive-bias/index.html" class="sidebar-link">18. Inductive Bias</a>
                    <a href="../19-architectural-biases/index.html" class="sidebar-link active">19. Architectural Biases</a>
                    <a href="../20-designing-biases/index.html" class="sidebar-link">20. Designing Biases</a>
                    <a href="../21-fst-fundamentals/index.html" class="sidebar-link">21. FST Fundamentals</a>
                    <a href="../22-weighted-fsts/index.html" class="sidebar-link">22. Weighted FSTs</a>
                    <a href="../23-fst-libraries/index.html" class="sidebar-link">23. FST Libraries</a>
                    <a href="../24-fst-applications/index.html" class="sidebar-link">24. FST Applications</a>
                    <a href="../25-neural-symbolic/index.html" class="sidebar-link">25. Neural-Symbolic Hybrids</a>
                    <a href="../26-sequence-alignment/index.html" class="sidebar-link">26. Sequence Alignment</a>
                    <a href="../27-mas-algorithm/index.html" class="sidebar-link">27. MAS Algorithm</a>
                    <a href="../28-forced-alignment/index.html" class="sidebar-link">28. Forced Alignment & MFA</a>
                    <a href="../29-tts-fundamentals/index.html" class="sidebar-link">29. TTS Fundamentals</a>
                    <a href="../30-neural-vocoders/index.html" class="sidebar-link">30. Neural Vocoders</a>
                    <a href="../31-tacotron/index.html" class="sidebar-link">31. Tacotron & Attention TTS</a>
                    <a href="../32-fastspeech/index.html" class="sidebar-link">32. FastSpeech & Non-AR TTS</a>
                    <a href="../33-glow-tts/index.html" class="sidebar-link">33. Glow-TTS & Flows</a>
                    <a href="../34-vits/index.html" class="sidebar-link">34. VITS: End-to-End TTS</a>
                    <a href="../35-bilingual-tts/index.html" class="sidebar-link">35. Bilingual TTS: RU+KY</a>
                </nav>
            </div>
            
            <div class="sidebar-section" style="margin-top: 2rem;">
                <h3 class="sidebar-section-title">Related Subjects</h3>
                <nav class="sidebar-nav">
                        <a href="../../linear-algebra/index.html" class="sidebar-link">Linear Algebra</a>
                    <a href="../../calculus/index.html" class="sidebar-link">Calculus</a>
                    <a href="../../physics/index.html" class="sidebar-link">Physics</a>
                </nav>
            </div>
        </aside>

        <!-- Main Article -->
        <main class="tutorial-main">

            <!-- ==================== THEORY TAB ==================== -->
            <article class="article-content" id="theory">

                <!-- Section 1 -->
                <h2 id="architecture-matters">Why Architecture Matters</h2>

                <p>
                    In deep learning, the architecture IS the inductive bias. Choosing an architecture means choosing which functions are easy to learn and which are nearly impossible. The difference between a CNN and an MLP on image data is not just a matter of convenience or efficiency &mdash; it is the difference between a model that learns from thousands of examples and one that requires millions.
                </p>

                <div class="note-box">
                    <div class="box-title">Connection to Tutorial 17 (Inductive Bias)</div>
                    <p style="margin-bottom: 0;">
                        In Tutorial 17, we introduced <em>language bias</em> (restricting the hypothesis space $\mathcal{H}$) and <em>preference bias</em> (favoring certain solutions within $\mathcal{H}$). Architecture is the most powerful form of language bias: by choosing convolutions over fully-connected layers, for example, we eliminate all non-translation-equivariant functions from $\mathcal{H}$. This tutorial shows exactly how each architecture carves out its hypothesis space through symmetry and weight sharing.
                    </p>
                </div>

                <div class="note-box">
                    <div class="box-title">The Key Insight</div>
                    <p style="margin-bottom: 0;">
                        A neural network architecture doesn't just process data &mdash; it makes a structural claim about the world. A CNN claims "local patterns matter and are translation-invariant." An RNN claims "order matters and patterns repeat across time." Choosing the wrong architecture means fighting against the structure of your data.
                    </p>
                </div>

                <p>
                    The architecture of a neural network determines three fundamental properties:
                </p>
                <ol>
                    <li><strong>Which symmetries are preserved:</strong> Does shifting an image change the output? Does reordering a sentence matter?</li>
                    <li><strong>How parameters are shared:</strong> Are the same weights reused across spatial positions, time steps, or graph nodes?</li>
                    <li><strong>What the effective hypothesis space looks like:</strong> Among all possible input-output mappings, which ones can the network represent easily, and which require exponentially more capacity?</li>
                </ol>

                <!-- Section 2 -->
                <h2 id="mlp-baseline">MLPs: The Minimal Bias Baseline</h2>

                <p>
                    The Multi-Layer Perceptron (MLP) makes almost no structural assumptions about its input. Any input dimension can connect to any output dimension with an independent learned weight. There is no notion of locality, no parameter sharing, no built-in symmetry. This makes the MLP maximally flexible &mdash; and maximally data-hungry.
                </p>

                <div class="definition-box">
                    <div class="box-title">Universal Approximation Theorem</div>
                    <p style="margin-bottom: 0;">
                        For any continuous function $f: [0,1]^d \to \mathbb{R}$ and any $\epsilon > 0$, there exists a single-hidden-layer MLP with enough neurons that approximates $f$ to within $\epsilon$:
                        $$\sup_{x \in [0,1]^d} |f(x) - \text{MLP}(x)| < \epsilon$$
                    </p>
                </div>

                <div class="warning-box">
                    <div class="box-title">UAT Says Nothing About Learnability</div>
                    <p style="margin-bottom: 0;">
                        The UAT guarantees existence, not learnability. Finding the right weights via gradient descent may require:
                    </p>
                    <ol>
                        <li>Exponentially many neurons</li>
                        <li>Exponentially many training samples</li>
                        <li>Exponentially long training time</li>
                    </ol>
                    <p style="margin-bottom: 0;">
                        Without structural bias, MLPs need data proportional to the complexity of the function, not the underlying structure.
                    </p>
                </div>

                <p>
                    This is why specialized architectures exist &mdash; they encode structural knowledge that reduces the sample complexity from exponential to manageable.
                </p>

                <!-- Section 3 -->
                <h2 id="cnn-equivariance">CNNs: Translation Equivariance</h2>

                <p>
                    Convolutional Neural Networks encode three key inductive biases about spatial data: <strong>locality</strong> (each neuron connects only to a small spatial region), <strong>weight sharing</strong> (the same filter is applied at every spatial position), and <strong>translation equivariance</strong> (shifting the input shifts the output correspondingly). These biases make CNNs extraordinarily efficient for image and spatial data.
                </p>

                <div class="definition-box">
                    <div class="box-title">Group and Group Action</div>
                    <p>
                        A <strong>group</strong> $(G, \circ)$ is a set $G$ with an operation $\circ$ satisfying four axioms: (1) <em>closure</em> — $g_1 \circ g_2 \in G$, (2) <em>associativity</em> — $(g_1 \circ g_2) \circ g_3 = g_1 \circ (g_2 \circ g_3)$, (3) <em>identity</em> — there exists $e \in G$ such that $e \circ g = g$, and (4) <em>inverses</em> — for every $g$ there exists $g^{-1}$ such that $g \circ g^{-1} = e$.
                    </p>
                    <p style="margin-bottom: 0;">
                        A <strong>group action</strong> $T_g$ describes how a group element $g$ transforms data. For example, the <em>translation group</em> $(\mathbb{Z}, +)$ acts on 1D signals by shifting: $T_t(x)[n] = x[n - t]$. The <em>permutation group</em> $S_n$ acts on sets by reordering elements: $T_\pi(x) = (x_{\pi(1)}, \ldots, x_{\pi(n)})$. These are the symmetry groups that architectures are designed to respect.
                    </p>
                </div>

                <div class="definition-box">
                    <div class="box-title">Equivariance</div>
                    <p style="margin-bottom: 0;">
                        A function $f$ is equivariant to a transformation group $G$ if applying a transformation $g \in G$ to the input produces a correspondingly transformed output:
                        $$f(T_g(x)) = T'_g(f(x))$$
                        For CNNs, the group is translations: shifting the input shifts the output by the same amount.
                    </p>
                </div>

                <div class="math-derivation">
                    <div class="math-derivation-title">Proof: Convolution is Translation Equivariant</div>

                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            Convolution of input $x$ with kernel $w$:
                            $$(w * x)[n] = \sum_k w[k] \cdot x[n-k]$$
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            Apply translation $T_t$ (shift by $t$):
                            $$(w * T_t(x))[n] = \sum_k w[k] \cdot x[n-k-t]$$
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            Substitute $m = n - t$ (so $n - k - t = m - k$):
                            $$\sum_k w[k] \cdot x[n-k-t] = \sum_k w[k] \cdot x[m-k] = (w * x)[m] = (w * x)[n-t]$$
                            But $(w * x)[n-t]$ is exactly $T_t(w * x)[n]$. Therefore $w * T_t(x) = T_t(w * x)$. QED.
                        </div>
                    </div>
                </div>

                <p>
                    <strong>Equivariance vs Invariance.</strong> Equivariance means the output transforms with the input &mdash; this is what convolutional layers provide. Invariance means the output is unchanged by the input transformation &mdash; this is achieved by pooling layers. A CNN achieves approximate translation invariance through the combination of equivariant convolutional layers and invariant pooling operations.
                </p>

                <div class="note-box">
                    <div class="box-title">Connection to Tutorial 12 (CNNs)</div>
                    <p style="margin-bottom: 0;">
                        In Tutorial 12, we studied convolution mechanics. Here we see the deeper reason: weight sharing across spatial positions is not just parameter efficiency &mdash; it mathematically guarantees translation equivariance.
                    </p>
                </div>

                <!-- Section 4 -->
                <h2 id="rnn-sequential">RNNs: Sequential &amp; Temporal Bias</h2>

                <p>
                    Recurrent Neural Networks encode the assumption that data has a sequential order and that patterns repeat across time. The hidden state carries information forward through the sequence, and the same transformation is applied at every time step.
                </p>

                <div class="math-block">
                    $$h_t = f(W_h h_{t-1} + W_x x_t + b)$$
                </div>

                <p>The key biases encoded by this architecture are:</p>
                <ol>
                    <li><strong>Temporal ordering:</strong> Position in sequence matters. The model processes inputs one at a time, left to right.</li>
                    <li><strong>Parameter sharing across time:</strong> The same $W_h, W_x$ are used at every step &mdash; encoding the bias that patterns at position 5 are the same as at position 50.</li>
                    <li><strong>Markov-like locality:</strong> $h_t$ depends directly on $h_{t-1}$ and $x_t$ (though indirect dependencies propagate through the hidden state).</li>
                </ol>

                <div class="note-box">
                    <div class="box-title">Connection to Tutorial 13 (RNNs)</div>
                    <p style="margin-bottom: 0;">
                        The vanishing/exploding gradient problem (Tutorial 13) is a consequence of this bias: the assumption of parameter sharing across time means gradients must flow through many multiplications of the same weight matrix.
                    </p>
                </div>

                <!-- Section 5 -->
                <h2 id="transformers-attention">Transformers: Attention as Soft Selection</h2>

                <p>
                    Transformers replace the sequential bias of RNNs with a fundamentally different one: every position can attend to every other position simultaneously, with learned attention weights determining which connections matter.
                </p>

                <div class="math-block">
                    $$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right) V$$
                </div>

                <p>
                    Here $d_k$ is the dimension of the key vectors (and queries). The scaling factor $\sqrt{d_k}$ prevents the dot products $QK^T$ from growing large in magnitude as $d_k$ increases. Without it, the softmax would saturate — pushing its outputs toward one-hot vectors — which causes vanishingly small gradients. Dividing by $\sqrt{d_k}$ keeps the variance of the dot products at roughly 1, ensuring the softmax stays in a region with meaningful gradients.
                </p>

                <p>
                    <strong>Key property:</strong> Self-attention is permutation equivariant &mdash; without position encodings, the output is unchanged by reordering the input tokens. This means self-attention treats its input as a <em>set</em>, not a sequence.
                </p>

                <div class="math-derivation">
                    <div class="math-derivation-title">Proof: Self-Attention is Permutation Equivariant</div>

                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            Let $P$ be a permutation matrix and let $X' = PX$ be the row-permuted input. The queries, keys, and values become $Q' = PXW_Q = PQ$, $K' = PK$, $V' = PV$.
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            Compute the attention scores: $Q'K'^T = (PQ)(PK)^T = PQ K^T P^T$.
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            Apply softmax row-wise: $\text{softmax}(PQK^TP^T) = P \,\text{softmax}(QK^T) \,P^T$. This works because $P$ permutes rows and $P^T$ permutes columns — softmax is applied per row, and permuting rows then permuting columns back preserves the row-wise operation.
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">4</div>
                        <div class="math-step-content">
                            Multiply by $V' = PV$: $P\,\text{softmax}(QK^T)\,P^T \cdot PV = P\,\text{softmax}(QK^T)\,V$, since $P^TP = I$. This gives $P \cdot \text{Attention}(X) = \text{Attention}(PX)$. QED.
                        </div>
                    </div>
                </div>

                <p>
                    <strong>Position encodings as injected bias.</strong> Since self-attention is permutation-equivariant by design, sequential order must be explicitly injected via position encodings. This is an architectural choice: you add exactly the bias you need, rather than having it baked into the computation graph as in RNNs.
                </p>

                <div class="warning-box">
                    <div class="box-title">Less Built-in Bias = More Data Needed</div>
                    <p style="margin-bottom: 0;">
                        Transformers have fewer built-in biases than CNNs or RNNs. This is why they typically need much more data to train effectively. When data is abundant, the flexibility wins. When data is scarce, the bias of CNNs or RNNs can be more effective.
                    </p>
                </div>

                <!-- Section 6 -->
                <h2 id="gnn-graphs">GNNs: Permutation Equivariance on Graphs</h2>

                <p>
                    Graph Neural Networks encode the bias that data has a graph structure &mdash; entities (nodes) connected by relationships (edges). Unlike grids (images) or sequences (text), graphs have irregular topology that varies from instance to instance.
                </p>

                <div class="math-block">
                    $$h_v^{(l+1)} = \text{UPDATE}\left(h_v^{(l)}, \text{AGGREGATE}\left(\{h_u^{(l)} : u \in \mathcal{N}(v)\}\right)\right)$$
                </div>

                <p>
                    <strong>Key bias: equivariance under node permutation.</strong> Relabeling the nodes of a graph shouldn't change the output. The AGGREGATE function (e.g., sum, mean, max) is permutation-invariant over neighbors, ensuring this property. This means a GNN produces the same result regardless of how the nodes happen to be indexed.
                </p>

                <p>
                    <strong>Why must AGGREGATE be permutation-invariant?</strong> The neighbor set $\mathcal{N}(v)$ has no natural ordering — node 3's neighbors $\{7, 2, 5\}$ could equally be listed as $\{2, 5, 7\}$ or $\{5, 7, 2\}$. If AGGREGATE were sensitive to the order (like concatenation or an RNN), the output would depend on an arbitrary indexing convention, breaking equivariance. Functions like sum, mean, and max produce the same result regardless of input order, making them valid choices. This is why GNN papers always choose symmetric aggregation functions.
                </p>

                <!-- Section 7 -->
                <h2 id="equivariance-framework">Equivariance as a Unifying Framework</h2>

                <p>
                    All major architectures can be understood through the lens of symmetry groups. Each architecture is designed to be equivariant to the symmetry group that is natural for its data domain.
                </p>

                <div class="definition-box">
                    <div class="box-title">The Symmetry Principle</div>
                    <p style="margin-bottom: 0;">
                        Architecture design follows a simple rule: identify the symmetry group of your data, then build equivariance to that group into your network. Symmetry &rarr; weight sharing pattern &rarr; equivariance.
                    </p>
                </div>

                <div style="overflow-x: auto;">
                    <table style="width: 100%; border-collapse: collapse; margin: 2rem 0;">
                        <thead>
                            <tr style="border-bottom: 2px solid var(--color-border);">
                                <th style="padding: 0.75rem; text-align: left;">Architecture</th>
                                <th style="padding: 0.75rem; text-align: left;">Symmetry Group</th>
                                <th style="padding: 0.75rem; text-align: left;">Weight Sharing Pattern</th>
                                <th style="padding: 0.75rem; text-align: left;">Equivariance Property</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr style="border-bottom: 1px solid var(--color-border);">
                                <td style="padding: 0.75rem;">MLP</td>
                                <td style="padding: 0.75rem;">None (trivial)</td>
                                <td style="padding: 0.75rem;">No sharing</td>
                                <td style="padding: 0.75rem;">None (maximally flexible)</td>
                            </tr>
                            <tr style="border-bottom: 1px solid var(--color-border);">
                                <td style="padding: 0.75rem;">CNN</td>
                                <td style="padding: 0.75rem;">Translation group</td>
                                <td style="padding: 0.75rem;">Shared kernels across space</td>
                                <td style="padding: 0.75rem;">Translating input translates feature maps</td>
                            </tr>
                            <tr style="border-bottom: 1px solid var(--color-border);">
                                <td style="padding: 0.75rem;">RNN</td>
                                <td style="padding: 0.75rem;">Time-translation group</td>
                                <td style="padding: 0.75rem;">Shared weights across time steps</td>
                                <td style="padding: 0.75rem;">Same dynamics at every time step</td>
                            </tr>
                            <tr style="border-bottom: 1px solid var(--color-border);">
                                <td style="padding: 0.75rem;">Transformer</td>
                                <td style="padding: 0.75rem;">Permutation group (tokens)</td>
                                <td style="padding: 0.75rem;">Shared attention across positions</td>
                                <td style="padding: 0.75rem;">Permutation equivariant (without positional encoding)</td>
                            </tr>
                            <tr>
                                <td style="padding: 0.75rem;">GNN</td>
                                <td style="padding: 0.75rem;">Node permutation group</td>
                                <td style="padding: 0.75rem;">Shared message functions across edges</td>
                                <td style="padding: 0.75rem;">Node relabeling doesn't change output</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <div class="note-box">
                    <div class="box-title">Group Theory Connection</div>
                    <p style="margin-bottom: 0;">
                        This perspective comes from geometric deep learning (Bronstein et al., 2021). The idea: all successful architectures exploit the symmetries of their data domain. Future architectures will be designed by first identifying the relevant symmetry group.
                    </p>
                </div>

                <!-- Section 8 -->
                <h2 id="summary">Summary</h2>

                <div style="overflow-x: auto;">
                    <table style="width: 100%; border-collapse: collapse; margin: 2rem 0;">
                        <thead>
                            <tr style="border-bottom: 2px solid var(--color-border);">
                                <th style="padding: 0.75rem; text-align: left;">Architecture</th>
                                <th style="padding: 0.75rem; text-align: left;">Key Bias</th>
                                <th style="padding: 0.75rem; text-align: left;">Best For</th>
                                <th style="padding: 0.75rem; text-align: left;">Limitation</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr style="border-bottom: 1px solid var(--color-border);">
                                <td style="padding: 0.75rem;">MLP</td>
                                <td style="padding: 0.75rem;">None (universal)</td>
                                <td style="padding: 0.75rem;">Tabular data, small structured problems</td>
                                <td style="padding: 0.75rem;">Needs exponential data for complex patterns</td>
                            </tr>
                            <tr style="border-bottom: 1px solid var(--color-border);">
                                <td style="padding: 0.75rem;">CNN</td>
                                <td style="padding: 0.75rem;">Translation equivariance, locality</td>
                                <td style="padding: 0.75rem;">Images, spatial data</td>
                                <td style="padding: 0.75rem;">Assumes grid structure and translation symmetry</td>
                            </tr>
                            <tr style="border-bottom: 1px solid var(--color-border);">
                                <td style="padding: 0.75rem;">RNN</td>
                                <td style="padding: 0.75rem;">Sequential processing, temporal weight sharing</td>
                                <td style="padding: 0.75rem;">Time series, sequences</td>
                                <td style="padding: 0.75rem;">Struggles with long-range dependencies</td>
                            </tr>
                            <tr style="border-bottom: 1px solid var(--color-border);">
                                <td style="padding: 0.75rem;">Transformer</td>
                                <td style="padding: 0.75rem;">Permutation equivariance + position encoding</td>
                                <td style="padding: 0.75rem;">Text, any set-structured data</td>
                                <td style="padding: 0.75rem;">Needs lots of data; quadratic attention cost</td>
                            </tr>
                            <tr>
                                <td style="padding: 0.75rem;">GNN</td>
                                <td style="padding: 0.75rem;">Node permutation equivariance</td>
                                <td style="padding: 0.75rem;">Graphs, molecules, social networks</td>
                                <td style="padding: 0.75rem;">Limited expressivity (WL test bound)</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <div class="note-box">
                    <div class="box-title">Looking Ahead: Tutorial 19</div>
                    <p style="margin-bottom: 0;">
                        Now that we've seen how architectures encode biases, the next tutorial asks: how do we choose the right bias for a given problem? We'll explore regularization, data augmentation, transfer learning, and the ongoing debate about whether hand-crafted biases can survive the scaling revolution.
                    </p>
                </div>

                <!-- Navigation -->
                <div class="tutorial-footer-summary" style="margin: 3rem 0; padding: 2rem; background: #f8f9fa; border-radius: 8px; border-left: 4px solid #3b82f6;">
                    <h1>18. Architectural Biases in Deep Learning</h1>
                    <p class="lead">
                        How neural network architectures encode assumptions about data structure through weight sharing, equivariance, and connectivity patterns.
                    </p>
                </div>

                <div class="tutorial-nav">
                    <a href="../18-inductive-bias/index.html" class="tutorial-nav-link prev">
                        <span class="nav-label">Previous</span>
                        <span class="nav-title">&larr; Inductive Bias</span>
                    </a>
                    <a href="../20-designing-biases/index.html" class="tutorial-nav-link next">
                        <span class="nav-label">Next</span>
                        <span class="nav-title">Designing Biases &rarr;</span>
                    </a>
                </div>

            </article>

            <!-- ==================== CODE TAB ==================== -->
            <article class="article-content" id="code" style="display: none;">

                <h2>Code Examples: Architectural Biases</h2>

                <p>
                    These examples demonstrate the key theoretical concepts from the theory tab using pure NumPy.
                    Run them to build intuition about equivariance, weight sharing, and the differences between architectures.
                </p>

                <!-- Code Example 1 -->
                <h3>1. Equivariance Test: CNN Translation Equivariance</h3>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-lang">Python</span>
                        <button class="code-block-copy" onclick="navigator.clipboard.writeText(this.closest('.code-block').querySelector('code').textContent)">Copy</button>
                    </div>
<pre><code class="language-python">import numpy as np

def conv2d(image, kernel):
    """Simple 2D convolution (no padding)."""
    h, w = image.shape
    kh, kw = kernel.shape
    out_h, out_w = h - kh + 1, w - kw + 1
    output = np.zeros((out_h, out_w))
    for i in range(out_h):
        for j in range(out_w):
            output[i, j] = np.sum(image[i:i+kh, j:j+kw] * kernel)
    return output

def translate(image, dx, dy):
    """Translate image by (dx, dy) pixels with zero padding."""
    h, w = image.shape
    result = np.zeros_like(image)
    for i in range(h):
        for j in range(w):
            ni, nj = i - dy, j - dx
            if 0 &lt;= ni &lt; h and 0 &lt;= nj &lt; w:
                result[i, j] = image[ni, nj]
    return result

# Create a simple test image with a pattern
np.random.seed(42)
image = np.zeros((10, 10))
image[2:5, 3:6] = np.random.rand(3, 3)  # Small pattern

# Edge-detection kernel
kernel = np.array([[-1, 0, 1],
                   [-2, 0, 2],
                   [-1, 0, 1]], dtype=float)

# Test equivariance: conv(translate(x)) vs translate(conv(x))
dx, dy = 2, 1

# Method 1: First translate, then convolve
translated_image = translate(image, dx, dy)
result1 = conv2d(translated_image, kernel)

# Method 2: First convolve, then translate
convolved_image = conv2d(image, kernel)
result2_full = translate(convolved_image, dx, dy)
# Crop to match dimensions
result2 = result2_full[:result1.shape[0], :result1.shape[1]]

# Compare
diff = np.abs(result1 - result2)
print("CNN Translation Equivariance Test")
print("=" * 40)
print(f"Max difference: {diff.max():.10f}")
print(f"Mean difference: {diff.mean():.10f}")
print(f"Equivariant? {diff.max() &lt; 1e-10}")
print("\nConvolution commutes with translation!")</code></pre>
                </div>

                <!-- Code Example 2 -->
                <h3>2. Parameter Counting: MLP vs CNN</h3>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-lang">Python</span>
                        <button class="code-block-copy" onclick="navigator.clipboard.writeText(this.closest('.code-block').querySelector('code').textContent)">Copy</button>
                    </div>
<pre><code class="language-python">def count_mlp_params(input_size, hidden_sizes, output_size):
    """Count parameters in a fully-connected MLP."""
    sizes = [input_size] + hidden_sizes + [output_size]
    total = 0
    for i in range(len(sizes) - 1):
        weights = sizes[i] * sizes[i+1]
        biases = sizes[i+1]
        total += weights + biases
    return total

def count_cnn_params(input_channels, conv_specs, fc_sizes, final_spatial):
    """
    Count parameters in a CNN.
    conv_specs: list of (out_channels, kernel_size)
    fc_sizes: list of fully-connected layer sizes
    final_spatial: spatial size before FC layers
    """
    total = 0
    in_ch = input_channels
    for out_ch, k in conv_specs:
        weights = in_ch * out_ch * k * k
        biases = out_ch
        total += weights + biases
        in_ch = out_ch

    # FC layers
    fc_input = in_ch * final_spatial * final_spatial
    sizes = [fc_input] + fc_sizes
    for i in range(len(sizes) - 1):
        total += sizes[i] * sizes[i+1] + sizes[i+1]
    return total

# Task: classify 32x32 grayscale images into 10 classes
img_size = 32
input_dim = img_size * img_size  # 1024
n_classes = 10

# MLP: 1024 -&gt; 512 -&gt; 256 -&gt; 10
mlp_params = count_mlp_params(input_dim, [512, 256], n_classes)

# CNN: Conv(1-&gt;16, 3x3) -&gt; Conv(16-&gt;32, 3x3) -&gt; FC(32*8*8 -&gt; 128 -&gt; 10)
# (assuming 2x2 pooling after each conv: 32-&gt;30-&gt;15-&gt;13-&gt;6 approx 8x8)
cnn_params = count_cnn_params(1, [(16, 3), (32, 3)], [128, n_classes], 8)

print("Parameter Comparison: MLP vs CNN")
print("=" * 45)
print(f"Task: 32x32 grayscale image -&gt; 10 classes")
print(f"\nMLP (1024-512-256-10):")
print(f"  Parameters: {mlp_params:,}")
print(f"\nCNN (Conv16-Conv32-FC128-FC10):")
print(f"  Parameters: {cnn_params:,}")
print(f"\nRatio: MLP has {mlp_params/cnn_params:.1f}x more parameters")
print(f"\nWeight sharing in CNNs dramatically reduces parameters")
print(f"while encoding translation equivariance as inductive bias.")

# For larger images, the gap grows
for size in [32, 64, 128, 224]:
    mlp_p = count_mlp_params(size*size, [512, 256], 10)
    cnn_p = count_cnn_params(1, [(16, 3), (32, 3)], [128, 10], max(size//4, 4))
    print(f"\n{size}x{size}: MLP={mlp_p:&gt;12,}  CNN={cnn_p:&gt;10,}  Ratio={mlp_p/cnn_p:.0f}x")</code></pre>
                </div>

                <!-- Code Example 3 -->
                <h3>3. Attention Has No Locality Bias</h3>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-lang">Python</span>
                        <button class="code-block-copy" onclick="navigator.clipboard.writeText(this.closest('.code-block').querySelector('code').textContent)">Copy</button>
                    </div>
<pre><code class="language-python">import numpy as np

def softmax(x, axis=-1):
    e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))
    return e_x / e_x.sum(axis=axis, keepdims=True)

def self_attention(X, W_q, W_k, W_v):
    """Single-head self-attention."""
    Q = X @ W_q
    K = X @ W_k
    V = X @ W_v
    d_k = K.shape[-1]
    scores = Q @ K.T / np.sqrt(d_k)
    weights = softmax(scores)
    return weights @ V, weights

# Create a sequence of 8 tokens with d=4
np.random.seed(42)
seq_len, d_model, d_k = 8, 4, 4
X = np.random.randn(seq_len, d_model)

# Random projection matrices
W_q = np.random.randn(d_model, d_k) * 0.5
W_k = np.random.randn(d_model, d_k) * 0.5
W_v = np.random.randn(d_model, d_k) * 0.5

output, attn_weights = self_attention(X, W_q, W_k, W_v)

print("Self-Attention: No Locality Bias")
print("=" * 50)
print(f"\nAttention weights for token 0 (attending to all 8 tokens):")
print(f"  {attn_weights[0].round(3)}")
print(f"\n  Nearest tokens (1,2): weight = {attn_weights[0, 1:3].sum():.3f}")
print(f"  Farthest tokens (6,7): weight = {attn_weights[0, 6:8].sum():.3f}")

# Compare: distance-weighted attention (what a local bias would look like)
print(f"\n--- If attention had locality bias ---")
distances = np.abs(np.arange(seq_len) - 0)
local_weights = softmax(-distances.astype(float))
print(f"  Local weights: {local_weights.round(3)}")
print(f"  Nearest tokens: {local_weights[1:3].sum():.3f}")
print(f"  Farthest tokens: {local_weights[6:8].sum():.3f}")

print(f"\nKey insight: Self-attention can attend to ANY position equally.")
print(f"This is why Transformers need position encodings to know order.")

# Verify permutation equivariance
perm = np.random.permutation(seq_len)
X_perm = X[perm]
output_perm, _ = self_attention(X_perm, W_q, W_k, W_v)
output_then_perm = output[perm]

print(f"\n--- Permutation Equivariance Test ---")
print(f"Max diff |Attn(permute(X)) - permute(Attn(X))|: {np.abs(output_perm - output_then_perm).max():.10f}")
print(f"Self-attention IS permutation equivariant.")</code></pre>
                </div>

                <!-- Code Example 4 -->
                <h3>4. Weight Sharing Ablation: CNN vs Locally-Connected</h3>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-lang">Python</span>
                        <button class="code-block-copy" onclick="navigator.clipboard.writeText(this.closest('.code-block').querySelector('code').textContent)">Copy</button>
                    </div>
<pre><code class="language-python">import numpy as np

class SimpleConvLayer:
    """Conv layer: SAME kernel everywhere (weight sharing)."""
    def __init__(self, kernel_size, in_size):
        self.kernel = np.random.randn(kernel_size) * 0.5
        self.n_params = kernel_size

    def forward(self, x):
        k = len(self.kernel)
        pad = k // 2
        x_padded = np.pad(x, pad, mode='constant')
        out = np.zeros_like(x)
        for i in range(len(x)):
            out[i] = np.sum(x_padded[i:i+k] * self.kernel)
        return out

class LocallyConnectedLayer:
    """Locally-connected: DIFFERENT kernel at each position (no sharing)."""
    def __init__(self, kernel_size, in_size):
        self.kernels = np.random.randn(in_size, kernel_size) * 0.5
        self.n_params = in_size * kernel_size

    def forward(self, x):
        k = self.kernels.shape[1]
        pad = k // 2
        x_padded = np.pad(x, pad, mode='constant')
        out = np.zeros_like(x)
        for i in range(len(x)):
            out[i] = np.sum(x_padded[i:i+k] * self.kernels[i])
        return out

# Compare on a translation-detection task
input_size = 20
kernel_size = 5

conv = SimpleConvLayer(kernel_size, input_size)
local = LocallyConnectedLayer(kernel_size, input_size)

print("Weight Sharing: CNN vs Locally-Connected Network")
print("=" * 50)
print(f"\nInput size: {input_size}")
print(f"Kernel size: {kernel_size}")
print(f"Conv layer parameters: {conv.n_params}")
print(f"Locally-connected parameters: {local.n_params}")
print(f"Ratio: {local.n_params / conv.n_params:.0f}x more parameters without sharing")

# Create a pattern that appears at different positions
pattern = np.array([1.0, 2.0, 1.0, 0.5, 0.0])
results_conv = []
results_local = []

for pos in range(0, input_size - len(pattern) + 1, 3):
    x = np.zeros(input_size)
    x[pos:pos+len(pattern)] = pattern
    out_c = conv.forward(x)
    out_l = local.forward(x)
    results_conv.append(out_c)
    results_local.append(out_l)

# Check consistency across positions
print(f"\n--- Response to same pattern at different positions ---")
print(f"Conv (shared weights): outputs are shifted versions of each other")
conv_profile = results_conv[0][np.nonzero(results_conv[0])]
for i, r in enumerate(results_conv):
    profile = r[np.nonzero(r)]
    if len(profile) == len(conv_profile):
        match = np.allclose(profile, conv_profile, atol=1e-10)
    else:
        match = False
    print(f"  Position {i*3}: profile match = {match}")

print(f"\nLocally-connected (no sharing): different response at each position")
local_profile = results_local[0][np.nonzero(results_local[0])]
for i, r in enumerate(results_local):
    profile = r[np.nonzero(r)]
    if len(profile) == len(local_profile):
        match = np.allclose(profile, local_profile, atol=1e-10)
    else:
        match = False
    print(f"  Position {i*3}: profile match = {match}")

print(f"\nKey insight: Weight sharing in CNNs guarantees the same feature")
print(f"is detected regardless of where it appears in the input.")</code></pre>
                </div>

            </article>

            <!-- ==================== EXERCISES TAB ==================== -->
            <article class="article-content" id="exercises" style="display: none;">

                <h2>Exercises: Architectural Biases</h2>

                <div class="exercise-list">

                    <!-- Easy Exercises -->
                    <h3 style="border-bottom: 2px solid var(--color-border); padding-bottom: 0.5rem; margin-top: 2rem;">Easy</h3>

                    <!-- Exercise 1 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">1. Equivariance vs Invariance</span>
                            <span class="exercise-toggle">+</span>
                        </div>
                        <div class="exercise-body">
                            <p>
                                Define equivariance and invariance. Give an example of each in everyday life (not ML).
                            </p>
                            <button class="solution-toggle" onclick="this.nextElementSibling.style.display = this.nextElementSibling.style.display === 'block' ? 'none' : 'block'; this.textContent = this.nextElementSibling.style.display === 'block' ? 'Hide Solution' : 'Show Solution';">Show Solution</button>
                            <div class="solution-content" style="display: none;">
                                <p>
                                    <strong>Equivariance:</strong> The output transforms consistently with the input. If you apply a transformation to the input, the output transforms in a corresponding (predictable) way.
                                </p>
                                <p>
                                    <em>Example:</em> Moving a shadow puppet moves its shadow by the same amount. The shadow (output) shifts in correspondence with the puppet (input).
                                </p>
                                <p>
                                    <strong>Invariance:</strong> The output is unchanged by the input transformation. No matter how you transform the input, the output remains the same.
                                </p>
                                <p>
                                    <em>Example:</em> The weight of a suitcase doesn't change if you rotate it. The measurement (output) is invariant to rotation (transformation).
                                </p>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 2 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">2. Three Biases of CNNs</span>
                            <span class="exercise-toggle">+</span>
                        </div>
                        <div class="exercise-body">
                            <p>
                                List and explain the three main inductive biases of CNNs.
                            </p>
                            <button class="solution-toggle" onclick="this.nextElementSibling.style.display = this.nextElementSibling.style.display === 'block' ? 'none' : 'block'; this.textContent = this.nextElementSibling.style.display === 'block' ? 'Hide Solution' : 'Show Solution';">Show Solution</button>
                            <div class="solution-content" style="display: none;">
                                <ol>
                                    <li><strong>Locality:</strong> Each neuron connects only to a small spatial region (receptive field), assuming nearby pixels are more related than distant ones.</li>
                                    <li><strong>Weight sharing (translation equivariance):</strong> The same filter is applied everywhere across the input, assuming that patterns can appear at any position and should be detected identically.</li>
                                    <li><strong>Hierarchical composition:</strong> Deeper layers combine features from earlier layers, assuming that complex features are compositions of simpler ones (edges &rarr; textures &rarr; parts &rarr; objects).</li>
                                </ol>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 3 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">3. Count Conv Parameters</span>
                            <span class="exercise-toggle">+</span>
                        </div>
                        <div class="exercise-body">
                            <p>
                                A convolutional layer has 32 input channels, 64 output channels, and 3&times;3 kernels. How many parameters does it have (including biases)? How many would a fully-connected layer with the same input/output dimensions need for a 32&times;32 feature map?
                            </p>
                            <button class="solution-toggle" onclick="this.nextElementSibling.style.display = this.nextElementSibling.style.display === 'block' ? 'none' : 'block'; this.textContent = this.nextElementSibling.style.display === 'block' ? 'Hide Solution' : 'Show Solution';">Show Solution</button>
                            <div class="solution-content" style="display: none;">
                                <p><strong>Convolutional layer:</strong></p>
                                <p>$32 \times 64 \times 3 \times 3 + 64 = 18{,}496$ parameters.</p>
                                <p><strong>Fully-connected layer:</strong></p>
                                <p>Input dimension = $32 \times 32 \times 32 = 32{,}768$.</p>
                                <p>Output dimension = $64 \times 32 \times 32 = 65{,}536$.</p>
                                <p>FC params = $32{,}768 \times 65{,}536 + 65{,}536 \approx 2.15 \times 10^9$.</p>
                                <p>Ratio: $\sim 116{,}000\times$ more parameters for the fully-connected layer.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Medium Exercises -->
                    <h3 style="border-bottom: 2px solid var(--color-border); padding-bottom: 0.5rem; margin-top: 2rem;">Medium</h3>

                    <!-- Exercise 4 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">4. Prove Translation Equivariance</span>
                            <span class="exercise-toggle">+</span>
                        </div>
                        <div class="exercise-body">
                            <p>
                                Formally prove that 1D convolution is equivariant to translation. That is, show that if $T_t$ denotes a shift by $t$, then $(w * T_t(x))[n] = T_t(w * x)[n]$.
                            </p>
                            <button class="solution-toggle" onclick="this.nextElementSibling.style.display = this.nextElementSibling.style.display === 'block' ? 'none' : 'block'; this.textContent = this.nextElementSibling.style.display === 'block' ? 'Hide Solution' : 'Show Solution';">Show Solution</button>
                            <div class="solution-content" style="display: none;">
                                <p>Let $(T_t x)[n] = x[n-t]$. Then:</p>
                                <div class="math-block">
                                    $$(w * T_t x)[n] = \sum_k w[k](T_t x)[n-k] = \sum_k w[k] \cdot x[n-k-t]$$
                                </div>
                                <p>But:</p>
                                <div class="math-block">
                                    $$(w*x)[n-t] = \sum_k w[k] \cdot x[(n-t)-k] = \sum_k w[k] \cdot x[n-k-t]$$
                                </div>
                                <p>These are identical, so $w * T_t x = T_t(w * x)$. QED.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 5 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">5. Transformer vs CNN Data Requirements</span>
                            <span class="exercise-toggle">+</span>
                        </div>
                        <div class="exercise-body">
                            <p>
                                Explain why transformers typically need more training data than CNNs for image tasks. Relate your answer to inductive bias.
                            </p>
                            <button class="solution-toggle" onclick="this.nextElementSibling.style.display = this.nextElementSibling.style.display === 'block' ? 'none' : 'block'; this.textContent = this.nextElementSibling.style.display === 'block' ? 'Hide Solution' : 'Show Solution';">Show Solution</button>
                            <div class="solution-content" style="display: none;">
                                <p>
                                    CNNs have strong built-in biases: locality, translation equivariance, and hierarchical feature composition. These dramatically reduce the effective hypothesis space, meaning fewer training examples are needed to find a good solution.
                                </p>
                                <p>
                                    Transformers (e.g., ViT) treat image patches as tokens with no spatial bias &mdash; they must learn locality, translation invariance, and hierarchical structure entirely from data. Without these built-in priors, the model must explore a vastly larger hypothesis space.
                                </p>
                                <p>
                                    With enough data (e.g., JFT-300M), transformers can learn these patterns and more, often surpassing CNNs. With limited data, CNNs win because their biases match image structure, giving them a strong head start.
                                </p>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 6 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">6. When RNNs Fail</span>
                            <span class="exercise-toggle">+</span>
                        </div>
                        <div class="exercise-body">
                            <p>
                                Give two examples of tasks where the sequential bias of RNNs is a poor match. Explain why.
                            </p>
                            <button class="solution-toggle" onclick="this.nextElementSibling.style.display = this.nextElementSibling.style.display === 'block' ? 'none' : 'block'; this.textContent = this.nextElementSibling.style.display === 'block' ? 'Hide Solution' : 'Show Solution';">Show Solution</button>
                            <div class="solution-content" style="display: none;">
                                <p><strong>(1) Tabular data</strong> (e.g., predicting house prices from features): Features have no inherent ordering, so the sequential processing of RNNs adds noise. Permuting the feature order shouldn't change the output, but an RNN would produce different results depending on the order features are fed in.</p>
                                <p><strong>(2) Long documents with distant dependencies:</strong> RNNs process sequentially, so information from token 1 must survive through all intermediate hidden states to influence token 1000. The vanishing gradient problem makes this extremely difficult &mdash; by the time the signal reaches the end, it has decayed exponentially.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 7 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">7. GNN Permutation Equivariance</span>
                            <span class="exercise-toggle">+</span>
                        </div>
                        <div class="exercise-body">
                            <p>
                                Consider a graph with 3 nodes and adjacency matrix $A = \begin{pmatrix} 0 & 1 & 0 \\ 1 & 0 & 1 \\ 0 & 1 & 0 \end{pmatrix}$. Node features: $h_1 = [1, 0]$, $h_2 = [0, 1]$, $h_3 = [1, 1]$. Compute one step of message passing with AGGREGATE = mean and UPDATE = identity + aggregated. Then permute nodes 1 and 3 and verify you get the corresponding permuted output.
                            </p>
                            <button class="solution-toggle" onclick="this.nextElementSibling.style.display = this.nextElementSibling.style.display === 'block' ? 'none' : 'block'; this.textContent = this.nextElementSibling.style.display === 'block' ? 'Hide Solution' : 'Show Solution';">Show Solution</button>
                            <div class="solution-content" style="display: none;">
                                <p><strong>Original graph:</strong></p>
                                <p>For node 1: neighbors = {2}. Aggregate = $h_2 = [0,1]$. Update: $h_1' = h_1 + [0,1] = [1,1]$.</p>
                                <p>For node 2: neighbors = {1,3}. Aggregate = $\text{mean}(h_1, h_3) = [1, 0.5]$. Update: $h_2' = [0,1] + [1,0.5] = [1,1.5]$.</p>
                                <p>For node 3: neighbors = {2}. Aggregate = $h_2 = [0,1]$. Update: $h_3' = [1,1] + [0,1] = [1,2]$.</p>
                                <p><strong>Now permute nodes 1 and 3:</strong></p>
                                <p>New features: $h_1=[1,1]$, $h_2=[0,1]$, $h_3=[1,0]$. The adjacency matrix is symmetric under this swap, so it remains the same.</p>
                                <p>Node 1': neighbors={2}, agg=$h_2=[0,1]$, update=$[1,1]+[0,1]=[1,2]$.</p>
                                <p>Node 2': neighbors={1,3}, agg=$\text{mean}([1,1],[1,0])=[1,0.5]$, update=$[0,1]+[1,0.5]=[1,1.5]$.</p>
                                <p>Node 3': neighbors={2}, agg=$[0,1]$, update=$[1,0]+[0,1]=[1,1]$.</p>
                                <p><strong>Verification:</strong> Original output: $[1,1], [1,1.5], [1,2]$. Permuted output: $[1,2], [1,1.5], [1,1]$. This is exactly the permutation (swap of positions 1 and 3) of the original output. Permutation equivariance confirmed.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Hard Exercises -->
                    <h3 style="border-bottom: 2px solid var(--color-border); padding-bottom: 0.5rem; margin-top: 2rem;">Hard</h3>

                    <!-- Exercise 8 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">8. Identify Symmetry Groups</span>
                            <span class="exercise-toggle">+</span>
                        </div>
                        <div class="exercise-body">
                            <p>
                                For each data type, identify the relevant symmetry group and suggest an appropriate architecture:
                            </p>
                            <ol style="list-style-type: lower-alpha;">
                                <li>Audio waveforms</li>
                                <li>3D point clouds</li>
                                <li>Molecular structures</li>
                                <li>Spherical images (e.g., Earth observation)</li>
                                <li>Time series with known periodicity</li>
                            </ol>
                            <button class="solution-toggle" onclick="this.nextElementSibling.style.display = this.nextElementSibling.style.display === 'block' ? 'none' : 'block'; this.textContent = this.nextElementSibling.style.display === 'block' ? 'Hide Solution' : 'Show Solution';">Show Solution</button>
                            <div class="solution-content" style="display: none;">
                                <ol style="list-style-type: lower-alpha;">
                                    <li><strong>Audio waveforms:</strong> Time-translation symmetry &rarr; 1D CNN or WaveNet. Patterns (phonemes, chords) can appear at any time.</li>
                                    <li><strong>3D point clouds:</strong> Rotation + translation + permutation of points &rarr; PointNet (permutation invariant) or SE(3)-equivariant networks. The labeling of points is arbitrary, and the object looks the same from any orientation.</li>
                                    <li><strong>Molecular structures:</strong> Atom permutation + 3D rotation &rarr; E(3)-equivariant GNNs (e.g., SchNet, DimeNet). Physical properties don't depend on how we label atoms or orient the molecule.</li>
                                    <li><strong>Spherical images:</strong> SO(3) rotation &rarr; Spherical CNNs with spherical harmonics. Standard planar convolutions distort on the sphere.</li>
                                    <li><strong>Time series with known periodicity:</strong> Time-translation + discrete rotation (period $T$) &rarr; 1D CNN with circular padding of length $T$. The periodic structure should be explicitly encoded.</li>
                                </ol>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 9 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">9. Design a Rotation-Equivariant Layer</span>
                            <span class="exercise-toggle">+</span>
                        </div>
                        <div class="exercise-body">
                            <p>
                                Design a convolutional layer that is equivariant to 90-degree rotations (the $C_4$ group) in addition to translations. Describe:
                            </p>
                            <ol style="list-style-type: lower-alpha;">
                                <li>How to modify the standard conv layer</li>
                                <li>How many filter orientations are needed</li>
                                <li>The parameter savings compared to learning rotation invariance from data</li>
                            </ol>
                            <button class="solution-toggle" onclick="this.nextElementSibling.style.display = this.nextElementSibling.style.display === 'block' ? 'none' : 'block'; this.textContent = this.nextElementSibling.style.display === 'block' ? 'Hide Solution' : 'Show Solution';">Show Solution</button>
                            <div class="solution-content" style="display: none;">
                                <p><strong>(a)</strong> For each filter $w$, create rotated copies: $w, R_{90}w, R_{180}w, R_{270}w$. Apply all 4 to the input, stacking outputs. The convolution becomes:</p>
                                <div class="math-block">
                                    $$f_k(x) = w_k * x \quad \text{for } k \in \{0, 90, 180, 270\}$$
                                </div>
                                <p>where $w_k = R_k(w)$. Only $w$ is a learnable parameter; the rotated versions are computed deterministically.</p>
                                <p><strong>(b)</strong> 4 orientations for the $C_4$ group ($0°, 90°, 180°, 270°$).</p>
                                <p><strong>(c)</strong> A standard CNN, to learn rotation invariance, needs approximately $4\times$ more filters (one per orientation) with independent parameters. A $C_4$-equivariant layer shares parameters across rotations, so it uses $4\times$ fewer learnable parameters while providing guaranteed equivariance rather than approximate invariance learned from data. This is the principle behind Group Equivariant CNNs (Cohen &amp; Welling, 2016).</p>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 10 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">10. Critique the Universal Approximation Theorem</span>
                            <span class="exercise-toggle">+</span>
                        </div>
                        <div class="exercise-body">
                            <p>
                                The UAT says MLPs can approximate any continuous function. Critically evaluate this theorem from the perspective of inductive bias. Address:
                            </p>
                            <ol style="list-style-type: lower-alpha;">
                                <li>What it guarantees</li>
                                <li>What it doesn't guarantee</li>
                                <li>Why it doesn't make specialized architectures unnecessary</li>
                            </ol>
                            <button class="solution-toggle" onclick="this.nextElementSibling.style.display = this.nextElementSibling.style.display === 'block' ? 'none' : 'block'; this.textContent = this.nextElementSibling.style.display === 'block' ? 'Hide Solution' : 'Show Solution';">Show Solution</button>
                            <div class="solution-content" style="display: none;">
                                <p><strong>(a) What it guarantees:</strong> Existence. For any target function and error tolerance, a wide enough single-hidden-layer MLP exists that achieves the approximation. This is a statement about the expressiveness of the hypothesis space &mdash; the set of functions an MLP <em>can</em> represent is dense in the space of continuous functions.</p>
                                <p><strong>(b) What it doesn't guarantee:</strong></p>
                                <ul>
                                    <li><strong>Learnability:</strong> That gradient descent can find the right weights</li>
                                    <li><strong>Sample efficiency:</strong> How much training data is needed</li>
                                    <li><strong>Computational efficiency:</strong> How long training takes</li>
                                    <li><strong>Generalization:</strong> Performance on unseen data</li>
                                </ul>
                                <p><strong>(c) Why specialized architectures are still necessary:</strong></p>
                                <p>The UAT treats the hypothesis space (language bias) as the only concern. But preference bias matters equally &mdash; among all functions an MLP <em>can</em> represent, which ones does gradient descent actually find? Without structure, the MLP's "flat" parameter space means gradient descent has no guidance toward the correct solution.</p>
                                <p>CNNs, RNNs, Transformers, and GNNs shape both the hypothesis space AND the loss landscape to make the right functions easy to find. They constrain the search space and create optimization surfaces where gradient descent naturally flows toward good solutions.</p>
                                <p><strong>Analogy:</strong> Saying "a library contains every possible book" doesn't mean you can find the one you need without a catalog system. The UAT says the library is complete; architecture design builds the catalog.</p>
                            </div>
                        </div>
                    </div>

                </div>

            </article>

        </main>

        <!-- TOC (Right Side) -->
        <aside class="toc-container">
            <h4 class="toc-title">Contents</h4>
            <nav class="toc-list">
                <a href="#architecture-matters" class="toc-link">Why Architecture Matters</a>
                <a href="#mlp-baseline" class="toc-link">MLPs: Minimal Bias</a>
                <a href="#cnn-equivariance" class="toc-link">CNNs: Equivariance</a>
                <a href="#rnn-sequential" class="toc-link">RNNs: Sequential Bias</a>
                <a href="#transformers-attention" class="toc-link">Transformers: Attention</a>
                <a href="#gnn-graphs" class="toc-link">GNNs: Graph Bias</a>
                <a href="#equivariance-framework" class="toc-link">Unifying Framework</a>
                <a href="#summary" class="toc-link">Summary</a>
            </nav>
        </aside>
    </div>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-brand">
                    <span class="logo-symbol">&#x2207;</span>
                    <span>ML Fundamentals</span>
                </div>
                <p class="footer-tagline">Deep understanding through first principles.</p>
            </div>
            <div class="footer-links">
                <a href="../../../index.html">Home</a>
                <a href="https://github.com/ml-entropy/ml-entropy.github.io" target="_blank">GitHub</a>
            </div>
        </div>
    </footer>

    <!-- Scripts -->
    <script src="../../../js/main.js"></script>
    <script>
        // Tab switching function
        function switchTab(tabId, clickedTab) {
            // Hide all articles
            document.querySelectorAll('.article-content').forEach(function(article) {
                article.style.display = 'none';
            });

            // Show selected article
            var target = document.getElementById(tabId);
            if (target) {
                target.style.display = 'block';
            }

            // Update tab active states
            document.querySelectorAll('.tutorial-tab').forEach(function(tab) {
                tab.classList.remove('active');
            });
            if (clickedTab) {
                clickedTab.classList.add('active');
            }

            // Re-render math in the newly visible tab
            if (typeof renderMathInElement === 'function') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        }

        // Render math on initial load
        document.addEventListener("DOMContentLoaded", function() {
            if (typeof renderMathInElement === 'function') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
    </script>
</body>
</html>
