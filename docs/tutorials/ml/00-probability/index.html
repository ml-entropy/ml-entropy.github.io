<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Probability Concepts for ML | ML Fundamentals</title>
    <meta name="description" content="Essential probability theory for machine learning. Master Bayes' theorem, conditional probability, and probabilistic thinking.">
    
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Playfair+Display:wght@400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}, {left: '\\\\[', right: '\\\\]', display: true}, {left: '\\\\(', right: '\\\\)', display: false}], throwOnError: false});"></script>
    
    <!-- Styles -->
    <link rel="stylesheet" href="../../../css/main.css">
    <link rel="stylesheet" href="../../../css/components.css">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>∞</text></svg>">
<link rel="stylesheet" href="../../../css/sidebar.css">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar" id="navbar">
        <div class="nav-container">
            <a href="../../../index.html" class="nav-logo">
                <span class="logo-symbol">∇</span>
                <span class="logo-text">ML Fundamentals</span>
            </a>
            
            <button class="nav-toggle" id="navToggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            
            <div class="nav-menu" id="navMenu">
                <div class="nav-links">
                    <a href="../../../tutorials/ml/index.html" class="nav-link active">Machine Learning</a>
                    <a href="../../../tutorials/linear-algebra/index.html" class="nav-link">Linear Algebra</a>
                    <a href="../../../tutorials/calculus/index.html" class="nav-link">Calculus</a>
                    <a href="../../../tutorials/physics/index.html" class="nav-link">Physics</a>
                    <a href="../../../index.html#philosophy" class="nav-link">Philosophy</a>
                    <a href="../../../index.html#roadmap" class="nav-link">Roadmap</a>
                    <a href="https://github.com/ml-entropy/ml-entropy.github.io" class="nav-link" target="_blank">GitHub</a>
                </div>
                
                <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
                    <svg class="sun-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <circle cx="12" cy="12" r="5"/>
                        <path d="M12 1v2M12 21v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M1 12h2M21 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42"/>
                    </svg>
                    <svg class="moon-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                    </svg>
                </button>
            </div>
        </div>
    </nav>

    <!-- Tutorial Header -->
    <header class="tutorial-content-header">
        <div class="container">
            <nav class="breadcrumb">
                <a href="../../../index.html">Home</a>
                <span class="breadcrumb-separator">→</span>
                <a href="../index.html">Machine Learning</a>
                <span class="breadcrumb-separator">→</span>
                <span>Probability Concepts</span>
            </nav>
            
            
            
            
            <div class="tutorial-tabs">
                <a href="#theory" class="tutorial-tab active">Theory</a>
                <a href="#code" class="tutorial-tab">Code</a>
                <a href="exercises.html" class="tutorial-tab">Exercises</a>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    
    <!-- Main Content -->
    <div class="tutorial-wrapper">
        
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <aside class="tutorial-sidebar">
            <div class="sidebar-section">
                <h3 class="sidebar-section-title">Machine Learning</h3>
                <nav class="sidebar-nav">
                        <a href="../00-probability/index.html" class="sidebar-link active">00. Probability Foundations</a>
                    <a href="../04-logarithms/index.html" class="sidebar-link">01. Why Logarithms?</a>
                    <a href="../05-combinatorics/index.html" class="sidebar-link">02. Combinatorics</a>
                    <a href="../03-distributions/index.html" class="sidebar-link">03. Normal Distributions</a>
                    <a href="../01-entropy/index.html" class="sidebar-link">04. Entropy Fundamentals</a>
                    <a href="../02-cross-entropy/index.html" class="sidebar-link">05. Cross-Entropy</a>
                    <a href="../02-kl-divergence/index.html" class="sidebar-link">06. KL Divergence</a>
                    <a href="../14-entropy-connections/index.html" class="sidebar-link">07. Entropy Connections</a>
                    <a href="../06-backpropagation/index.html" class="sidebar-link">08. Backpropagation</a>
                    <a href="../07-regularization/index.html" class="sidebar-link">09. Regularization</a>
                    <a href="../08-batch-normalization/index.html" class="sidebar-link">10. Batch Normalization</a>
                    <a href="../09-learning-rate/index.html" class="sidebar-link">11. Learning Rate</a>
                    <a href="../10-cnn/index.html" class="sidebar-link">12. CNNs</a>
                    <a href="../11-rnn/index.html" class="sidebar-link">13. RNNs</a>
                    <a href="../15-autoencoder/index.html" class="sidebar-link">14. Autoencoders</a>
                    <a href="../13-variational-inference/index.html" class="sidebar-link">15. Variational Inference</a>
                    <a href="../12-vae/index.html" class="sidebar-link">16. VAE</a>
                    <a href="../16-inductive-bias/index.html" class="sidebar-link">17. Inductive Bias</a>
                    <a href="../17-architectural-biases/index.html" class="sidebar-link">18. Architectural Biases</a>
                    <a href="../18-designing-biases/index.html" class="sidebar-link">19. Designing Biases</a>
                    <a href="../19-fst-fundamentals/index.html" class="sidebar-link">20. FST Fundamentals</a>
                    <a href="../20-weighted-fsts/index.html" class="sidebar-link">21. Weighted FSTs</a>
                    <a href="../21-fst-libraries/index.html" class="sidebar-link">22. FST Libraries</a>
                    <a href="../22-fst-applications/index.html" class="sidebar-link">23. FST Applications</a>
                    <a href="../23-neural-symbolic/index.html" class="sidebar-link">24. Neural-Symbolic Hybrids</a>
                </nav>
            </div>
            
            <div class="sidebar-section" style="margin-top: 2rem;">
                <h3 class="sidebar-section-title">Related Subjects</h3>
                <nav class="sidebar-nav">
                        <a href="../../linear-algebra/index.html" class="sidebar-link">Linear Algebra</a>
                    <a href="../../calculus/index.html" class="sidebar-link">Calculus</a>
                    <a href="../../physics/index.html" class="sidebar-link">Physics</a>
                </nav>
            </div>
        </aside>

        <!-- Main Article -->
        <main class="tutorial-main">
            
            <article class="article-content" id="theory">

                <div class="tutorial-footer-summary" style="margin: 0 0 3rem 0; padding: 2rem; background: #f8f9fa; border-radius: 8px; border-left: 4px solid #3b82f6;">
                    <h1>00. Probability Concepts for ML</h1>
                    <p class="lead">
                        Probability is the language of uncertainty. Before diving into ML,
                        we need to master the foundations: random variables, Bayes' theorem,
                        continuous distributions, probability density, and the art of probabilistic reasoning.
                    </p>
                </div>

                <!-- =============================== -->
                <!-- Section 1: Random Variables     -->
                <!-- =============================== -->
                <h2 id="random-variables">Random Variables</h2>

                <p>
                    Imagine you roll a die. Before it lands, the outcome is uncertain—it could be any
                    number from 1 to 6. A <strong>random variable</strong> is simply a way to attach
                    numbers to uncertain outcomes so we can do math with them.
                </p>

                <div class="definition-box">
                    <div class="box-title">Definition: Random Variable</div>
                    <p style="margin-bottom: 0;">
                        A random variable $X: \Omega \to \mathbb{R}$ assigns a numerical value to each
                        outcome in the sample space $\Omega$. We write $P(X = x)$ for the probability
                        that $X$ takes value $x$.
                    </p>
                </div>

                <p>
                    <strong>Example:</strong> You flip two coins. The sample space is
                    $\Omega = \{HH, HT, TH, TT\}$. Define $X$ = "number of heads."
                    Then $X(HH) = 2$, $X(HT) = 1$, $X(TH) = 1$, $X(TT) = 0$, giving us:
                </p>

                <table class="data-table" style="max-width: 400px;">
                    <thead>
                        <tr><th>$x$</th><th>$P(X = x)$</th></tr>
                    </thead>
                    <tbody>
                        <tr><td>0</td><td>$1/4 = 0.25$</td></tr>
                        <tr><td>1</td><td>$2/4 = 0.50$</td></tr>
                        <tr><td>2</td><td>$1/4 = 0.25$</td></tr>
                    </tbody>
                </table>

                <p>
                    Notice: probabilities sum to 1. This is always true—something <em>must</em> happen.
                </p>

                <p>Random variables come in two fundamental flavors:</p>

                <ul>
                    <li><strong>Discrete:</strong> Takes countable values (coin flips, dice rolls, word counts, pixel classes)</li>
                    <li><strong>Continuous:</strong> Takes values in an interval (height, temperature, neural network weights, pixel intensity)</li>
                </ul>

                <p>
                    This distinction matters enormously. For discrete variables, we can ask
                    "what's the probability of <em>exactly</em> this value?" For continuous variables,
                    that question breaks down—and understanding <em>why</em> is one of the most
                    important insights in probability. We'll tackle this in depth
                    <a href="#continuous-probability">below</a>.
                </p>


                <!-- =============================== -->
                <!-- Section 2: Rules of Probability -->
                <!-- =============================== -->
                <h2 id="probability-rules">The Rules of Probability</h2>

                <p>
                    All of probability theory rests on just a few rules. Master these, and you can
                    derive almost everything else.
                </p>

                <h3>The Sum Rule (Marginalization)</h3>

                <p>
                    Suppose you track two variables: $X$ = "weather" (sunny, rainy) and
                    $Y$ = "mood" (happy, sad). You have the full joint table:
                </p>

                <table class="data-table" style="max-width: 450px;">
                    <thead>
                        <tr><th></th><th>$Y$=Happy</th><th>$Y$=Sad</th><th>$P(X)$</th></tr>
                    </thead>
                    <tbody>
                        <tr><td><strong>$X$=Sunny</strong></td><td>0.40</td><td>0.10</td><td style="background-color: #f0fdf4;"><strong>0.50</strong></td></tr>
                        <tr><td><strong>$X$=Rainy</strong></td><td>0.15</td><td>0.35</td><td style="background-color: #f0fdf4;"><strong>0.50</strong></td></tr>
                        <tr><td>$P(Y)$</td><td style="background-color: #f0fdf4;"><strong>0.55</strong></td><td style="background-color: #f0fdf4;"><strong>0.45</strong></td><td>1.00</td></tr>
                    </tbody>
                </table>

                <p>
                    To find $P(X = \text{Sunny})$, sum across the row: $0.40 + 0.10 = 0.50$.
                    We "marginalize out" $Y$. In general:
                </p>

                <div class="math-block">
                    $$P(X = x) = \sum_{y} P(X = x, Y = y)$$
                </div>

                <div class="note-box">
                    <div class="box-title">Why "marginalize"?</div>
                    <p style="margin-bottom: 0;">
                        The name comes from writing sums in the <em>margins</em> of a table—exactly like
                        the highlighted column and row above. You collapse away one variable to learn
                        about the other.
                    </p>
                </div>

                <h3>The Product Rule (Chain Rule)</h3>

                <p>
                    Joint probabilities decompose into conditionals. From the table above:
                    $P(\text{Sunny, Happy}) = P(\text{Happy} | \text{Sunny}) \cdot P(\text{Sunny})
                    = \frac{0.40}{0.50} \times 0.50 = 0.80 \times 0.50 = 0.40$. ✓
                </p>

                <div class="math-block">
                    $$P(X, Y) = P(X | Y) \cdot P(Y) = P(Y | X) \cdot P(X)$$
                </div>

                <div class="note-box">
                    <div class="box-title">Chain Rule Extension</div>
                    <p style="margin-bottom: 0;">
                        For multiple variables:
                        $P(X_1, X_2, \ldots, X_n) = P(X_1) \prod_{i=2}^{n} P(X_i | X_1, \ldots, X_{i-1})$.
                        This is the foundation of autoregressive models (GPT generates text one token at a time,
                        each conditioned on all previous tokens).
                    </p>
                </div>


                <!-- =============================== -->
                <!-- Section 3: Bayes' Theorem       -->
                <!-- =============================== -->
                <h2 id="bayes-theorem">Bayes' Theorem: The Heart of ML</h2>

                <p>
                    From the product rule, we can derive the most important equation in machine learning.
                    The key insight: we can write $P(A, B)$ in two ways and set them equal.
                </p>

                <div class="math-derivation">
                    <div class="math-derivation-title">Deriving Bayes' Theorem</div>

                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            Start with product rule: $P(A, B) = P(A|B)P(B) = P(B|A)P(A)$
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            Equate the two expressions: $P(A|B)P(B) = P(B|A)P(A)$
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            Solve for $P(A|B)$:
                            $$\boxed{P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}}$$
                        </div>
                    </div>
                </div>

                <h3>Concrete Example: Medical Testing</h3>

                <p>
                    A disease affects 1% of the population. A test detects the disease 95% of the time
                    (sensitivity), but has a 5% false positive rate. You test positive—what's the
                    probability you actually have the disease?
                </p>

                <p><strong>Your gut says:</strong> "The test is 95% accurate, so about 95%." <strong>Your gut is wrong.</strong></p>

                <div class="math-derivation">
                    <div class="math-derivation-title">Applying Bayes' Theorem</div>

                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            <strong>Prior:</strong> $P(\text{Disease}) = 0.01$, $P(\text{Healthy}) = 0.99$
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            <strong>Likelihood:</strong> $P(+|\text{Disease}) = 0.95$, $P(+|\text{Healthy}) = 0.05$
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            <strong>Evidence:</strong> $P(+) = 0.95 \times 0.01 + 0.05 \times 0.99 = 0.0095 + 0.0495 = 0.059$
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">4</div>
                        <div class="math-step-content">
                            <strong>Posterior:</strong>
                            $P(\text{Disease}|+) = \frac{0.95 \times 0.01}{0.059} \approx 0.161 = 16.1\%$
                        </div>
                    </div>
                </div>

                <div class="warning-box">
                    <div class="box-title">Base Rate Neglect</div>
                    <p style="margin-bottom: 0;">
                        Despite a 95% accurate test, a positive result only means ~16% chance of disease!
                        The low base rate (1%) means most positives are false positives. This is why Bayes'
                        theorem is so important—it forces you to account for <strong>prior probabilities</strong>,
                        which your intuition often ignores.
                    </p>
                </div>

                <p>In machine learning terms:</p>

                <div class="math-block">
                    $$\underbrace{P(\theta | \mathcal{D})}_{\text{Posterior}} = \frac{\overbrace{P(\mathcal{D} | \theta)}^{\text{Likelihood}} \cdot \overbrace{P(\theta)}^{\text{Prior}}}{\underbrace{P(\mathcal{D})}_{\text{Evidence}}}$$
                </div>

                <ul>
                    <li><strong>Prior $P(\theta)$:</strong> What we believe about model parameters before seeing data (e.g., "weights should be small" → L2 regularization)</li>
                    <li><strong>Likelihood $P(\mathcal{D}|\theta)$:</strong> How probable is the observed data under these parameters</li>
                    <li><strong>Posterior $P(\theta|\mathcal{D})$:</strong> Updated belief after seeing data—this is what we want</li>
                    <li><strong>Evidence $P(\mathcal{D})$:</strong> Normalizing constant (often intractable, which motivates variational inference)</li>
                </ul>


                <!-- =============================== -->
                <!-- Section 4: Expectation          -->
                <!-- =============================== -->
                <h2 id="expectation">Expectation and Variance</h2>

                <p>
                    The <strong>expected value</strong> answers: "If I repeated this experiment forever,
                    what would the average outcome be?"
                </p>

                <p>
                    <strong>Example:</strong> A game costs $1 to play. You roll a die: if you get a 6,
                    you win $4; otherwise you win nothing. Should you play?
                </p>

                <div class="math-block">
                    $$\mathbb{E}[\text{profit}] = \frac{1}{6}(\$4) + \frac{5}{6}(\$0) - \$1 = \$0.67 - \$1 = -\$0.33$$
                </div>

                <p>
                    On average you lose 33 cents per game. The formal definition:
                </p>

                <div class="math-block">
                    $$\mathbb{E}[X] = \sum_{x} x \cdot P(X = x) \quad \text{(discrete)} \qquad \mathbb{E}[X] = \int x \cdot p(x) \, dx \quad \text{(continuous)}$$
                </div>

                <p>
                    The <strong>variance</strong> measures how spread out the values are around the mean.
                    Two investments might have the same expected return, but very different variances—that
                    difference is <em>risk</em>.
                </p>

                <div class="math-block">
                    $$\text{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[X^2] - (\mathbb{E}[X])^2$$
                </div>

                <div class="definition-box">
                    <div class="box-title">Linearity of Expectation</div>
                    <p style="margin-bottom: 0;">
                        $\mathbb{E}[aX + bY] = a\mathbb{E}[X] + b\mathbb{E}[Y]$, always—even when $X$ and $Y$
                        are dependent! This is one of the most powerful properties in probability.
                        It's why the expected number of heads in 100 coin flips is exactly 50, regardless
                        of any correlations between flips.
                    </p>
                </div>


                <!-- =============================== -->
                <!-- Section 5: Independence         -->
                <!-- =============================== -->
                <h2 id="independence">Independence</h2>

                <p>
                    Two events are <strong>independent</strong> if knowing one tells you nothing about the other:
                </p>

                <div class="math-block">
                    $$P(A \cap B) = P(A) \cdot P(B) \quad \Leftrightarrow \quad P(A|B) = P(A)$$
                </div>

                <p>
                    <strong>Example:</strong> Two dice rolls are independent—knowing the first die landed
                    on 3 tells you nothing about the second die. But "rain today" and "carry umbrella"
                    are <em>not</em> independent.
                </p>

                <p>
                    <strong>Conditional independence</strong> is crucial for graphical models:
                </p>

                <div class="math-block">
                    $$X \perp Y \mid Z \quad \Leftrightarrow \quad P(X, Y \mid Z) = P(X|Z) \cdot P(Y|Z)$$
                </div>

                <p>
                    <strong>Example:</strong> Whether two students get an A ($X$ and $Y$) may be correlated
                    (both depend on exam difficulty). But <em>given</em> the exam difficulty ($Z$), their
                    grades become independent—each student's performance depends only on their own ability.
                </p>

                <div class="warning-box">
                    <div class="box-title">Common Pitfall</div>
                    <p style="margin-bottom: 0;">
                        Independence and conditional independence are different! $X \perp Y$ does NOT imply
                        $X \perp Y \mid Z$, and vice versa. This subtlety is essential for understanding
                        Bayesian networks and Naive Bayes classifiers.
                    </p>
                </div>


                <!-- ============================================ -->
                <!-- Section 6: Continuous Probability & Density  -->
                <!-- ============================================ -->
                <h2 id="continuous-probability">Continuous Probability & Probability Density</h2>

                <p>
                    This is where most beginners get confused—and where deep understanding
                    separates good ML practitioners from great ones.
                </p>

                <h3 id="discrete-vs-continuous">The Fundamental Problem with Continuous Variables</h3>

                <p>
                    With a fair die, $P(X = 3) = 1/6$. Simple. Now consider a spinner that can land
                    on any real number between 0 and 1. What is $P(X = 0.5)$?
                </p>

                <p>
                    There are <em>uncountably infinitely many</em> points between 0 and 1. If each
                    had positive probability, the sum would be infinite—violating the axiom that
                    all probabilities must sum to 1. So the probability of any <em>exact</em> point must be:
                </p>

                <div class="math-block">
                    $$P(X = x) = 0 \quad \text{for any specific } x$$
                </div>

                <div class="warning-box">
                    <div class="box-title">This is not a technicality—it's profound</div>
                    <p style="margin-bottom: 0;">
                        Your height is exactly 170.000000... cm with probability zero. The temperature
                        right now is exactly 22.000000...°C with probability zero. Every continuous measurement
                        you've ever taken has probability zero of being exactly what it was.
                        Yet these things happen! This paradox is resolved by probability <em>density</em>.
                    </p>
                </div>

                <h3 id="probability-density">Probability Density Functions (PDFs)</h3>

                <p>
                    Since we can't assign probability to individual points, we assign probability to
                    <strong>intervals</strong>. The <strong>probability density function</strong> $p(x)$
                    tells you how probability is "concentrated" around each point:
                </p>

                <div class="definition-box">
                    <div class="box-title">Definition: Probability Density Function</div>
                    <p>
                        A function $p(x) \geq 0$ is a probability density function if:
                    </p>
                    <div class="math-block">
                        $$\int_{-\infty}^{\infty} p(x) \, dx = 1$$
                    </div>
                    <p style="margin-bottom: 0;">
                        The probability that $X$ falls in interval $[a, b]$ is:
                        $P(a \leq X \leq b) = \int_{a}^{b} p(x) \, dx$
                    </p>
                </div>

                <p>
                    <strong>Key insight:</strong> $p(x)$ is <em>not</em> a probability. It's a <strong>density</strong>—probability
                    per unit length. Just like mass density (kg/m³) isn't mass, probability density isn't probability.
                    You need to multiply by a "volume" (integrate over an interval) to get actual probability.
                </p>

                <p>
                    <strong>Analogy:</strong> Think of a long rope with varying thickness. The density at
                    a point tells you how thick the rope is there, but you can't weigh a single point of rope.
                    To get actual weight, you need to integrate density over a length of rope.
                </p>

                <h3 id="density-can-exceed-one">Density Can Exceed 1!</h3>

                <p>
                    Because $p(x)$ is not a probability, it is <em>not</em> bounded by 1. Consider a
                    uniform distribution on $[0, 0.5]$:
                </p>

                <div class="math-block">
                    $$p(x) = \begin{cases} 2 & \text{if } 0 \leq x \leq 0.5 \\ 0 & \text{otherwise} \end{cases}$$
                </div>

                <p>
                    Here $p(x) = 2$ for all $x$ in the interval, and $\int_0^{0.5} 2 \, dx = 1$. ✓ Perfectly valid.
                    The density is 2, but every interval probability is at most 1.
                </p>

                <div class="note-box">
                    <div class="box-title">Rule of Thumb</div>
                    <p style="margin-bottom: 0;">
                        $p(x) > 1$ simply means probability is concentrated in a small region.
                        A Gaussian with $\sigma = 0.1$ has $p(\mu) \approx 4.0$ at its peak.
                        The narrower the distribution, the taller the density peak.
                    </p>
                </div>


                <!-- ============================================ -->
                <!-- Section 7: p(x) = 0.01 for images           -->
                <!-- ============================================ -->
                <h2 id="density-images">Is $p(x) = 0.01$ High or Low? It Depends.</h2>

                <p>
                    This is one of the most important questions in ML, and the answer reveals a deep truth
                    about high-dimensional probability.
                </p>

                <h3>The 1D Case: A Simple Start</h3>

                <p>
                    If $X$ is a single number (say, a person's height in meters), and $p(x) = 0.01$,
                    what does that tell us? It means: in a tiny interval $[x, x + dx]$, the probability
                    of landing there is approximately $0.01 \cdot dx$.
                </p>

                <p>
                    For a standard Gaussian $\mathcal{N}(0, 1)$, the peak density is $p(0) = \frac{1}{\sqrt{2\pi}} \approx 0.399$.
                    So $p(x) = 0.01$ means $x$ is way out in the tails—rare. In 1D, $0.01$ is indeed a "low" density.
                </p>

                <h3>The Image Case: Where Intuition Breaks</h3>

                <p>
                    Now suppose $x$ is a $28 \times 28$ grayscale image (like MNIST digits). Each pixel
                    is a continuous value, so $x \in \mathbb{R}^{784}$. The density $p(x)$ now lives in
                    a <strong>784-dimensional space</strong>.
                </p>

                <p>
                    Is $p(x) = 0.01$ high or low for an image? <strong>It's actually extremely high.</strong>
                </p>

                <div class="definition-box">
                    <div class="box-title">Why? The Curse of Dimensionality</div>
                    <p>
                        In $d$ dimensions, the density at a point tells you the probability per unit
                        <em>hypervolume</em>. To get actual probability, you integrate over some
                        $d$-dimensional region:
                    </p>
                    <div class="math-block">
                        $$P(x \in R) = \int_R p(x) \, dx_1 \, dx_2 \cdots dx_d$$
                    </div>
                    <p style="margin-bottom: 0;">
                        Even a tiny interval $[x_i - \epsilon, x_i + \epsilon]$ per dimension creates
                        a hypervolume of $(2\epsilon)^d$. For $d = 784$ and $\epsilon = 0.01$,
                        that's $(0.02)^{784} \approx 10^{-1332}$. The volume is unimaginably small.
                    </p>
                </div>

                <p>
                    Let's build intuition step by step. Consider a standard Gaussian $\mathcal{N}(0, I)$ in $d$ dimensions.
                    The peak density (at the origin) is:
                </p>

                <div class="math-block">
                    $$p(0) = \frac{1}{(2\pi)^{d/2}} = \frac{1}{(2\pi)^{392}} \approx 10^{-362}$$
                </div>

                <p>
                    For a 784-dimensional Gaussian, even the <em>most likely</em> point has a density of $10^{-362}$.
                    So $p(x) = 0.01 = 10^{-2}$ would be <strong>about 10<sup>360</sup> times larger than
                    the peak of a standard Gaussian</strong>—meaning the distribution is incredibly
                    concentrated around that image. That's a model that is extremely confident about
                    what images look like.
                </p>

                <h3>A More Practical Perspective</h3>

                <p>
                    In practice, when ML researchers say "$p(x)$ is high," they usually mean relative to
                    other images under the same model. What matters is the <strong>log-likelihood</strong>:
                </p>

                <div class="math-block">
                    $$\log p(x) = -2 \quad \text{vs.} \quad \log p(x') = -500$$
                </div>

                <p>
                    Image $x$ is far more "likely" (typical) under the model than $x'$. The absolute value
                    of $p(x)$ in high dimensions is essentially meaningless—only <strong>comparisons</strong> matter.
                </p>

                <div class="note-box">
                    <div class="box-title">Bits Per Dimension</div>
                    <p style="margin-bottom: 0;">
                        To make log-likelihoods comparable across different image sizes, researchers often
                        report <strong>bits per dimension</strong>: $\frac{-\log_2 p(x)}{d}$. This normalizes
                        by the number of dimensions, giving you the average number of bits needed to encode
                        each pixel. Lower is better. State-of-the-art generative models achieve ~3 bits/dim
                        on natural images.
                    </p>
                </div>

                <h3>The Typical Set: Where Probability Actually Lives</h3>

                <p>
                    Here's a mind-bending fact: in high dimensions, the most probable <em>point</em> (the mode)
                    is <em>not</em> where most of the probability mass lives. This seems contradictory, but
                    the explanation is geometric.
                </p>

                <p>
                    For a $d$-dimensional Gaussian, the mode is at the origin, where density is highest.
                    But the origin is a single point, while there are exponentially more points at distance
                    $\sqrt{d}$ from the origin. The thin "shell" at radius $\approx \sqrt{d}$ has enormous
                    surface area—enough to dominate despite having lower density per point. This shell
                    is called the <strong>typical set</strong>.
                </p>

                <div class="warning-box">
                    <div class="box-title">Critical for Generative Models</div>
                    <p style="margin-bottom: 0;">
                        When sampling images from a VAE or diffusion model, you should sample from the
                        <em>typical set</em>, not the mode. Sampling from the mode (maximum density point)
                        often gives blurry, "average" images. This is why truncation tricks and temperature
                        scaling exist—they adjust <em>where</em> in the distribution you sample from.
                    </p>
                </div>

                <h3>Summary: Interpreting Density Values</h3>

                <table class="data-table">
                    <thead>
                        <tr><th>Dimension</th><th>Peak of $\mathcal{N}(0,I)$</th><th>Is $p(x)=0.01$ high?</th></tr>
                    </thead>
                    <tbody>
                        <tr><td>$d = 1$</td><td>$\approx 0.40$</td><td>No — in the tails</td></tr>
                        <tr><td>$d = 10$</td><td>$\approx 1.6 \times 10^{-4}$</td><td>Very high — 60× above peak</td></tr>
                        <tr><td>$d = 100$</td><td>$\approx 10^{-40}$</td><td>Astronomically high</td></tr>
                        <tr><td>$d = 784$ (MNIST)</td><td>$\approx 10^{-362}$</td><td>Absurdly high — model is incredibly concentrated</td></tr>
                    </tbody>
                </table>

                <div class="definition-box">
                    <div class="box-title">The Takeaway</div>
                    <p style="margin-bottom: 0;">
                        <strong>Never interpret density values without considering dimensionality.</strong>
                        In 1D, $p(x) = 0.01$ is low. In 784D, it's astronomically high. Always compare
                        densities to other points under the same model and in the same space.
                        When in doubt, use log-likelihoods and bits-per-dimension.
                    </p>
                </div>


                <!-- ================================================ -->
                <!-- Section 8: Why p(x) Matters in Generative DL   -->
                <!-- ================================================ -->
                <h2 id="why-px-matters">Why Know $p(x)$? The Goal of Generative Deep Learning</h2>

                <p>
                    You might wonder: why do we care about learning $p(x)$ at all? If we just want to
                    generate images, can't we skip the probability and directly train a neural network
                    to produce outputs? The answer reveals something deep about what generative models
                    really do.
                </p>

                <h3>What $p(x)$ Actually Tells You</h3>

                <p>
                    Suppose you've somehow learned the true probability distribution $p(x)$ over all
                    possible images. This single object gives you <strong>everything</strong>:
                </p>

                <ul>
                    <li><strong>Generation:</strong> Sample $x \sim p(x)$ to create new, realistic images</li>
                    <li><strong>Evaluation:</strong> Given an image $x$, compute $p(x)$ to ask "how typical is this?"</li>
                    <li><strong>Anomaly detection:</strong> If $p(x)$ is very low relative to training data, $x$ is an outlier</li>
                    <li><strong>Compression:</strong> Images with high $p(x)$ can be encoded with fewer bits (Shannon's theorem)</li>
                    <li><strong>Inpainting/denoising:</strong> Find $\arg\max_x p(x | x_{\text{observed}})$ to fill in missing regions</li>
                </ul>

                <div class="definition-box">
                    <div class="box-title">The Central Claim of Generative Modeling</div>
                    <p style="margin-bottom: 0;">
                        If you know $p(x)$ perfectly, you understand the data perfectly. Every question
                        about the data reduces to a computation involving $p(x)$. This is why learning
                        $p(x)$ is the holy grail of unsupervised learning.
                    </p>
                </div>

                <h3>Comparing Densities: Why Relative Values Matter</h3>

                <p>
                    Imagine your generative model assigns these densities to different images:
                </p>

                <table class="data-table">
                    <thead>
                        <tr><th>Image $x$</th><th>$\log p(x)$</th><th>Interpretation</th></tr>
                    </thead>
                    <tbody>
                        <tr><td>$x_1$ = sharp photo of a cat</td><td>$-1{,}200$</td><td>Highly typical — model "understands" cats</td></tr>
                        <tr><td>$x_2$ = blurry noise</td><td>$-45{,}000$</td><td>Very atypical — model says "this isn't a real image"</td></tr>
                        <tr><td>$x_3$ = photo of a dog</td><td>$-1{,}350$</td><td>Somewhat typical — less common but still plausible</td></tr>
                        <tr><td>$x_4$ = random static</td><td>$-120{,}000$</td><td>Extremely atypical — essentially impossible under this model</td></tr>
                    </tbody>
                </table>

                <p>
                    The absolute numbers are uninterpretable (they depend on dimensionality, as we saw).
                    But the <strong>ranking</strong> is everything: $p(x_1) > p(x_3) \gg p(x_2) \gg p(x_4)$.
                    The model assigns higher density to images that look like real photographs, and lower
                    density to noise. This ranking <em>is</em> the model's understanding of what images look like.
                </p>

                <h3>Four Things You Can Do Once You Know $p(x)$</h3>

                <h4>1. Generate New Data (Sampling)</h4>
                <p>
                    If you can sample $x \sim p(x)$, you create new data points that are statistically
                    indistinguishable from real ones. This is what DALL-E, Stable Diffusion, and GPT do:
                    they approximate $p(x)$ (over images or text), then sample from it.
                </p>

                <h4>2. Detect Anomalies</h4>
                <p>
                    A medical imaging model trained on healthy brain scans learns $p(x)$ for normal brains.
                    When a scan with a tumor arrives, $p(x_{\text{tumor}})$ is much lower than
                    $p(x_{\text{healthy}})$. The density ratio acts as an automatic anomaly score—no
                    labeled examples of tumors needed.
                </p>

                <h4>3. Compress Data Optimally</h4>
                <p>
                    Shannon proved: the optimal code length for an event $x$ is $-\log_2 p(x)$ bits.
                    If $p(x_1) = 0.001$, you need about 10 bits. If $p(x_2) = 0.0000003$, you need
                    about 22 bits. Common images get short codes; rare ones get long codes. A perfect
                    generative model is a perfect compressor—and vice versa.
                </p>

                <div class="note-box">
                    <div class="box-title">Compression = Understanding</div>
                    <p style="margin-bottom: 0;">
                        This connection is profound. A model that compresses images well must "understand"
                        their structure—edges, textures, objects, scenes. The log-likelihood
                        $\log p(x)$ directly measures compression quality. This is why researchers
                        use bits-per-dimension as a benchmark for generative models.
                    </p>
                </div>

                <h4>4. Make Decisions Under Uncertainty</h4>
                <p>
                    In Bayesian ML, every prediction averages over model uncertainty:
                </p>
                <div class="math-block">
                    $$p(y | x, \mathcal{D}) = \int p(y | x, \theta) \, p(\theta | \mathcal{D}) \, d\theta$$
                </div>
                <p>
                    This integral requires knowing $p(\theta | \mathcal{D})$—the posterior distribution
                    over model parameters. Without probability distributions, you can't quantify
                    uncertainty, and your model can't say "I don't know."
                </p>

                <h3>Why Not Just Learn to Generate Directly?</h3>

                <p>
                    GANs do exactly this—they learn to generate without explicitly modeling $p(x)$.
                    But this comes at a cost:
                </p>

                <table class="data-table">
                    <thead>
                        <tr><th>Capability</th><th>Knows $p(x)$ (VAE, Flow, Diffusion)</th><th>No $p(x)$ (GAN)</th></tr>
                    </thead>
                    <tbody>
                        <tr><td>Generate samples</td><td>✅</td><td>✅</td></tr>
                        <tr><td>Evaluate "how likely is $x$?"</td><td>✅</td><td>❌</td></tr>
                        <tr><td>Anomaly detection</td><td>✅</td><td>❌ (need workarounds)</td></tr>
                        <tr><td>Optimal compression</td><td>✅</td><td>❌</td></tr>
                        <tr><td>Stable training</td><td>✅ (maximize likelihood)</td><td>❌ (mode collapse, instability)</td></tr>
                        <tr><td>Interpolation in latent space</td><td>✅ (meaningful)</td><td>⚠️ (no guarantees)</td></tr>
                    </tbody>
                </table>

                <div class="warning-box">
                    <div class="box-title">The Takeaway</div>
                    <p style="margin-bottom: 0;">
                        Knowing $p(x)$ is strictly more powerful than just being able to generate samples.
                        It's the difference between an artist who can paint (generation) and one who can
                        also critique, compress, detect forgeries, and explain uncertainty. This is why
                        much of modern generative AI (diffusion models, normalizing flows, autoregressive
                        models) is built around learning $p(x)$.
                    </p>
                </div>

                <!-- Navigation -->
                <div class="tutorial-nav">
                    <div class="tutorial-nav-link prev disabled">
                        <span class="nav-label">Previous</span>
                        <span class="nav-title">← Start of Series</span>
                    </div>
                    <a href="../04-logarithms/index.html" class="tutorial-nav-link next">
                        <span class="nav-label">Next</span>
                        <span class="nav-title">Logarithms in ML →</span>
                    </a>
                </div>
                
            </article>
        
        </main>

        <!-- TOC (Right Side) -->
        <aside class="toc-container">
        <h4 class="toc-title">Contents</h4>
        <nav class="toc-list">
            <a href="#random-variables" class="toc-link">Random Variables</a>
            <a href="#probability-rules" class="toc-link">Rules of Probability</a>
            <a href="#bayes-theorem" class="toc-link">Bayes' Theorem</a>
            <a href="#expectation" class="toc-link">Expectation & Variance</a>
            <a href="#independence" class="toc-link">Independence</a>
            <a href="#continuous-probability" class="toc-link">Continuous Probability</a>
            <a href="#density-images" class="toc-link">p(x) = 0.01 for Images?</a>
            <a href="#why-px-matters" class="toc-link">Why Know p(x)?</a>
        </nav>
    </aside>
    </div>
    

    <!-- Table of Contents (floating) -->
    

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-brand">
                    <span class="logo-symbol">∇</span>
                    <span>ML Fundamentals</span>
                </div>
                <p class="footer-tagline">Deep understanding through first principles.</p>
            </div>
            <div class="footer-links">
                <a href="../../../index.html">Home</a>
                <a href="https://github.com/ml-entropy/ml-entropy.github.io" target="_blank">GitHub</a>
            </div>
        </div>
    </footer>

    <!-- Scripts -->
    <script src="../../../js/main.js"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            if (typeof renderMathInElement === 'function') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
    </script>
</body>
</html>
