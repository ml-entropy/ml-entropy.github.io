<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Variational Inference | ML Fundamentals</title>
    <meta name="description" content="Master variational inference: approximate Bayesian inference by optimization. Understand mean-field, ELBO, and modern VI methods.">
    
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Playfair+Display:wght@400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}, {left: '\\\\[', right: '\\\\]', display: true}, {left: '\\\\(', right: '\\\\)', display: false}], throwOnError: false});"></script>
    
    <!-- Styles -->
    <link rel="stylesheet" href="../../../css/main.css">
    <link rel="stylesheet" href="../../../css/components.css">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>‚àû</text></svg>">
<link rel="stylesheet" href="../../../css/sidebar.css">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar" id="navbar">
        <div class="nav-container">
            <a href="../../../index.html" class="nav-logo">
                <span class="logo-symbol">‚àá</span>
                <span class="logo-text">ML Fundamentals</span>
            </a>
            
            <button class="nav-toggle" id="navToggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            
            <div class="nav-menu" id="navMenu">
                <div class="nav-links">
                    <a href="../../../tutorials/ml/index.html" class="nav-link active">Machine Learning</a>
                    <a href="../../../tutorials/linear-algebra/index.html" class="nav-link">Linear Algebra</a>
                    <a href="../../../tutorials/calculus/index.html" class="nav-link">Calculus</a>
                    <a href="../../../tutorials/physics/index.html" class="nav-link">Physics</a>
                    <a href="../../../index.html#philosophy" class="nav-link">Philosophy</a>
                    <a href="../../../index.html#roadmap" class="nav-link">Roadmap</a>
                    <a href="https://github.com/ml-entropy/ml-entropy.github.io" class="nav-link" target="_blank">GitHub</a>
                </div>
                
                <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
                    <svg class="sun-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <circle cx="12" cy="12" r="5"/>
                        <path d="M12 1v2M12 21v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M1 12h2M21 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42"/>
                    </svg>
                    <svg class="moon-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                    </svg>
                </button>
            </div>
        </div>
    </nav>

    <!-- Tutorial Header -->
    <header class="tutorial-content-header">
        <div class="container">
            <nav class="breadcrumb">
                <a href="../../../index.html">Home</a>
                <span class="breadcrumb-separator">‚Üí</span>
                <a href="../index.html">Machine Learning</a>
                <span class="breadcrumb-separator">‚Üí</span>
                <span>Variational Inference</span>
            </nav>
            
            
            
            
            <div class="tutorial-tabs">
                <a href="#theory" class="tutorial-tab active">Theory</a>
                <a href="#code" class="tutorial-tab">Code</a>
                <a href="#exercises" class="tutorial-tab">Exercises</a>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    
    <!-- Main Content -->
    <div class="tutorial-wrapper">
        
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <aside class="tutorial-sidebar">
            <div class="sidebar-section">
                <h3 class="sidebar-section-title">Machine Learning</h3>
                <nav class="sidebar-nav">
                        <a href="../00-probability/index.html" class="sidebar-link">00. Probability Foundations</a>
                    <a href="../01-entropy/index.html" class="sidebar-link">01. Entropy Fundamentals</a>
                    <a href="../02-cross-entropy/index.html" class="sidebar-link">02. Cross-Entropy</a>
                    <a href="../02-kl-divergence/index.html" class="sidebar-link">03. KL Divergence</a>
                    <a href="../03-distributions/index.html" class="sidebar-link">04. Normal Distributions</a>
                    <a href="../04-logarithms/index.html" class="sidebar-link">05. Why Logarithms?</a>
                    <a href="../05-combinatorics/index.html" class="sidebar-link">06. Combinatorics</a>
                    <a href="../06-backpropagation/index.html" class="sidebar-link">07. Backpropagation</a>
                    <a href="../07-regularization/index.html" class="sidebar-link">08. Regularization</a>
                    <a href="../08-batch-normalization/index.html" class="sidebar-link">09. Batch Normalization</a>
                    <a href="../09-learning-rate/index.html" class="sidebar-link">10. Learning Rate</a>
                    <a href="../10-cnn/index.html" class="sidebar-link">11. CNNs</a>
                    <a href="../11-rnn/index.html" class="sidebar-link">12. RNNs</a>
                    <a href="../12-vae/index.html" class="sidebar-link">13. VAE</a>
                    <a href="../13-variational-inference/index.html" class="sidebar-link active">14. Variational Inference</a>
                    <a href="../14-entropy-connections/index.html" class="sidebar-link">15. Entropy Connections</a>
                </nav>
            </div>
            
            <div class="sidebar-section" style="margin-top: 2rem;">
                <h3 class="sidebar-section-title">Related Subjects</h3>
                <nav class="sidebar-nav">
                        <a href="../../linear-algebra/index.html" class="sidebar-link">Linear Algebra</a>
                    <a href="../../calculus/index.html" class="sidebar-link">Calculus</a>
                    <a href="../../physics/index.html" class="sidebar-link">Physics</a>
                </nav>
            </div>
        </aside>

        <!-- Main Article -->
        <main class="tutorial-main">
            
            <article class="article-content" id="theory">
                
                <!-- Section 1 -->
                <h2 id="problem">The Inference Problem</h2>
                
                <p>
                    To understand Variational Inference, we must first deeply understand the problem it tries to solve: 
                    <strong>Bayesian Inference</strong> in the face of complexity.
                </p>

                <h3>The Setup: A Generative Story</h3>
                <p>
                    In probabilistic machine learning, we view the world through a <strong>Generative Process</strong>. 
                    We assume that the complex, high-dimensional data we see ($\mathbf{x}$) didn't just appear out of nowhere. 
                    Instead, it was generated by a set of lower-dimensional, meaningful, but invisible factors.
                </p>

                <div class="definition-box">
                    <div class="box-title">1. Latent Variables ($\mathbf{z}$): The Blueprint</div>
                    <p>
                        <strong>Latent</strong> means "hidden." Think of $\mathbf{z}$ as the <strong>DNA</strong> or the <strong>blueprint</strong> of the data. 
                        These are the fundamental factors of variation that define the object.
                    </p>
                    <p>
                        <em>Example:</em> If $\mathbf{x}$ is an image of a handwritten digit (784 pixels), $\mathbf{z}$ might be a vector of just 10 numbers representing:
                        <br>‚Ä¢ Which digit is it? (e.g., "7")
                        <br>‚Ä¢ How thick is the stroke?
                        <br>‚Ä¢ What is the writing angle?
                    </p>
                    <p>
                        <strong>Analogy:</strong> Think of <em>Plato's Cave</em>. The prisoners (us) only see the shadows on the wall ($\mathbf{x}$). 
                        But these shadows are cast by real, 3D objects passing in front of a fire ($\mathbf{z}$). 
                        We want to understand the 3D objects, but we only have access to the 2D shadows.
                    </p>
                </div>

                <div class="definition-box">
                    <div class="box-title">2. The Prior ($p(\mathbf{z})$): The Landscape of Possibility</div>
                    <p>
                        This is our assumption about the latent variables <strong>before</strong> we see any data. 
                        It defines what we believe is "normal" in the universe of our model.
                    </p>
                    <p>
                        Often, we choose a simple prior like a standard normal distribution $\mathcal{N}(0, 1)$. 
                        This implies we expect the latent factors to be independent and clustered around zero. 
                        We expect most handwritten digits to have "average" thickness and "average" slant, with extreme values being rare.
                    </p>
                </div>

                <div class="definition-box">
                    <div class="box-title">3. The Likelihood ($p(\mathbf{x}|\mathbf{z})$): The Renderer</div>
                    <p>
                        The likelihood is the function that turns the abstract concept into concrete reality. 
                        It answers the question: <em>"If the latent code $\mathbf{z}$ describes a 'thick, slanted 7', how probable is this specific grid of pixels $\mathbf{x}$?"</em>
                    </p>
                    <p>
                        <strong>"We Design This":</strong> This phrase is crucial. The likelihood isn't a physical law we discover; it's a <strong>mathematical simulator</strong> we invent.
                        We act as architects building a machine (the Decoder) that mimics the real world.
                    </p>
                    <p>
                        <em>Examples of Design Choices:</em>
                        <br>‚Ä¢ <strong>Binary Images:</strong> If our data is black-and-white pixels, we might design the likelihood to be a <strong>Bernoulli</strong> distribution.
                        <br>‚Ä¢ <strong>Color Images:</strong> If our data is real-valued RGB, we might design it as a <strong>Gaussian</strong> distribution.
                    </p>
                    <p>
                        In deep learning, "designing the likelihood" usually means choosing a Neural Network architecture (e.g., a CNN) to output the parameters of these distributions. 
                        "Training" means tuning the network's weights so that the simulator produces realistic data.
                    </p>
                </div>

                <h3>The Goal: Reverse Engineering</h3>
                <p>
                    As machine learning practitioners, we only get to see the data $\mathbf{x}$ (the pixels). Our job is to reverse-engineer the process. 
                    We want to find the specific latent recipe $\mathbf{z}$ that produced a specific data point $\mathbf{x}$.
                </p>
                <p>
                    Mathematically, we are asking for the <strong>Posterior</strong> distribution $p(\mathbf{z}|\mathbf{x})$. 
                    This distribution represents our updated belief about the latent variables <em>after</em> observing the evidence.
                    Bayes' Theorem gives us the recipe to flip the probability from the "renderer" ($p(\mathbf{x}|\mathbf{z})$) to the "inference" ($p(\mathbf{z}|\mathbf{x})$):
                </p>
                
                <div class="math-block">
                    $$p(\mathbf{z}|\mathbf{x}) = \frac{p(\mathbf{x}|\mathbf{z})p(\mathbf{z})}{p(\mathbf{x})}$$
                </div>

                <p>Let's label these terms carefully:</p>
                <ul style="list-style-type: none; padding-left: 0;">
                    <li>$\color{blue} p(\mathbf{z}|\mathbf{x})$: <strong>The Posterior.</strong> "Given this image, what digit is it?" (The Goal)</li>
                    <li>$\color{green} p(\mathbf{x}|\mathbf{z})$: <strong>The Likelihood.</strong> "How well does this image match a '7'?" (The Renderer)</li>
                    <li>$\color{orange} p(\mathbf{z})$: <strong>The Prior.</strong> "How likely is a '7' in general?" (The Assumption)</li>
                    <li>$\color{red} p(\mathbf{x})$: <strong>The Evidence.</strong> (or Marginal Likelihood).
                        <br>‚Ä¢ <strong>Statistical View:</strong> It is the <em>normalizing constant</em> that ensures the posterior $p(\mathbf{z}|\mathbf{x})$ integrates to 1.
                        <br>‚Ä¢ <strong>Model View:</strong> It represents the total probability of generating the data $\mathbf{x}$ by "averaging" over all possible blueprints $\mathbf{z}$. A higher evidence means the model class itself is a better fit for the data.
                    </li>
                </ul>
                
                <div class="definition-box">
                    <div class="box-title">The Villain: The Marginal Likelihood</div>
                    <p>
                        The equation looks simple, but there is a trap. The denominator, $p(\mathbf{x})$, is called the <strong>Evidence</strong> 
                        or <strong>Marginal Likelihood</strong>. To calculate it, we must sum up the probability of generating $\mathbf{x}$ 
                        from <em>every possible configuration</em> of $\mathbf{z}$:
                    </p>
                    <div class="math-block" style="margin: 1rem 0;">
                        $$p(\mathbf{x}) = \int p(\mathbf{x}|\mathbf{z})p(\mathbf{z}) d\mathbf{z}$$
                    </div>
                    <p style="margin-bottom: 0;">
                        This integral is the root of the "Inference Problem."
                    </p>
                </div>

                <h3>Why is the Integral Hard?</h3>
                <p>
                    You might ask, "Why not just compute the integral?" In simple 1D textbook problems, we can. 
                    But in modern machine learning, $\mathbf{z}$ is often a high-dimensional vector (e.g., 100 dimensions).
                </p>
                
                <div class="note-box">
                    <div class="box-title">The Curse of Dimensionality</div>
                    <p>
                        Imagine $\mathbf{z}$ has just 100 dimensions, and we try to approximate the integral by checking a grid of points. 
                        If we check just 2 points along each dimension, we would need to evaluate the likelihood $2^{100}$ times.
                    </p>
                    <p>
                        $2^{100} \approx 10^{30}$. If we had a supercomputer checking a billion points per second, 
                        it would take longer than the age of the universe to finish.
                    </p>
                    <p style="margin-bottom: 0;">
                        Because we cannot compute the denominator $p(\mathbf{x})$, we cannot compute the value of the posterior $p(\mathbf{z}|\mathbf{x})$. 
                        We know the <em>shape</em> of the posterior (from the numerator), but we don't know the <em>scale</em> (the normalization constant). 
                        Without normalization, it's not a valid probability distribution.
                    </p>
                </div>

                <!-- Section 1.5: Intuition -->
                <h2 id="intuition">Intuition: Optimization as Projection</h2>
                
                <p>
                    Imagine the true posterior $p(\mathbf{z}|\mathbf{x})$ is a complex, jagged mountain range. 
                    We want to understand it, but we can't climb it directly.
                </p>
                
                <p>
                    <strong>Variational Inference</strong> proposes a different approach: instead of climbing 
                    the mountain, let's find the best-fitting "simple shape" (like a smooth hill) that matches 
                    the mountain range as closely as possible.
                </p>

                <div class="note-box">
                    <div class="box-title">Analogy</div>
                    <p>
                        Think of it as <strong>shadow puppetry</strong>. The complex object is the true posterior. 
                        The shadow it casts is the data likelihood. We want to find a simple object (our variational family) 
                        whose shadow looks just like the complex object's shadow.
                    </p>
                    <p style="margin-bottom: 0;">
                        Mathematically, we are <strong>projecting</strong> the complex distribution $p$ onto a 
                        simpler manifold of distributions $\mathcal{Q}$.
                    </p>
                </div>
                
                <!-- Section 2 -->
                <h2 id="vi-idea">The Variational Inference Idea</h2>
                
                <p>
                    Instead of computing $p(\mathbf{z}|\mathbf{x})$ exactly, <strong>approximate</strong> it 
                    with a simpler distribution $q(\mathbf{z})$ from a tractable family $\mathcal{Q}$:
                </p>
                
                <div class="math-block">
                    $$q^*(\mathbf{z}) = \arg\min_{q \in \mathcal{Q}} D_{KL}(q(\mathbf{z}) \| p(\mathbf{z}|\mathbf{x}))$$
                </div>

                <div class="definition-box">
                    <div class="box-title">Why is it called "Variational"?</div>
                    <p>
                        The name comes from the <strong>Calculus of Variations</strong>, a field of mathematics.
                    </p>
                    <p>
                        In standard calculus, we vary a <em>variable</em> $x$ to minimize a function $f(x)$.
                        <br>
                        In calculus of variations, we vary a <strong>function</strong> $q(z)$ to minimize a <em>functional</em> $F[q]$.
                    </p>
                    <p style="margin-bottom: 0;">
                        Here, our "variable" is the entire probability distribution $q$. We are tweaking and reshaping this distribution function itself until it minimizes the KL divergence.
                    </p>
                </div>
                
                <p>
                    Find the member of $\mathcal{Q}$ closest to the true posterior in KL divergence.
                </p>
                
                <div class="note-box">
                    <div class="box-title">Key Insight</div>
                    <p style="margin-bottom: 0;">
                        We've turned an <em>integration</em> problem into an <em>optimization</em> problem. 
                        This is the core idea of variational inference.
                    </p>
                </div>
                
                <!-- Section 3 -->
                <h2 id="elbo-derivation">Deriving the ELBO</h2>
                
                <p>
                    We have a problem. We want to minimize $D_{KL}(q(\mathbf{z}) \| p(\mathbf{z}|\mathbf{x}))$, but this expression contains the intractable posterior $p(\mathbf{z}|\mathbf{x})$.
                    We need a workaround.
                </p>

                <h3>The Log-Evidence Decomposition</h3>
                <p>
                    Instead of attacking the KL directly, let's look at the quantity we <em>wish</em> we could compute: the log-evidence $\log p(\mathbf{x})$.
                </p>
                
                <div class="math-derivation">
                    <div class="math-derivation-title">The Magic Trick</div>
                    
                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            Start with the marginal likelihood:
                            $$\log p(\mathbf{x}) = \int q(\mathbf{z}) \log p(\mathbf{x}) d\mathbf{z}$$
                            (We can multiply by $\int q(z)dz = 1$ and move $\log p(x)$ inside because it doesn't depend on $z$)
                        </div>
                    </div>
                    
                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            Use Bayes' Rule $p(\mathbf{x}) = \frac{p(\mathbf{x},\mathbf{z})}{p(\mathbf{z}|\mathbf{x})}$:
                            $$= \int q(\mathbf{z}) \log \left( \frac{p(\mathbf{x},\mathbf{z})}{p(\mathbf{z}|\mathbf{x})} \right) d\mathbf{z}$$
                        </div>
                    </div>
                    
                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            <strong>Multiply by 1:</strong> Introduce $\frac{q(\mathbf{z})}{q(\mathbf{z})}$ inside the log:
                            $$= \int q(\mathbf{z}) \log \left( \frac{p(\mathbf{x},\mathbf{z})}{q(\mathbf{z})} \cdot \frac{q(\mathbf{z})}{p(\mathbf{z}|\mathbf{x})} \right) d\mathbf{z}$$
                        </div>
                    </div>
                    
                    <div class="math-step">
                        <div class="math-step-number">4</div>
                        <div class="math-step-content">
                            Split the log product $\log(a \cdot b) = \log a + \log b$:
                            $$= \underbrace{\int q(\mathbf{z}) \log \left( \frac{p(\mathbf{x},\mathbf{z})}{q(\mathbf{z})} \right) d\mathbf{z}}_{\text{ELBO}} + \underbrace{\int q(\mathbf{z}) \log \left( \frac{q(\mathbf{z})}{p(\mathbf{z}|\mathbf{x})} \right) d\mathbf{z}}_{\text{KL Divergence}}$$
                        </div>
                    </div>
                </div>

                <h3>The "Seesaw" Intuition</h3>
                <p>
                    We have derived the fundamental identity of Variational Inference:
                </p>

                <div class="math-block">
                    $$\log p(\mathbf{x}) = \mathcal{L}(q) + D_{KL}(q(\mathbf{z}) \| p(\mathbf{z}|\mathbf{x}))$$
                </div>

                <div class="note-box">
                    <div class="box-title">Why this solves our problem</div>
                    <p>
                        1. <strong>The Left Side is Fixed:</strong> $\log p(\mathbf{x})$ is the true evidence of the data. It is a constant number (though unknown) that does not depend on our choice of $q$.
                        <br>
                        2. <strong>The KL is Non-Negative:</strong> $D_{KL} \geq 0$ always.
                    </p>
                    <p>
                        This means $\mathcal{L}(q)$ is a <strong>Lower Bound</strong> on the evidence (Evidence Lower BOund).
                    </p>
                    <p>
                        <strong>The Seesaw:</strong> Since the sum is constant, if we <strong>maximize</strong> the ELBO ($\mathcal{L}(q)$), we automatically <strong>minimize</strong> the KL divergence.
                        We can optimize the ELBO because it only involves terms we can compute ($p(\mathbf{x}, \mathbf{z})$ and $q(\mathbf{z})$)!
                    </p>
                </div>

                <h3>Interpreting the ELBO</h3>
                <p>
                    What does maximizing the ELBO actually do? Let's rearrange its terms:
                </p>
                <div class="math-block">
                    $$\mathcal{L}(q) = \mathbb{E}_{q}[\log p(\mathbf{x}|\mathbf{z})] - D_{KL}(q(\mathbf{z}) \| p(\mathbf{z}))$$
                </div>
                
                <ul style="list-style-type: none; padding-left: 0;">
                    <li>
                        <strong>Term 1: Reconstruction Quality ($\mathbb{E}_{q}[\log p(\mathbf{x}|\mathbf{z})]$)</strong>
                        <br>Encourages $q$ to pick latent codes $\mathbf{z}$ that explain the data well. "Make the shadow look like the object."
                    </li>
                    <li style="margin-top: 1rem;">
                        <strong>Term 2: Regularization ($-D_{KL}(q(\mathbf{z}) \| p(\mathbf{z}))$)</strong>
                        <br>Encourages $q$ to stay close to the prior $p(\mathbf{z})$. "Don't hallucinate complex codes; keep it simple."
                    </li>
                </ul>
                
                <!-- Section 4 -->
                <h2 id="mean-field">Mean-Field Variational Inference</h2>
                
                <p>
                    So far, we've defined the objective (ELBO). But how do we choose the family $\mathcal{Q}$?
                    If $\mathcal{Q}$ is too complex, we can't compute the expectations in the ELBO. 
                    If it's too simple, the approximation will be poor.
                </p>

                <h3>The Mean-Field Assumption</h3>
                <p>
                    The most common strategy is to assume that the variational distribution <strong>factorizes</strong> 
                    over the latent variables. This is called the <strong>Mean-Field Assumption</strong>:
                </p>
                
                <div class="math-block">
                    $$q(\mathbf{z}) = \prod_{j=1}^{m} q_j(z_j)$$
                </div>
                
                <p>
                    This means we assume the latent variables are <strong>independent</strong> in our approximation, 
                    even if they are correlated in the true posterior.
                </p>

                <div class="definition-box">
                    <div class="box-title">Why "Mean Field"?</div>
                    <p>
                        The term comes from statistical physics. Imagine a gas where every particle interacts with every other particle. 
                        Solving this exactly is impossible ($N$-body problem).
                    </p>
                    <p>
                        <strong>Approximation:</strong> Instead of modeling individual interactions, assume each particle interacts with the 
                        <strong>"mean field"</strong> created by the average behavior of all other particles.
                    </p>
                    <p style="margin-bottom: 0;">
                        In VI, we replace the complex dependency of $z_j$ on specific values of other variables with a dependency on their 
                        <strong>average</strong> values (expectations).
                    </p>
                </div>

                <h3>Coordinate Ascent Optimization</h3>
                <p>
                    Because of the factorization, we can optimize each factor $q_j(z_j)$ one at a time while holding the others fixed. 
                    This is called <strong>Coordinate Ascent Variational Inference (CAVI)</strong>.
                </p>
                
                <div class="math-derivation">
                    <div class="math-derivation-title">The Update Rule</div>
                    
                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            <strong>Goal:</strong> Find the optimal distribution $q_k^*(z_k)$ for the $k$-th variable, assuming all other $q_{j \neq k}$ are fixed.
                        </div>
                    </div>
                    
                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            <strong>The Solution:</strong> It turns out (via calculus of variations) that the optimal form is:
                            $$\log q_k^*(z_k) = \mathbb{E}_{-k}[\log p(\mathbf{x}, \mathbf{z})] + \text{const}$$
                        </div>
                    </div>
                    
                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            <strong>Interpretation:</strong> Take the joint log-probability of everything ($\mathbf{x}$ and all $\mathbf{z}$). 
                            Then, take the expected value over <em>every other variable</em> except $z_k$. 
                            What remains is a function of only $z_k$, which becomes our new $q_k$.
                        </div>
                    </div>
                </div>

                <div class="note-box">
                    <div class="box-title">The Limitation</div>
                    <p>
                        By assuming independence, Mean-Field VI <strong>cannot model correlations</strong> in the posterior. 
                        If $z_1$ and $z_2$ are highly correlated (e.g., "if tall, then heavy"), the mean-field approximation will simply ignore this relationship.
                    </p>
                    <p style="margin-bottom: 0;">
                        This typically leads to <strong>underestimating the variance</strong> of the posterior. The approximation will be "too confident" and centered on the mode.
                    </p>
                </div>

                <!-- Section 4.5: Examples -->
                <h2 id="examples">Examples</h2>

                <h3>1. Discrete Example: Breaking Correlations</h3>
                <p>
                    Let's use a concrete analogy to see how the Mean-Field assumption breaks correlations.
                </p>

                <div class="note-box">
                    <div class="box-title">The "Pizza or Sushi" Problem</div>
                    <p>
                        Imagine two friends, Alice ($z_1$) and Bob ($z_2$), trying to decide on dinner.
                        <br>
                        They are best friends and <strong>always</strong> eat the same thing.
                    </p>
                    <p>
                        <strong>The True Distribution ($p$):</strong>
                        <br>‚Ä¢ Option A: Both eat Pizza (0, 0) $\rightarrow$ probability 0.5
                        <br>‚Ä¢ Option B: Both eat Sushi (1, 1) $\rightarrow$ probability 0.5
                        <br>‚Ä¢ Disagreement (0, 1) or (1, 0) $\rightarrow$ probability <strong>0.0</strong> (Impossible!)
                    </p>
                </div>

                <p>
                    Now, let's try to approximate this using <strong>Mean-Field VI</strong>.
                    <br>
                    The assumption $q(z_1, z_2) = q_1(z_1)q_2(z_2)$ means Alice and Bob make their decisions <strong>independently</strong>.
                </p>

                <p><strong>The Attempt:</strong> Suppose we try to capture the "50/50" uncertainty.
                    <br>
                    Alice sets her preference to 50% Pizza, 50% Sushi ($q_1(0)=0.5, q_1(1)=0.5$).
                    <br>
                    Bob does the same ($q_2(0)=0.5, q_2(1)=0.5$).
                </p>

                <p><strong>The Failure:</strong> Because they are independent, the joint probability of them disagreeing is:
                    <br>
                    $q(\text{Alice=Pizza, Bob=Sushi}) = 0.5 \times 0.5 = 0.25$
                </p>

                <p>
                    But in the true world $p$, this event has probability <strong>0</strong>.
                    <br>
                    The KL divergence formula contains the term $\log \frac{q(z)}{p(z)}$.
                    <br>
                    If $p(z) = 0$ and $q(z) > 0$, then we are dividing by zero inside the log. The penalty is <strong>Infinite</strong>.
                </p>

                <div class="definition-box">
                    <div class="box-title">The Consequence: Mode Collapse</div>
                    <p>
                        To avoid this infinite penalty, $q$ must ensure that it <strong>never</strong> assigns probability to events that are impossible in $p$.
                    </p>
                    <p>
                        The only way to satisfy this with independent distributions is to pick <strong>one valid solution</strong> and stick to it 100%.
                        <br>
                        ‚Ä¢ Solution 1: $q_1(0)=1, q_2(0)=1$ (Both eat Pizza with certainty).
                        <br>‚Ä¢ Solution 2: $q_1(1)=1, q_2(1)=1$ (Both eat Sushi with certainty).
                    </p>
                    <p style="margin-bottom: 0;">
                        We successfully approximated <em>one</em> of the modes, but we completely lost the global uncertainty (that it could have been the other option). <strong>The correlation is broken.</strong>
                    </p>
                </div>

                <h3>2. Continuous Example: Mode Seeking</h3>
                <p>
                    Now consider a continuous case where the true posterior $p(z)$ is <strong>bimodal</strong> (has two separate peaks, like a camel's back).
                    <br>
                    Our variational family $q(z)$ is a single Gaussian (unimodal, one peak).
                </p>

                <div class="note-box">
                    <div class="box-title">Analogy: The Perfectionist vs. The Politician</div>
                    <p>
                        There are two ways to measure the difference between distributions, leading to opposite behaviors.
                    </p>
                </div>

                <h4>Case 1: The Perfectionist ($D_{KL}(q\|p)$) - Variational Inference</h4>
                <p>
                    This is what we use in VI. Let's look at the term inside the integral:
                </p>
                <div class="math-block">
                    $$D_{KL}(q\|p) = \int q(z) \log \left( \frac{q(z)}{p(z)} \right) dz$$
                </div>
                <p>
                    <strong>The Danger Zone:</strong> Consider regions where $p(z) \approx 0$ (the valley between the two peaks).
                    <br>
                    If $q(z)$ puts any mass there ($q(z) > 0$), the ratio $\frac{q(z)}{p(z)}$ explodes to infinity.
                    <br>
                    <strong>The Strategy:</strong> To stay safe, $q(z)$ acts like a <strong>Perfectionist</strong>. It effectively says: <em>"I cannot be wrong. If $p$ is zero, I MUST be zero."</em>
                </p>
                <p>
                    <strong>The Result (Mode Seeking):</strong> $q$ will choose <strong>one</strong> of the two peaks and fit it tightly. It completely ignores the other peak to avoid crossing the valley of zero probability.
                    <br>
                    <em>Consequence:</em> We underestimate variance. We think we are very certain about the answer, but we missed half the possibilities.
                </p>

                <h4>Case 2: The Politician ($D_{KL}(p\|q)$) - Expectation Propagation</h4>
                <p>
                    What if we swapped the order?
                </p>
                <div class="math-block">
                    $$D_{KL}(p\|q) = \int p(z) \log \left( \frac{p(z)}{q(z)} \right) dz$$
                </div>
                <p>
                    <strong>The Danger Zone:</strong> Now, if $p(z) > 0$ (a peak exists), $q(z)$ <strong>cannot</strong> be zero.
                    <br>
                    <strong>The Strategy:</strong> $q(z)$ acts like a <strong>Politician</strong>. It tries to please everyone. It says: <em>"If anyone is there ($p>0$), I must cover them."</em>
                </p>
                <p>
                    <strong>The Result (Mean Seeking):</strong> $q$ will stretch out to cover <strong>both</strong> peaks. Since it's a single Gaussian, it ends up centered in the valley (where probability is low!) with a huge variance.
                    <br>
                    <em>Consequence:</em> We overestimate variance. We are "inclusive but vague."
                </p>

                <div class="definition-box">
                    <div class="box-title">Summary: Why VI is Mode-Seeking</div>
                    <p>
                        Variational Inference uses the "Perfectionist" distance ($KL(q\|p)$) because it's computationally tractable (we can take expectations over $q$).
                    </p>
                    <p style="margin-bottom: 0;">
                        This creates the <strong>Zero-Forcing Property</strong>: $q$ is forced to be zero wherever $p$ is zero. This leads to sharp, focused approximations that may miss other modes.
                    </p>
                </div>
                
                <!-- Section 5 -->
                <h2 id="stochastic-vi">Stochastic Variational Inference</h2>
                
                <p>
                    Mean-Field VI with Coordinate Ascent has a major flaw: it's slow. 
                    To update the global parameters, you often need to iterate through the <strong>entire dataset</strong>. 
                    For modern "Big Data" (millions of images), this is impossible.
                </p>

                <h3>The Solution: Mini-Batches</h3>
                <p>
                    We want to use <strong>Stochastic Gradient Descent (SGD)</strong>. We want to grab a small "mini-batch" of data, 
                    estimate the gradient of the ELBO, and take a small step. This makes learning scalable.
                </p>

                <div class="definition-box">
                    <div class="box-title">The Challenge: Backpropagating through Randomness</div>
                    <p>
                        To use SGD, we need to compute the gradient of our loss (the ELBO) with respect to the variational parameters $\phi$ (e.g., $\mu$ and $\sigma$).
                    </p>
                    <p>
                        The ELBO contains an expectation: $\mathcal{L} = \mathbb{E}_{z \sim q_\phi}[\log p(x, z) - \log q_\phi(z)]$.
                    </p>
                    <p style="margin-bottom: 0;">
                        <strong>The Problem:</strong> The distribution we are sampling from ($q_\phi$) <em>depends on the parameters we want to differentiate</em>. 
                        You cannot standard backpropagate through a "sampling" node (like `np.random.normal()`). 
                        It's like trying to ask a dice roll, "How would the outcome change if I changed the probability of rolling a 6?" 
                        The outcome is discrete and random; the derivative is undefined or high-variance.
                    </p>
                </div>

                <h3>The Fix: The Reparameterization Trick</h3>
                <p>
                    We fix this by moving the randomness <strong>outside</strong> the network. This is the magic behind VAEs.
                </p>

                <div class="note-box">
                    <div class="box-title">Analogy: Moving the Cloud</div>
                    <p>
                        <strong>Before (Standard Sampling):</strong> You tell the computer: "Draw a sample from $\mathcal{N}(\mu, \sigma^2)$."
                        <br>
                        The computer gives you a number, say `1.7`. You can't compute $\frac{\partial (1.7)}{\partial \mu}$. The connection is broken.
                    </p>
                    <p>
                        <strong>After (Reparameterization):</strong> You tell the computer:
                        <br>1. "Go get a random number $\epsilon$ from a standard generator $\mathcal{N}(0, 1)$." (This $\epsilon$ has no parameters).
                        <br>2. "Now, calculate $z = \mu + \sigma \times \epsilon$."
                    </p>
                    <p style="margin-bottom: 0;">
                        Now, $z$ is just a deterministic function of $\mu$ and $\sigma$ (and a fixed constant $\epsilon$). 
                        We <strong>can</strong> compute $\frac{\partial z}{\partial \mu} = 1$ and $\frac{\partial z}{\partial \sigma} = \epsilon$. 
                        Gradients can flow freely!
                    </p>
                </div>

                <div class="math-derivation">
                    <div class="math-derivation-title">Mathematical Formulation</div>
                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            <strong>Original Gradient:</strong> $\nabla_\phi \mathbb{E}_{q_\phi}[f(z)]$ (Hard!)
                        </div>
                    </div>
                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            <strong>Reparameterize:</strong> Let $z = g_\phi(\epsilon)$ where $\epsilon \sim p(\epsilon)$ (fixed distribution).
                            <br>
                            For Gaussian: $z = \mu + \sigma \odot \epsilon$ with $\epsilon \sim \mathcal{N}(0, I)$.
                        </div>
                    </div>
                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            <strong>Pathwise Derivative:</strong> We can now move the gradient <em>inside</em> the expectation:
                            $$\nabla_\phi \mathbb{E}_{q_\phi}[f(z)] = \mathbb{E}_{p(\epsilon)}[\nabla_\phi f(g_\phi(\epsilon))]$$
                        </div>
                    </div>
                    <div class="math-step">
                        <div class="math-step-number">4</div>
                        <div class="math-step-content">
                            <strong>Monte Carlo:</strong> We approximate this expectation by sampling one (or a few) $\epsilon$ per step:
                            $$\approx \frac{1}{L}\sum_{l=1}^{L} \nabla_\phi [\log p(\mathbf{x}, z^{(l)}) - \log q_\phi(z^{(l)})]$$
                            where $z^{(l)} = \mu + \sigma \odot \epsilon^{(l)}$.
                        </div>
                    </div>
                </div>

                <div class="warning-box">
                    <div class="box-title">Modern VI Methods</div>
                    <p style="margin-bottom: 0;">
                        <strong>Black-box VI:</strong> Works with any model using score function gradients (REINFORCE), even if reparameterization isn't possible (e.g., discrete latents).<br>
                        <strong>Normalizing flows:</strong> Starts with a simple $q(z)$ and transforms it through a series of invertible mappings to create complex, flexible posteriors beyond the mean-field limit.<br>
                        <strong>Amortized inference:</strong> Instead of optimizing a separate $\phi_i$ for every data point $x_i$, we train a neural network $f_\theta(x)$ that predicts $\phi$ for any input (like the VAE Encoder).
                    </p>
                </div>
                
                <!-- Section 6 -->
                <h2 id="comparison">VI vs MCMC</h2>
                
                <p>
                    We've spent this entire tutorial on Variational Inference. But it's not the only game in town. 
                    The other major family of algorithms is <strong>Markov Chain Monte Carlo (MCMC)</strong>.
                </p>

                <div class="note-box">
                    <div class="box-title">Analogy: The Hiker vs. The Surveyor</div>
                    <p>
                        Imagine the posterior $p(\mathbf{z}|\mathbf{x})$ is a vast, rugged mountain range. We want to understand its shape.
                    </p>
                    <p>
                        <strong>Variational Inference (The Hiker):</strong>
                        <br>The hiker wants to find the highest peak <em>quickly</em>. They choose a specific climbing gear (the variational family $q$) and sprint uphill (optimization).
                        <br><em>Pros:</em> Fast, efficient.
                        <br><em>Cons:</em> Might get stuck on a small hill (local optimum) or miss a second peak entirely (mode seeking).
                    </p>
                    <p>
                        <strong>MCMC (The Surveyor):</strong>
                        <br>The surveyor wants to map the <em>entire</em> landscape perfectly. They wander around randomly (sampling), spending more time in high-altitude areas.
                        <br><em>Pros:</em> Eventually produces a perfect map (asymptotically exact). Captures all modes and complex shapes.
                        <br><em>Cons:</em> Takes forever. Requires walking everywhere. Hard to know when the map is "done" (convergence).
                    </p>
                </div>

                <h3>Comparison Summary</h3>
                <div style="overflow-x: auto;">
                    <table style="width: 100%; border-collapse: collapse; margin: 2rem 0;">
                        <thead>
                            <tr style="background-color: #f3f4f6; border-bottom: 2px solid #e5e7eb;">
                                <th style="padding: 1rem; text-align: left;">Feature</th>
                                <th style="padding: 1rem; text-align: left;">Variational Inference (VI)</th>
                                <th style="padding: 1rem; text-align: left;">MCMC</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr style="border-bottom: 1px solid #e5e7eb;">
                                <td style="padding: 1rem; font-weight: bold;">Core Math</td>
                                <td style="padding: 1rem;">Optimization (minimize KL)</td>
                                <td style="padding: 1rem;">Integration (sampling)</td>
                            </tr>
                            <tr style="border-bottom: 1px solid #e5e7eb;">
                                <td style="padding: 1rem; font-weight: bold;">Speed</td>
                                <td style="padding: 1rem;">‚ö° Fast (seconds/minutes)</td>
                                <td style="padding: 1rem;">üê¢ Slow (hours/days)</td>
                            </tr>
                            <tr style="border-bottom: 1px solid #e5e7eb;">
                                <td style="padding: 1rem; font-weight: bold;">Scalability</td>
                                <td style="padding: 1rem;">High (works with SGD/Big Data)</td>
                                <td style="padding: 1rem;">Low (hard to batch)</td>
                            </tr>
                            <tr style="border-bottom: 1px solid #e5e7eb;">
                                <td style="padding: 1rem; font-weight: bold;">Accuracy</td>
                                <td style="padding: 1rem;">Biased (restricted by family $\mathcal{Q}$)</td>
                                <td style="padding: 1rem;">Asymptotically Exact</td>
                            </tr>
                            <tr style="border-bottom: 1px solid #e5e7eb;">
                                <td style="padding: 1rem; font-weight: bold;">Problem</td>
                                <td style="padding: 1rem;">Underestimates variance</td>
                                <td style="padding: 1rem;">Convergence diagnosis</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <div class="definition-box">
                    <div class="box-title">When to use which?</div>
                    <p>
                        <strong>Use Variational Inference when:</strong>
                        <br>‚Ä¢ You have massive datasets (Deep Learning, VAEs).
                        <br>‚Ä¢ You need real-time predictions.
                        <br>‚Ä¢ You care more about the "best guess" than perfect uncertainty bars.
                    </p>
                    <p>
                        <strong>Use MCMC when:</strong>
                        <br>‚Ä¢ You have small, scientific datasets.
                        <br>‚Ä¢ Accuracy is critical (e.g., medical diagnosis, structural safety).
                        <br>‚Ä¢ You need to know the exact shape of the "tail" risks.
                    </p>
                </div>


                
                <!-- Navigation -->
                

                <div class="tutorial-nav">
                    <a href="../12-vae/index.html" class="tutorial-nav-link prev">
                        <span class="nav-label">Previous</span>
                        <span class="nav-title">‚Üê VAEs</span>
                    </a>
                    <div class="tutorial-nav-link next disabled">
                        <span class="nav-label">Next</span>
                        <span class="nav-title">End of Series ‚Üí</span>
                    </div>
                </div>
                
            </article>

            <article class="article-content" id="code">
                <h2>Implementing Variational Inference</h2>
                <p>
                    Let's implement a simple example: Approximating a bimodal distribution with a single Gaussian using <strong>Stochastic Variational Inference</strong> in PyTorch.
                </p>

                <h3>The Target Distribution</h3>
                <p>
                    $p(z) \propto e^{-(z-2)^2} + e^{-(z+2)^2}$ (A mixture of two Gaussians).
                </p>

                <div class="code-block">
<pre><code class="language-python">import torch
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np

# 1. Define the (unnormalized) log-probability of the target p(z)
def log_p(z):
    # Mixture of two Gaussians at -2 and +2
    return torch.log(torch.exp(-(z - 2)**2) + torch.exp(-(z + 2)**2))

# 2. Define the Variational Family q(z) = N(mu, sigma)
class VariationalGaussian(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.mu = torch.nn.Parameter(torch.tensor(0.0))
        self.log_sigma = torch.nn.Parameter(torch.tensor(0.0))
    
    def sample(self, n_samples):
        sigma = torch.exp(self.log_sigma)
        epsilon = torch.randn(n_samples) # Standard Normal
        return self.mu + sigma * epsilon # Reparameterization Trick
    
    def log_q(self, z):
        sigma = torch.exp(self.log_sigma)
        return -0.5 * torch.log(2 * torch.tensor(np.pi)) - self.log_sigma - 0.5 * ((z - self.mu) / sigma)**2

# 3. Optimization Loop (Maximizing ELBO)
model = VariationalGaussian()
optimizer = optim.Adam(model.parameters(), lr=0.1)

for i in range(1000):
    optimizer.zero_grad()
    
    # Sample z from q (Reparameterization)
    z = model.sample(100)
    
    # Calculate ELBO: E[log p(z) - log q(z)]
    # Note: Since p(x) is constant, maximizing this is equivalent to minimizing KL(q||p)
    elbo = torch.mean(log_p(z) - model.log_q(z))
    
    # Minimize negative ELBO
    loss = -elbo
    loss.backward()
    optimizer.step()
    
    if i % 100 == 0:
        print(f"Iter {i}: mu={model.mu.item():.2f}, sigma={torch.exp(model.log_sigma).item():.2f}")

print("Result: The model converges to ONE of the modes (e.g., +2 or -2) with low variance.")
</code></pre>
                </div>
            </article>

            <article class="article-content" id="exercises">
                <h2>Exercises</h2>

                <div class="exercise-box">
                    <div class="box-title">Exercise 1: Discrete Mean-Field</div>
                    <p>
                        Let $p(z_1, z_2)$ be defined on $\{0,1\}^2$ as:
                        $$p(0,0)=0.4, \quad p(0,1)=0.1, \quad p(1,0)=0.1, \quad p(1,1)=0.4$$
                        Assume $q(z_1, z_2) = q_1(z_1)q_2(z_2)$. Let $q_1(1) = \mu_1$ and $q_2(1) = \mu_2$.
                    </p>
                    <p>
                        <strong>Task:</strong> Write down the ELBO as a function of $\mu_1, \mu_2$ and find the stationary points. 
                        Does the optimal solution capture the correlation?
                    </p>
                </div>

                <div class="exercise-box">
                    <div class="box-title">Exercise 2: Gaussian VI</div>
                    <p>
                        Let $p(z) = \mathcal{N}(z; \mu_p, \sigma_p^2)$ and $q(z) = \mathcal{N}(z; \mu_q, \sigma_q^2)$.
                    </p>
                    <p>
                        <strong>Task:</strong> Calculate $D_{KL}(q\|p)$ analytically. Minimize it with respect to $\mu_q$ and $\sigma_q$. 
                        Show that the optimal $q$ is exactly $p$ (i.e., $\mu_q=\mu_p, \sigma_q=\sigma_p$).
                    </p>
                </div>
            </article>
        
        </main>

        <!-- TOC (Right Side) -->
        <aside class="toc-container">
        <h4 class="toc-title">Contents</h4>
        <nav class="toc-list">
            <a href="#problem" class="toc-link">The Problem</a>
            <a href="#intuition" class="toc-link">Intuition</a>
            <a href="#vi-idea" class="toc-link">VI Idea</a>
            <a href="#elbo-derivation" class="toc-link">ELBO Derivation</a>
            <a href="#mean-field" class="toc-link">Mean-Field VI</a>
            <a href="#examples" class="toc-link">Examples</a>
            <a href="#stochastic-vi" class="toc-link">Stochastic VI</a>
            <a href="#comparison" class="toc-link">VI vs MCMC</a>
            <a href="#exercises" class="toc-link">Exercises</a>
        </nav>
    </aside>
    </div>
    

    <!-- Table of Contents (floating) -->
    

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-brand">
                    <span class="logo-symbol">‚àá</span>
                    <span>ML Fundamentals</span>
                </div>
                <p class="footer-tagline">Deep understanding through first principles.</p>
            </div>
            <div class="footer-links">
                <a href="../../../index.html">Home</a>
                <a href="https://github.com/ml-entropy/ml-entropy.github.io" target="_blank">GitHub</a>
            </div>
        </div>
    </footer>

    <!-- Scripts -->
    <script src="../../../js/main.js"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            if (typeof renderMathInElement === 'function') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
    </script>
</body>
</html>
