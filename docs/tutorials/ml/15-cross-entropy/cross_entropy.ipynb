{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 15: Cross-Entropy \u2014 Code\n",
    "\n",
    "This notebook provides interactive code examples for the Cross-Entropy tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cross-Entropy Implementation\n",
    "\n",
    "This corresponds to Exercise B1. We'll create a numerically stable function to calculate cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(P, Q):\n",
    "    \"\"\"\n",
    "    Calculates the cross-entropy between two probability distributions.\n",
    "    \n",
    "    Args:\n",
    "        P (np.array): The true distribution (one-hot).\n",
    "        Q (np.array): The predicted distribution.\n",
    "        \n",
    "    Returns:\n",
    "        float: The cross-entropy loss.\n",
    "    \"\"\"\n",
    "    # Add a small epsilon for numerical stability to prevent log(0)\n",
    "    epsilon = 1e-9\n",
    "    Q = np.clip(Q, epsilon, 1. - epsilon)\n",
    "    \n",
    "    return -np.sum(P * np.log(Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification\n",
    "\n",
    "Let's test the function with the example from Exercise A3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_banana = np.array([0, 1, 0])\n",
    "Q_banana = np.array([0.2, 0.5, 0.3])\n",
    "\n",
    "loss = cross_entropy(P_banana, Q_banana)\n",
    "print(f\"Calculated Loss: {loss:.3f}\")\n",
    "print(f\"Expected Loss (-ln(0.5)): {-np.log(0.5):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizing BCE vs. MSE Loss\n",
    "\n",
    "This plot, from Exercise B2, is crucial for understanding why Cross-Entropy is preferred over Mean Squared Error for classification. It shows how each loss function penalizes incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities for the correct class (where true label y=1)\n",
    "p_hat = np.linspace(0.01, 0.99, 200)\n",
    "\n",
    "# Binary Cross-Entropy Loss for y=1 is -log(p_hat)\n",
    "bce_loss = -np.log(p_hat)\n",
    "\n",
    "# Mean Squared Error Loss for y=1 is (1-p_hat)^2\n",
    "mse_loss = (1 - p_hat)**2\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.plot(p_hat, bce_loss, label='Binary Cross-Entropy Loss', color='darkred', lw=2.5)\n",
    "plt.plot(p_hat, mse_loss, label='Mean Squared Error Loss', color='darkblue', lw=2.5, linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Predicted Probability for Correct Class (p\u0302)\", fontsize=12)\n",
    "plt.ylabel(\"Loss Value\", fontsize=12)\n",
    "plt.title(\"BCE vs. MSE Loss (When True Label is 1)\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.ylim(0, 5) # Limit y-axis to better see the shapes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the Plot\n",
    "\n",
    "1.  **When the prediction is good (p\u0302 \u2192 1)**: Both losses approach 0.\n",
    "2.  **When the prediction is bad (p\u0302 \u2192 0)**:\n",
    "    -   **Cross-Entropy** shoots up towards infinity. This provides a large gradient for the model to learn from its mistake.\n",
    "    -   **MSE** flattens out. The gradient becomes very small, meaning the model learns very slowly from its most confident mistakes. This is the primary reason MSE is a poor choice for classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}