<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning Tutorials | ML Fundamentals</title>
    <meta name="description" content="Comprehensive machine learning tutorials with entropy perspective, from probability to VAEs and neural networks.">
    
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Playfair+Display:wght@400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}, {left: '\\\\[', right: '\\\\]', display: true}, {left: '\\\\(', right: '\\\\)', display: false}], throwOnError: false});"></script>
    
    <!-- Styles -->
    <link rel="stylesheet" href="../../css/main.css">
    <link rel="stylesheet" href="../../css/components.css">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>‚àû</text></svg>">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar" id="navbar">
        <div class="nav-container">
            <a href="../../index.html" class="nav-logo">
                <span class="logo-symbol">‚àá</span>
                <span class="logo-text">ML Fundamentals</span>
            </a>
            
            <button class="nav-toggle" id="navToggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            
            <div class="nav-menu" id="navMenu">
                <div class="nav-links">
                    <div class="nav-dropdown">
                        <button class="nav-link dropdown-trigger">
                            Tutorials <span class="dropdown-arrow">‚ñæ</span>
                        </button>
                        <div class="dropdown-content">
                            <a href="../ml/index.html" class="active">Machine Learning</a>
                            <a href="../linear-algebra/index.html">Linear Algebra</a>
                            <a href="../calculus/index.html">Calculus</a>
                            <a href="../physics/index.html">Physics</a>
                        </div>
                    </div>
                    <a href="../../index.html#philosophy" class="nav-link">Philosophy</a>
                    <a href="../../index.html#roadmap" class="nav-link">Roadmap</a>
                    <a href="https://github.com/ml-entropy/ml-entropy.github.io" class="nav-link" target="_blank">GitHub</a>
                </div>
                
                <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
                    <svg class="sun-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <circle cx="12" cy="12" r="5"/>
                        <path d="M12 1v2M12 21v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M1 12h2M21 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42"/>
                    </svg>
                    <svg class="moon-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                    </svg>
                </button>
            </div>
        </div>
    </nav>

    <!-- Header -->
    <header class="tutorial-header">
        <div class="container">
            <nav class="breadcrumb">
                <a href="../../index.html">Home</a>
                <span class="breadcrumb-separator">‚Üí</span>
                <span>Machine Learning</span>
            </nav>
            
            <h1>Machine Learning Tutorials</h1>
            <p class="lead">
                A comprehensive journey through machine learning from an information-theoretic perspective. 
                Every formula derived, every concept visualized.
            </p>
            
            <div class="featured-equation" style="margin-top: 2rem;">
                $$H(X) = -\sum_{x \in \mathcal{X}} p(x) \log_2 p(x)$$
            </div>
        </div>
    </header>

    <!-- Tutorial List -->
    <main class="tutorial-list">
        <div class="container">
            <!-- Foundations -->
            <h2 style="margin-bottom: 1.5rem; font-size: 1.25rem; color: var(--color-text-secondary);">
                Part I: Foundations
            </h2>
            
            <a href="00-probability/index.html" class="tutorial-item">
                <div class="tutorial-number">00</div>
                <div class="tutorial-content">
                    <h3>Probability Concepts for ML</h3>
                    <p>P(X), P(Y|X), Bayes theorem, priors, posteriors, likelihood. The foundation of all ML.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Exercises</span>
                        <span>‚è± ~45 min</span>
                    </div>
                </div>
            </a>
            
            <a href="01-entropy/index.html" class="tutorial-item">
                <div class="tutorial-number">01</div>
                <div class="tutorial-content">
                    <h3>Information Entropy</h3>
                    <p>Shannon entropy, information content, optimal coding, Huffman encoding. Why entropy measures surprise.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Code + Exercises</span>
                        <span>‚è± ~60 min</span>
                    </div>
                </div>
            </a>
            
            <a href="02-kl-divergence/index.html" class="tutorial-item">
                <div class="tutorial-number">02</div>
                <div class="tutorial-content">
                    <h3>KL Divergence</h3>
                    <p>Relative entropy for discrete and continuous distributions. Cross-entropy loss explained.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Derivations + Code</span>
                        <span>‚è± ~75 min</span>
                    </div>
                </div>
            </a>
            
            <a href="03-distributions/index.html" class="tutorial-item">
                <div class="tutorial-number">03</div>
                <div class="tutorial-content">
                    <h3>Probability Distributions</h3>
                    <p>PDF, CDF, expectation, variance. Normal and multivariate normal distributions in depth.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Visualizations + Code</span>
                        <span>‚è± ~60 min</span>
                    </div>
                </div>
            </a>
            
            <a href="04-logarithms/index.html" class="tutorial-item">
                <div class="tutorial-number">04</div>
                <div class="tutorial-content">
                    <h3>Logarithms in ML</h3>
                    <p>Why we use log-likelihood. Is it just numerical stability or something fundamental?</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Proofs</span>
                        <span>‚è± ~45 min</span>
                    </div>
                </div>
            </a>
            
            <a href="05-combinatorics/index.html" class="tutorial-item">
                <div class="tutorial-number">05</div>
                <div class="tutorial-content">
                    <h3>Combinatorics</h3>
                    <p>Permutations, combinations, and why they appear everywhere in probability.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Formula Derivations</span>
                        <span>‚è± ~40 min</span>
                    </div>
                </div>
            </a>
            
            <!-- Advanced -->
            <h2 style="margin: 3rem 0 1.5rem; font-size: 1.25rem; color: var(--color-text-secondary);">
                Part II: Deep Learning
            </h2>
            
            <a href="06-backpropagation/index.html" class="tutorial-item">
                <div class="tutorial-number">06</div>
                <div class="tutorial-content">
                    <h3>Backpropagation</h3>
                    <p>Chain rule, computational graphs, gradient flow. Connection between entropy and backprop.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Code + Exercises</span>
                        <span>‚è± ~90 min</span>
                    </div>
                </div>
            </a>
            
            <a href="07-regularization/index.html" class="tutorial-item">
                <div class="tutorial-number">07</div>
                <div class="tutorial-content">
                    <h3>Regularization</h3>
                    <p>L1, L2, dropout, weight decay. The Bayesian interpretation of regularization.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Code + Exercises</span>
                        <span>‚è± ~60 min</span>
                    </div>
                </div>
            </a>
            
            <a href="08-batch-normalization/index.html" class="tutorial-item">
                <div class="tutorial-number">08</div>
                <div class="tutorial-content">
                    <h3>Batch Normalization</h3>
                    <p>Internal covariate shift, running statistics, layer norm variants.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Code + Exercises</span>
                        <span>‚è± ~50 min</span>
                    </div>
                </div>
            </a>
            
            <a href="09-learning-rate/index.html" class="tutorial-item">
                <div class="tutorial-number">09</div>
                <div class="tutorial-content">
                    <h3>Learning Rate</h3>
                    <p>Gradient descent dynamics, schedulers, warmup, cyclical learning rates.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Visualizations + Code</span>
                        <span>‚è± ~45 min</span>
                    </div>
                </div>
            </a>
            
            <a href="10-cnn/index.html" class="tutorial-item">
                <div class="tutorial-number">10</div>
                <div class="tutorial-content">
                    <h3>Convolutional Neural Networks</h3>
                    <p>Convolutions, pooling, feature maps. Why CNNs work for images.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Code + Exercises</span>
                        <span>‚è± ~75 min</span>
                    </div>
                </div>
            </a>
            
            <a href="11-rnn/index.html" class="tutorial-item">
                <div class="tutorial-number">11</div>
                <div class="tutorial-content">
                    <h3>Recurrent Neural Networks</h3>
                    <p>Sequence modeling, BPTT, LSTMs, GRUs. The vanishing gradient problem.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Code + Exercises</span>
                        <span>‚è± ~75 min</span>
                    </div>
                </div>
            </a>
            
            <!-- Generative Models -->
            <h2 style="margin: 3rem 0 1.5rem; font-size: 1.25rem; color: var(--color-text-secondary);">
                Part III: Generative Models
            </h2>
            
            <a href="12-vae/index.html" class="tutorial-item">
                <div class="tutorial-number">12</div>
                <div class="tutorial-content">
                    <h3>Variational Autoencoders</h3>
                    <p>VAE architecture, ELBO derivation, reparameterization trick. Why KL loss on latent space.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Full Derivation + Code</span>
                        <span>‚è± ~90 min</span>
                    </div>
                </div>
            </a>
            
            <a href="13-variational-inference/index.html" class="tutorial-item">
                <div class="tutorial-number">13</div>
                <div class="tutorial-content">
                    <h3>Variational Inference</h3>
                    <p>Approximating intractable posteriors. Mean-field approximation. Connection to EM algorithm.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Derivations</span>
                        <span>‚è± ~75 min</span>
                    </div>
                </div>
            </a>
        </div>
    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-brand">
                    <span class="logo-symbol">‚àá</span>
                    <span>ML Fundamentals</span>
                </div>
                <p class="footer-tagline">Deep understanding through first principles.</p>
            </div>
            <div class="footer-links">
                <a href="../../index.html">Home</a>
                <a href="https://github.com/ml-entropy/ml-entropy.github.io" target="_blank">GitHub</a>
            </div>
        </div>
    </footer>

    <!-- Scripts -->
    <script src="../../js/main.js"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            if (typeof renderMathInElement === 'function') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
    </script>
</body>
</html>
