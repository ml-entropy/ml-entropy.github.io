<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Weighted FSTs and Algorithms | ML Fundamentals</title>
    <meta name="description" content="Adding weights to Finite State Transducers: semirings, shortest path, determinization, weight pushing, and weighted composition for probabilistic reasoning.">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Playfair+Display:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}, {left: '\\\\[', right: '\\\\]', display: true}, {left: '\\\\(', right: '\\\\)', display: false}], throwOnError: false});"></script>

    <!-- Styles -->
    <link rel="stylesheet" href="../../../css/main.css">
    <link rel="stylesheet" href="../../../css/components.css">
    <link rel="stylesheet" href="../../../css/sidebar.css">

    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>&#x221E;</text></svg>">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar" id="navbar">
        <div class="nav-container">
            <a href="../../../index.html" class="nav-logo">
                <span class="logo-symbol">&nabla;</span>
                <span class="logo-text">ML Fundamentals</span>
            </a>

            <button class="nav-toggle" id="navToggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>

            <div class="nav-menu" id="navMenu">
                <div class="nav-links">
                    <a href="../../../tutorials/ml/index.html" class="nav-link active">Machine Learning</a>
                    <a href="../../../tutorials/linear-algebra/index.html" class="nav-link">Linear Algebra</a>
                    <a href="../../../tutorials/calculus/index.html" class="nav-link">Calculus</a>
                    <a href="../../../tutorials/physics/index.html" class="nav-link">Physics</a>
                    <a href="../../../index.html#philosophy" class="nav-link">Philosophy</a>
                    <a href="../../../index.html#roadmap" class="nav-link">Roadmap</a>
                    <a href="https://github.com/ml-entropy/ml-entropy.github.io" class="nav-link" target="_blank">GitHub</a>
                </div>

                <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
                    <svg class="sun-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <circle cx="12" cy="12" r="5"/>
                        <path d="M12 1v2M12 21v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M1 12h2M21 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42"/>
                    </svg>
                    <svg class="moon-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                    </svg>
                </button>
            </div>
        </div>
    </nav>

    <!-- Tutorial Header -->
    <header class="tutorial-content-header">
        <div class="container">
            <nav class="breadcrumb">
                <a href="../../../index.html">Home</a>
                <span class="breadcrumb-separator">&rarr;</span>
                <a href="../index.html">Machine Learning</a>
                <span class="breadcrumb-separator">&rarr;</span>
                <span>Weighted FSTs</span>
            </nav>

            <div class="tutorial-tabs">
                <a href="#theory" class="tutorial-tab active">Theory</a>
                <a href="#code" class="tutorial-tab">Code</a>
                <a href="#exercises" class="tutorial-tab">Exercises</a>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    <div class="tutorial-wrapper">

        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <!-- Sidebar Navigation -->
        <aside class="tutorial-sidebar">
            <div class="sidebar-section">
                <h3 class="sidebar-section-title">Machine Learning</h3>
                <nav class="sidebar-nav">
                        <a href="../00-probability/index.html" class="sidebar-link">00. Probability Foundations</a>
                    <a href="../04-logarithms/index.html" class="sidebar-link">01. Why Logarithms?</a>
                    <a href="../05-combinatorics/index.html" class="sidebar-link">02. Combinatorics</a>
                    <a href="../03-distributions/index.html" class="sidebar-link">03. Normal Distributions</a>
                    <a href="../01-entropy/index.html" class="sidebar-link">04. Entropy Fundamentals</a>
                    <a href="../02-cross-entropy/index.html" class="sidebar-link">05. Cross-Entropy</a>
                    <a href="../02-kl-divergence/index.html" class="sidebar-link">06. KL Divergence</a>
                    <a href="../14-entropy-connections/index.html" class="sidebar-link">07. Entropy Connections</a>
                    <a href="../06-backpropagation/index.html" class="sidebar-link">08. Backpropagation</a>
                    <a href="../07-regularization/index.html" class="sidebar-link">09. Regularization</a>
                    <a href="../08-batch-normalization/index.html" class="sidebar-link">10. Batch Normalization</a>
                    <a href="../09-learning-rate/index.html" class="sidebar-link">11. Learning Rate</a>
                    <a href="../10-cnn/index.html" class="sidebar-link">12. CNNs</a>
                    <a href="../11-rnn/index.html" class="sidebar-link">13. RNNs</a>
                    <a href="../15-autoencoder/index.html" class="sidebar-link">14. Autoencoders</a>
                    <a href="../13-variational-inference/index.html" class="sidebar-link">15. Variational Inference</a>
                    <a href="../12-vae/index.html" class="sidebar-link">16. VAE</a>
                    <a href="../16-inductive-bias/index.html" class="sidebar-link">17. Inductive Bias</a>
                    <a href="../17-architectural-biases/index.html" class="sidebar-link">18. Architectural Biases</a>
                    <a href="../18-designing-biases/index.html" class="sidebar-link">19. Designing Biases</a>
                    <a href="../19-fst-fundamentals/index.html" class="sidebar-link">20. FST Fundamentals</a>
                    <a href="../20-weighted-fsts/index.html" class="sidebar-link active">21. Weighted FSTs</a>
                    <a href="../21-fst-libraries/index.html" class="sidebar-link">22. FST Libraries</a>
                    <a href="../22-fst-applications/index.html" class="sidebar-link">23. FST Applications</a>
                    <a href="../23-neural-symbolic/index.html" class="sidebar-link">24. Neural-Symbolic Hybrids</a>
                    <a href="../24-sequence-alignment/index.html" class="sidebar-link">25. Sequence Alignment</a>
                    <a href="../25-mas-algorithm/index.html" class="sidebar-link">26. MAS Algorithm</a>
                    <a href="../26-forced-alignment/index.html" class="sidebar-link">27. Forced Alignment & MFA</a>
                </nav>
            </div>
            
            <div class="sidebar-section" style="margin-top: 2rem;">
                <h3 class="sidebar-section-title">Related Subjects</h3>
                <nav class="sidebar-nav">
                        <a href="../../linear-algebra/index.html" class="sidebar-link">Linear Algebra</a>
                    <a href="../../calculus/index.html" class="sidebar-link">Calculus</a>
                    <a href="../../physics/index.html" class="sidebar-link">Physics</a>
                </nav>
            </div>
        </aside>

        <!-- Main Article -->
        <main class="tutorial-main">

            <!-- ==================== THEORY TAB ==================== -->
            <article class="article-content" id="theory">

                <!-- Section 1: Why Weighted FSTs? -->
                <h2 id="motivation">Why Weighted FSTs?</h2>

                <p>
                    In Tutorial 20, we built FSTs that perform deterministic transformations: given an input, an FST either produces an output or rejects the input. But many real-world problems require more than binary accept/reject decisions. We need to <strong>rank</strong> alternative outputs, assign <strong>costs</strong> to transformations, or model <strong>probabilities</strong> over possible paths.
                </p>

                <p>
                    Consider speech recognition. When someone says "I scream," an unweighted FST might produce both "I scream" and "ice cream" as valid outputs &mdash; but it cannot tell you which is more likely. A <strong>Weighted FST</strong> (WFST) assigns a numerical score to each path, allowing the system to rank "ice cream" higher in the context of a dessert menu and "I scream" higher in a horror movie script.
                </p>

                <p><strong>Concrete scenarios where weights are essential:</strong></p>
                <ul>
                    <li><strong>Acoustic modeling:</strong> The probability that a given sound wave corresponds to phoneme /k/ vs /g/ is not binary &mdash; it is a continuous score. WFSTs encode these scores on transitions.</li>
                    <li><strong>Spell correction:</strong> "teh" could be corrected to "the" (one transposition, cost 1) or "ten" (one substitution, cost 1) or "tea" (two edits, cost 2). Weights let us prefer lower-cost corrections.</li>
                    <li><strong>Machine translation:</strong> Multiple translations exist for a sentence, each with a different probability. WFSTs rank them.</li>
                    <li><strong>Phonetic dictionaries:</strong> A word may have multiple pronunciations, each with a different frequency. WFSTs encode the probability of each pronunciation variant.</li>
                </ul>

                <div class="note-box">
                    <div class="box-title">From Binary to Graded</div>
                    <p style="margin-bottom: 0;">
                        Unweighted FSTs compute <em>relations</em>: sets of (input, output) pairs. Weighted FSTs compute <em>weighted relations</em>: each (input, output) pair has an associated weight. This single extension &mdash; adding a number to each transition &mdash; transforms FSTs from logical devices into algebraic ones, opening the door to optimization, probabilistic reasoning, and learning.
                    </p>
                </div>

                <!-- Section 2: Semirings -->
                <h2 id="semirings">Semirings</h2>

                <p>
                    Before defining weighted FSTs, we need to understand the algebraic structure that governs how weights combine. Different applications need different notions of "adding" and "multiplying" weights. The unifying concept is the <strong>semiring</strong>.
                </p>

                <div class="definition-box">
                    <div class="box-title">Semiring</div>
                    <p>A <strong>semiring</strong> is a 5-tuple $(K, \oplus, \otimes, \bar{0}, \bar{1})$ where:</p>
                    <ul>
                        <li>$K$ is a set of weights</li>
                        <li>$\oplus: K \times K \to K$ is the <strong>additive operation</strong> (combines weights of parallel paths)</li>
                        <li>$\otimes: K \times K \to K$ is the <strong>multiplicative operation</strong> (combines weights along a path)</li>
                        <li>$\bar{0} \in K$ is the <strong>additive identity</strong>: $a \oplus \bar{0} = a$ for all $a$</li>
                        <li>$\bar{1} \in K$ is the <strong>multiplicative identity</strong>: $a \otimes \bar{1} = a$ for all $a$</li>
                    </ul>
                    <p style="margin-bottom: 0;"><strong>Axioms:</strong> $(K, \oplus, \bar{0})$ is a commutative monoid, $(K, \otimes, \bar{1})$ is a monoid, $\otimes$ distributes over $\oplus$, and $\bar{0}$ is an annihilator for $\otimes$: $a \otimes \bar{0} = \bar{0} \otimes a = \bar{0}$.</p>
                </div>

                <p>
                    The key intuition: $\otimes$ combines weights <em>sequentially</em> (along a single path), while $\oplus$ combines weights of <em>alternative</em> paths (multiple paths between the same input/output pair). Different choices of $\oplus$ and $\otimes$ give different semirings suited to different problems.
                </p>

                <p><strong>The most important semirings in practice:</strong></p>

                <div class="math-derivation">
                    <div class="math-derivation-title">Common Semirings</div>

                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            <p><strong>Tropical Semiring</strong> $(\mathbb{R}_{\geq 0} \cup \{+\infty\}, \min, +, +\infty, 0)$</p>
                            <div class="math-block">
                                $$a \oplus b = \min(a, b), \quad a \otimes b = a + b$$
                            </div>
                            <p>Path weight = sum of edge costs. Total weight = minimum over all paths. Used for <strong>shortest path</strong> problems.</p>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            <p><strong>Log Semiring</strong> $(\mathbb{R} \cup \{+\infty\}, \oplus_{\log}, +, +\infty, 0)$ where:</p>
                            <div class="math-block">
                                $$a \oplus_{\log} b = -\log(e^{-a} + e^{-b})$$
                            </div>
                            <p>Equivalent to working with negative log-probabilities. The $\oplus_{\log}$ operation adds probabilities in log-space (log-sum-exp). Used for <strong>probabilistic models</strong> where you need the total probability over all paths.</p>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            <p><strong>Boolean Semiring</strong> $(\{\text{true}, \text{false}\}, \lor, \land, \text{false}, \text{true})$</p>
                            <div class="math-block">
                                $$a \oplus b = a \lor b, \quad a \otimes b = a \land b$$
                            </div>
                            <p>This is the "unweighted" case: a path either exists (true) or doesn't (false). Ordinary FSTs are WFSTs over the boolean semiring.</p>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">4</div>
                        <div class="math-step-content">
                            <p><strong>Real (Probability) Semiring</strong> $(\mathbb{R}_{\geq 0}, +, \times, 0, 1)$</p>
                            <div class="math-block">
                                $$a \oplus b = a + b, \quad a \otimes b = a \times b$$
                            </div>
                            <p>Path weight = product of transition probabilities. Total weight = sum over all paths. Directly models probabilities, but numerically unstable for long paths (underflow). The log semiring solves this.</p>
                        </div>
                    </div>
                </div>

                <div class="note-box">
                    <div class="box-title">Why the Choice of Semiring Matters in Practice</div>
                    <p style="margin-bottom: 0;">
                        The semiring determines what "best" means. The <strong>tropical semiring</strong> finds the lowest-cost path (shortest path). The <strong>log semiring</strong> computes the total probability of all paths (marginalization). The <strong>boolean semiring</strong> just checks reachability. The <strong>real semiring</strong> sums probabilities directly but risks underflow. Choosing the wrong semiring gives you the wrong answer: if you use the tropical semiring when you need total probability, you get only the single best path's probability instead of the sum over all paths. If you use the log semiring when you need the single best path, you get a combined score that does not correspond to any individual path.
                    </p>
                </div>

                <div class="math-derivation">
                    <div class="math-derivation-title">Why the Tropical Semiring for Shortest Paths</div>

                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            <p>Consider a WFST with two paths $\pi_1$ and $\pi_2$ from input $x$ to output $y$.</p>
                            <p>Path $\pi_1$ has edges with costs $c_1, c_2, c_3$. Path $\pi_2$ has edges with costs $d_1, d_2$.</p>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            <p>Weight of $\pi_1$: $c_1 \otimes c_2 \otimes c_3 = c_1 + c_2 + c_3$ (sum of costs along path).</p>
                            <p>Weight of $\pi_2$: $d_1 \otimes d_2 = d_1 + d_2$.</p>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            <p>Total weight for $(x, y)$:</p>
                            <div class="math-block">
                                $$w(\pi_1) \oplus w(\pi_2) = \min(c_1 + c_2 + c_3, \; d_1 + d_2)$$
                            </div>
                            <p>This is exactly the shortest path: the minimum total cost among all paths mapping $x$ to $y$.</p>
                        </div>
                    </div>
                </div>

                <!-- Section 3: Weighted FST Definition -->
                <h2 id="wfst-definition">Weighted FST Definition</h2>

                <p>
                    Now we can formally define a weighted FST by extending the unweighted definition from Tutorial 20 with a weight function that assigns a semiring element to each transition.
                </p>

                <div class="definition-box">
                    <div class="box-title">Weighted Finite State Transducer</div>
                    <p>A <strong>Weighted FST</strong> over semiring $(K, \oplus, \otimes, \bar{0}, \bar{1})$ is a tuple $T = (Q, \Sigma, \Gamma, \delta, \lambda, \rho, q_0, F)$ where:</p>
                    <ul>
                        <li>$Q$ is a finite set of <strong>states</strong></li>
                        <li>$\Sigma$ is a finite <strong>input alphabet</strong></li>
                        <li>$\Gamma$ is a finite <strong>output alphabet</strong></li>
                        <li>$\delta \subseteq Q \times (\Sigma \cup \{\varepsilon\}) \times (\Gamma \cup \{\varepsilon\}) \times K \times Q$ is the <strong>weighted transition relation</strong></li>
                        <li>$\lambda: Q \to K$ assigns an <strong>initial weight</strong> to each state (often $\bar{1}$ for $q_0$ and $\bar{0}$ for all others)</li>
                        <li>$\rho: Q \to K$ assigns a <strong>final weight</strong> to each state</li>
                        <li>$q_0 \in Q$ is the <strong>start state</strong></li>
                        <li>$F \subseteq Q$ is the set of <strong>final states</strong></li>
                    </ul>
                    <p style="margin-bottom: 0;">Each transition $(q, a, b, w, q')$ means: "In state $q$, read input $a$, output $b$, with weight $w \in K$, and move to state $q'$."</p>
                </div>

                <p>
                    The weight of a single <strong>path</strong> $\pi = t_1 t_2 \cdots t_n$ through the WFST is the product (using $\otimes$) of all transition weights along the path, including the initial weight of the start state and the final weight of the ending state:
                </p>

                <div class="math-derivation">
                    <div class="math-derivation-title">Computing Path and Total Weights</div>

                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            <p>The <strong>weight of a path</strong> $\pi = t_1 t_2 \cdots t_n$ is:</p>
                            <div class="math-block">
                                $$w(\pi) = \lambda(q_{\text{start}}) \otimes w(t_1) \otimes w(t_2) \otimes \cdots \otimes w(t_n) \otimes \rho(q_{\text{end}})$$
                            </div>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            <p>If multiple paths $\pi_1, \pi_2, \ldots, \pi_m$ all map input $x$ to output $y$, the <strong>total weight</strong> is:</p>
                            <div class="math-block">
                                $$W(x, y) = \bigoplus_{i=1}^{m} w(\pi_i) = w(\pi_1) \oplus w(\pi_2) \oplus \cdots \oplus w(\pi_m)$$
                            </div>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            <p><strong>Example (Tropical):</strong> Two paths with weights $w(\pi_1) = 2 + 3 + 1 = 6$ and $w(\pi_2) = 4 + 1 = 5$.</p>
                            <div class="math-block">
                                $$W(x, y) = \min(6, 5) = 5$$
                            </div>
                            <p>The best (shortest) path has total cost 5.</p>
                        </div>
                    </div>
                </div>

                <p>
                    A WFST defines a <strong>weighted relation</strong>: a function from $\Sigma^* \times \Gamma^*$ to $K$, mapping each (input, output) pair to a weight. This is the weighted generalization of the binary relation computed by an unweighted FST.
                </p>

                <!-- Section 4: Shortest Path Algorithm -->
                <h2 id="shortest-path">Shortest Path Algorithm</h2>

                <p>
                    The most fundamental algorithm on WFSTs is <strong>shortest path</strong>: given a WFST (in the tropical semiring), find the path with the lowest total weight. This is how speech recognizers find the most likely transcription and how spell checkers find the nearest correction.
                </p>

                <div class="math-derivation">
                    <div class="math-derivation-title">Shortest Path via Dijkstra on WFSTs</div>

                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            <p><strong>Setup:</strong> Given a WFST over the tropical semiring, we seek a path $\pi^*$ such that:</p>
                            <div class="math-block">
                                $$\pi^* = \arg\min_{\pi \in \text{Paths}(q_0 \to F)} w(\pi)$$
                            </div>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            <p><strong>Algorithm:</strong> Dijkstra's algorithm adapted for WFSTs. Initialize $d(q_0) = \bar{1} = 0$, $d(q) = \bar{0} = +\infty$ for all $q \neq q_0$. Use a priority queue.</p>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            <p><strong>Relaxation:</strong> For each transition $(q, a, b, w, q')$:</p>
                            <div class="math-block">
                                $$\text{if } d(q) + w < d(q'), \text{ then } d(q') \leftarrow d(q) + w$$
                            </div>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">4</div>
                        <div class="math-step-content">
                            <p><strong>Epsilon handling:</strong> Unlike standard Dijkstra on a labeled graph, FST Dijkstra must follow $\varepsilon$-transitions without consuming input. The pseudocode differs as follows:</p>
                            <pre style="background: var(--color-surface); padding: 1rem; border-radius: 6px; font-size: 0.9em; overflow-x: auto;"><code>DIJKSTRA-FST(T, q0, F):
  d[q0] = 0; d[q] = inf for all q != q0
  PQ = {(0, q0)}; prev = {}
  while PQ is not empty:
    (cost, q) = PQ.extract_min()
    if cost > d[q]: continue        // stale entry
    if q in F:
      return cost + rho(q), reconstruct(prev, q)
    for each (q, a, b, w, q') in delta:
      // a may be epsilon -- no input consumed
      if d[q] + w < d[q']:
        d[q'] = d[q] + w
        prev[q'] = (q, a, b)
        PQ.insert((d[q'], q'))
  return inf, null                   // no path found</code></pre>
                            <p>The key difference from standard Dijkstra: transitions with $a = \varepsilon$ are relaxed identically to non-epsilon transitions, but the input position does not advance. This means a single "step" in the algorithm may traverse multiple epsilon arcs before consuming the next input symbol.</p>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">5</div>
                        <div class="math-step-content">
                            <p><strong>Termination:</strong> When a final state $q_f \in F$ is popped from the priority queue, the shortest path weight is $d(q_f) + \rho(q_f)$. Backtrack to reconstruct the path and read off the (input, output) pair.</p>
                        </div>
                    </div>
                </div>

                <div class="note-box">
                    <div class="box-title">FST Dijkstra Requires Acyclic Graphs or Non-Negative Weights</div>
                    <p style="margin-bottom: 0;">
                        Dijkstra's algorithm on WFSTs is only correct when the underlying graph is acyclic or all weights are non-negative in the tropical semiring. If the WFST contains cycles with negative total weight, Dijkstra can return incorrect results (just as with standard shortest-path graphs). For WFSTs with negative weights, use the Bellman-Ford algorithm instead, or ensure $\varepsilon$-cycles have been removed. In practice, most WFSTs in speech and NLP applications use non-negative costs (e.g., $-\log p \geq 0$), so Dijkstra applies directly.
                    </p>
                </div>

                <p><strong>Example: Finding the Best Pronunciation</strong></p>
                <p>
                    Suppose we have a WFST representing a phonetic dictionary. The word "read" has two pronunciations:
                </p>
                <ul>
                    <li>Path $\pi_1$: "read" $\to$ /r iy d/ with weight 0.3 (present tense, more common)</li>
                    <li>Path $\pi_2$: "read" $\to$ /r eh d/ with weight 0.7 (past tense, less common in isolation)</li>
                </ul>
                <p>
                    In the tropical semiring (lower weight = better), the shortest path algorithm returns /r iy d/ as the best pronunciation with cost 0.3. The $n$-shortest paths algorithm can return both, ranked by weight.
                </p>

                <div class="note-box">
                    <div class="box-title">Complexity</div>
                    <p style="margin-bottom: 0;">
                        Dijkstra's algorithm on a WFST runs in $O(|E| \log |Q|)$ time where $|E|$ is the number of transitions and $|Q|$ the number of states. For the $n$-shortest paths (finding the top-$n$ best outputs), the complexity is $O(|E| + n \cdot |Q| \log |Q|)$. Both are efficient enough for real-time speech recognition.
                    </p>
                </div>

                <!-- Section 5: Determinization & Minimization -->
                <h2 id="determinization">Determinization &amp; Minimization</h2>

                <p>
                    Just as with unweighted FSTs, we want to optimize WFSTs for efficiency. The three key operations are <strong>epsilon removal</strong>, <strong>determinization</strong>, and <strong>minimization</strong>. However, the weighted case introduces complications that do not arise in the unweighted setting.
                </p>

                <div class="warning-box">
                    <div class="box-title">Not All WFSTs Are Determinizable</div>
                    <p style="margin-bottom: 0;">
                        Unlike unweighted finite automata (where every NFA has an equivalent DFA), not every weighted transducer has a deterministic equivalent. A WFST is determinizable if and only if it satisfies the <strong>twins property</strong>: for any two states $p, q$ reachable by the same input with the same residual weight, the suffixes from $p$ and $q$ must be compatible. When determinization is not possible, we can still apply epsilon removal and weight pushing to partially optimize the WFST.
                    </p>
                </div>

                <div class="definition-box">
                    <div class="box-title">The Twins Property</div>
                    <p>Two states $p, q$ in a WFST are <strong>twins</strong> if for every string $w$, if both $p$ and $q$ can reach a final state on $w$, then they produce the same residual output string.</p>
                    <p style="margin-bottom: 0;">A WFST is <strong>determinizable</strong> if and only if it has the twins property. Intuitively, twins are states that "behave identically in the future" with respect to output. If a WFST has two states reachable by the same input that disagree on future outputs, the determinizer cannot merge them into a single deterministic state, and determinization fails (or produces an infinite transducer).</p>
                </div>

                <p><strong>Epsilon Removal:</strong> Transitions with $\varepsilon$ on input or output complicate many algorithms. Epsilon removal replaces $\varepsilon$-transitions with equivalent direct transitions by computing the $\varepsilon$-closure of each state. In the weighted case, the weights of the removed $\varepsilon$-transitions are folded into the replacement transitions using $\otimes$.</p>

                <p><strong>Weight Pushing:</strong> Redistributes weights along paths so that they are concentrated toward the start state. This does not change the total weight of any path, but it enables more effective determinization and minimization.</p>

                <div class="math-derivation">
                    <div class="math-derivation-title">Weight Pushing</div>

                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            <p>For each state $q$, compute the <strong>shortest distance</strong> to any final state:</p>
                            <div class="math-block">
                                $$d(q) = \bigoplus_{\pi: q \to F} w(\pi)$$
                            </div>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            <p>For each transition $(q, a, b, w, q')$, the <strong>pushed weight</strong> is:</p>
                            <div class="math-block">
                                $$w' = d(q)^{-1} \otimes w \otimes d(q')$$
                            </div>
                            <p>(In the tropical semiring: $w' = w + d(q') - d(q)$.)</p>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            <p>Update the initial weight: $\lambda'(q_0) = \lambda(q_0) \otimes d(q_0)$.</p>
                            <p>Update the final weights: $\rho'(q_f) = d(q_f)^{-1} \otimes \rho(q_f)$.</p>
                        </div>
                    </div>
                </div>

                <p>
                    <strong>Minimization:</strong> After determinization and weight pushing, we can minimize the WFST by merging states that are equivalent (same future behavior and same weights). The minimized WFST has the fewest states of any equivalent deterministic WFST, leading to faster runtime and smaller memory footprint.
                </p>

                <div class="note-box">
                    <div class="box-title">The Optimization Pipeline</div>
                    <p style="margin-bottom: 0;">
                        The standard optimization pipeline for WFSTs is: (1) Epsilon Removal, (2) Determinization, (3) Weight Pushing, (4) Minimization. This sequence, when applicable, produces the smallest equivalent deterministic WFST. In speech recognition, this pipeline can reduce a WFST from millions of states to thousands.
                    </p>
                </div>

                <!-- Section 6: Weighted Composition -->
                <h2 id="composition-revisited">Weighted Composition</h2>

                <p>
                    In Tutorial 20, we learned that composition chains two FSTs: $T_1 \circ T_2$ maps input directly to output by feeding $T_1$'s output as $T_2$'s input. Weighted composition extends this by multiplying weights: the weight of a composed transition is the $\otimes$-product of the weights from $T_1$ and $T_2$.
                </p>

                <div class="definition-box">
                    <div class="box-title">Weighted Composition</div>
                    <p>Given WFSTs $T_1$ and $T_2$ over the same semiring $(K, \oplus, \otimes, \bar{0}, \bar{1})$:</p>
                    <p>For each pair of transitions $(q_1, a, b, w_1, q_1') \in T_1$ and $(q_2, b, c, w_2, q_2') \in T_2$ that match on the intermediate symbol $b$:</p>
                    <div class="math-block">
                        $$(q_1, q_2) \xrightarrow{a:c \;/\; w_1 \otimes w_2} (q_1', q_2')$$
                    </div>
                    <p style="margin-bottom: 0;">The composed transition reads $a$, outputs $c$, and has weight $w_1 \otimes w_2$. The intermediate symbol $b$ is consumed internally.</p>
                </div>

                <p><strong>Example: Cascade of Probabilistic Transducers</strong></p>
                <p>
                    Consider a simple speech recognition pipeline with two WFSTs:
                </p>
                <ul>
                    <li>$T_1$ (acoustic model): maps audio features to phonemes with probability weights. For instance, feature vector $f$ maps to /k/ with weight 0.8 and to /g/ with weight 0.2.</li>
                    <li>$T_2$ (pronunciation model): maps phonemes to words. /k ae t/ maps to "cat" with weight 0.9 and /k ae t/ maps to "kat" with weight 0.1.</li>
                </ul>
                <p>
                    The composed WFST $T_1 \circ T_2$ maps audio features directly to words. The weight of the path $f \to$ /k/ $\to$ "cat" is $0.8 \times 0.9 = 0.72$ in the probability semiring. The total weight for "cat" sums over all paths: if there are other paths leading to "cat" (through different phoneme sequences), their probabilities are added.
                </p>

                <div class="math-derivation">
                    <div class="math-derivation-title">Composition with Weights: Step by Step</div>

                    <div class="math-step">
                        <div class="math-step-number">1</div>
                        <div class="math-step-content">
                            <p>$T_1$: State $s_0 \xrightarrow{f_1:\text{/k/} \;/\; 0.8} s_1$ and $s_0 \xrightarrow{f_1:\text{/g/} \;/\; 0.2} s_2$.</p>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">2</div>
                        <div class="math-step-content">
                            <p>$T_2$: State $r_0 \xrightarrow{\text{/k/}:\text{"c"} \;/\; 0.9} r_1$ and $r_0 \xrightarrow{\text{/g/}:\text{"g"} \;/\; 1.0} r_1$.</p>
                        </div>
                    </div>

                    <div class="math-step">
                        <div class="math-step-number">3</div>
                        <div class="math-step-content">
                            <p>Composed $T_1 \circ T_2$: Matching on /k/:</p>
                            <div class="math-block">
                                $$(s_0, r_0) \xrightarrow{f_1:\text{"c"} \;/\; 0.8 \times 0.9 = 0.72} (s_1, r_1)$$
                            </div>
                            <p>Matching on /g/:</p>
                            <div class="math-block">
                                $$(s_0, r_0) \xrightarrow{f_1:\text{"g"} \;/\; 0.2 \times 1.0 = 0.2} (s_2, r_1)$$
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Section 7: Applications Preview -->
                <h2 id="applications-preview">Applications Preview</h2>

                <p>
                    WFSTs are not merely theoretical constructs &mdash; they are the backbone of production speech recognition systems and are increasingly used in other domains. Here we preview the major application areas, which we explore in depth in Tutorial 23.
                </p>

                <p><strong>Speech Recognition: The WFST Cascade</strong></p>
                <p>
                    The classic WFST speech recognition pipeline composes four transducers:
                </p>
                <ol>
                    <li><strong>H (HMM model):</strong> Maps HMM state sequences to context-dependent phonemes. Weights are acoustic likelihoods.</li>
                    <li><strong>C (Context-dependency):</strong> Maps context-dependent phonemes to context-independent phonemes. Encodes triphone models.</li>
                    <li><strong>L (Lexicon):</strong> Maps phoneme sequences to words. Weights encode pronunciation probabilities.</li>
                    <li><strong>G (Grammar):</strong> A language model that scores word sequences. Weights are $n$-gram probabilities.</li>
                </ol>
                <p>
                    The composed WFST $H \circ C \circ L \circ G$ maps directly from acoustic features to word sequences, and the shortest path through this composed WFST gives the most likely transcription. This is the decoding step.
                </p>

                <p><strong>Machine Translation Preview</strong></p>
                <p>
                    WFSTs can model phrase-based translation: each phrase pair is a transition with a translation probability weight. Composing with a target language model (also a WFST) produces fluent translations ranked by probability. While neural machine translation has largely replaced WFST-based approaches, the compositional framework remains influential.
                </p>

                <p><strong>Text Normalization and TTS</strong></p>
                <p>
                    In text-to-speech (TTS), WFSTs handle text normalization: converting "$3.50" to "three dollars and fifty cents," choosing between "St." as "Saint" or "Street" based on weighted context rules, and selecting the correct pronunciation for heteronyms like "lead" or "bass."
                </p>

                <div class="note-box">
                    <div class="box-title">Preview: Tutorial 23</div>
                    <p style="margin-bottom: 0;">
                        In Tutorial 23 (FST Applications), we will build a complete speech recognition decoder, implement a spell-correction system, and construct a text normalization pipeline &mdash; all using weighted FST composition and shortest-path algorithms.
                    </p>
                </div>

                <!-- Section 8: Summary -->
                <h2 id="summary">Summary</h2>

                <p><strong>Key takeaways:</strong></p>
                <ol>
                    <li><strong>Weights add ranking:</strong> Weighted FSTs extend unweighted FSTs by assigning a semiring weight to each transition, enabling probabilistic reasoning, cost optimization, and ranking of alternatives.</li>
                    <li><strong>Semirings are the algebra:</strong> Different semirings suit different problems &mdash; tropical for shortest path, log for probabilities, boolean for the unweighted case.</li>
                    <li><strong>Path weight = $\bigotimes$, total weight = $\bigoplus$:</strong> The weight of a single path is the semiring product of edge weights; the total weight for an (input, output) pair is the semiring sum over all paths.</li>
                    <li><strong>Shortest path via Dijkstra:</strong> Finding the best output for a given input reduces to Dijkstra's algorithm on the WFST graph.</li>
                    <li><strong>Optimization pipeline:</strong> Epsilon removal, determinization, weight pushing, and minimization produce efficient WFSTs &mdash; but not all WFSTs can be determinized.</li>
                    <li><strong>Weighted composition:</strong> Chaining WFSTs multiplies weights, enabling modular pipeline construction (acoustic model $\circ$ lexicon $\circ$ language model).</li>
                </ol>

                <p>
                    In the next tutorial, we move from theory to practice: <strong>FST Libraries</strong> (Tutorial 22) introduces OpenFst, Pynini, and other tools that implement these algorithms efficiently, so you can build and optimize WFSTs without coding everything from scratch.
                </p>

                <!-- Navigation -->
                <div class="tutorial-footer-summary" style="margin: 3rem 0; padding: 2rem; background: #f8f9fa; border-radius: 8px; border-left: 4px solid #3b82f6;">
                    <h1>21. Weighted FSTs</h1>
                    <p class="lead">
                        Adding weights to Finite State Transducers for probabilistic reasoning, cost optimization, and ranking of alternative outputs through semiring algebra.
                    </p>
                </div>
                <div class="tutorial-nav">
                    <a href="../19-fst-fundamentals/index.html" class="tutorial-nav-link prev">
                        <span class="nav-label">Previous</span>
                        <span class="nav-title">&larr; FST Fundamentals</span>
                    </a>
                    <a href="../21-fst-libraries/index.html" class="tutorial-nav-link next">
                        <span class="nav-label">Next</span>
                        <span class="nav-title">FST Libraries &rarr;</span>
                    </a>
                </div>

            </article>

            <!-- ==================== CODE TAB ==================== -->
            <article class="article-content" id="code" style="display: none;">
                <h2>Python Code Examples</h2>
                <p>Four code examples: implementing a tropical semiring WFST, running shortest path, performing weight pushing, and composing two WFSTs with weights.</p>

                <!-- Code Example 1 -->
                <h3>1. Tropical Semiring WFST</h3>
                <p>
                    A Python implementation of a weighted FST over the tropical semiring, with weight accumulation along paths and minimum over alternatives.
                </p>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-lang">python</span>
                        <button class="code-block-copy">Copy</button>
                    </div>
                    <pre><code class="language-python">import math
from collections import defaultdict

class TropicalSemiring:
    """Tropical semiring: (R+ U {inf}, min, +, inf, 0)"""

    @staticmethod
    def zero():
        """Additive identity: infinity (worst possible cost)."""
        return float('inf')

    @staticmethod
    def one():
        """Multiplicative identity: 0 (no cost)."""
        return 0.0

    @staticmethod
    def plus(a, b):
        """Additive operation: min (keep the best path)."""
        return min(a, b)

    @staticmethod
    def times(a, b):
        """Multiplicative operation: + (accumulate costs along path)."""
        return a + b


class WeightedFST:
    """Weighted FST over the tropical semiring."""

    def __init__(self):
        self.transitions = defaultdict(list)  # state -> [(input, output, weight, next_state)]
        self.start_state = 'q0'
        self.final_states = {}   # state -> final_weight
        self.semiring = TropicalSemiring()

    def add_transition(self, src, inp, out, weight, dst):
        """Add transition: src --inp:out/weight--> dst"""
        self.transitions[src].append((inp, out, weight, dst))

    def set_final(self, state, weight=0.0):
        """Mark state as final with given weight."""
        self.final_states[state] = weight

    def all_paths(self, input_string):
        """Find all accepting paths and their (output, weight) pairs.

        Returns list of (output_string, total_weight) tuples.
        """
        # BFS: (state, input_pos, output, accumulated_weight)
        queue = [(self.start_state, 0, '', self.semiring.one())]
        results = []

        while queue:
            state, pos, output, weight = queue.pop(0)

            # Check if we consumed all input
            if pos == len(input_string):
                if state in self.final_states:
                    total = self.semiring.times(weight, self.final_states[state])
                    results.append((output, total))
                # Try epsilon transitions
                for inp, out, w, nxt in self.transitions.get(state, []):
                    if inp == '':
                        new_weight = self.semiring.times(weight, w)
                        queue.append((nxt, pos, output + out, new_weight))
                continue

            # Try matching current input symbol
            for inp, out, w, nxt in self.transitions.get(state, []):
                if inp == input_string[pos]:
                    new_weight = self.semiring.times(weight, w)
                    queue.append((nxt, pos + 1, output + out, new_weight))
                elif inp == '':
                    new_weight = self.semiring.times(weight, w)
                    queue.append((nxt, pos, output + out, new_weight))

        return results

    def best_output(self, input_string):
        """Find the output with the best (minimum) total weight."""
        paths = self.all_paths(input_string)
        if not paths:
            return None, self.semiring.zero()

        # Group by output, take min weight for each
        output_weights = defaultdict(lambda: self.semiring.zero())
        for output, weight in paths:
            output_weights[output] = self.semiring.plus(
                output_weights[output], weight
            )

        # Find the best output
        best_out = min(output_weights, key=output_weights.get)
        return best_out, output_weights[best_out]


# Build a WFST for a phonetic dictionary
# Maps words to pronunciations with frequency-based costs
# Lower cost = more common pronunciation
wfst = WeightedFST()

# "read" -> /riyd/ (present tense, cost 0.3) or /rEd/ (past tense, cost 0.7)
wfst.add_transition('q0', 'r', '/r', 0.0, 'read_r')
wfst.add_transition('read_r', 'e', ' iy', 0.3, 'read_iy')
wfst.add_transition('read_r', 'e', ' Eh', 0.7, 'read_eh')
wfst.add_transition('read_iy', 'a', '', 0.0, 'read_iy_a')
wfst.add_transition('read_eh', 'a', '', 0.0, 'read_eh_a')
wfst.add_transition('read_iy_a', 'd', ' d/', 0.0, 'final_read1')
wfst.add_transition('read_eh_a', 'd', ' d/', 0.0, 'final_read2')

wfst.set_final('final_read1', 0.0)
wfst.set_final('final_read2', 0.0)

# "lead" -> /liyd/ (verb, cost 0.4) or /lEd/ (noun, cost 0.6)
wfst.add_transition('q0', 'l', '/l', 0.0, 'lead_l')
wfst.add_transition('lead_l', 'e', ' iy', 0.4, 'lead_iy')
wfst.add_transition('lead_l', 'e', ' Eh', 0.6, 'lead_eh')
wfst.add_transition('lead_iy', 'a', '', 0.0, 'lead_iy_a')
wfst.add_transition('lead_eh', 'a', '', 0.0, 'lead_eh_a')
wfst.add_transition('lead_iy_a', 'd', ' d/', 0.0, 'final_lead1')
wfst.add_transition('lead_eh_a', 'd', ' d/', 0.0, 'final_lead2')

wfst.set_final('final_lead1', 0.0)
wfst.set_final('final_lead2', 0.0)

# Test
print("Tropical Semiring WFST: Phonetic Dictionary")
print("=" * 55)

for word in ['read', 'lead']:
    paths = wfst.all_paths(word)
    print(f"\nWord: '{word}'")
    print(f"  All pronunciations:")
    for output, weight in sorted(paths, key=lambda x: x[1]):
        print(f"    {output}  (cost: {weight:.1f})")

    best, cost = wfst.best_output(word)
    print(f"  Best pronunciation: {best}  (cost: {cost:.1f})")</code></pre>
                </div>

                <!-- Code Example 2 -->
                <h3>2. Shortest Path on WFST</h3>
                <p>
                    A Dijkstra-based shortest path algorithm on a WFST. We model a phonetic dictionary as a graph and find the lowest-cost pronunciation.
                </p>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-lang">python</span>
                        <button class="code-block-copy">Copy</button>
                    </div>
                    <pre><code class="language-python">import heapq
from collections import defaultdict

class WFSTGraph:
    """WFST represented as a weighted directed graph for shortest path."""

    def __init__(self):
        self.edges = defaultdict(list)  # state -> [(next_state, input, output, weight)]
        self.start = 'START'
        self.final_weights = {}  # state -> final_weight

    def add_edge(self, src, dst, inp, out, weight):
        self.edges[src].append((dst, inp, out, weight))

    def set_final(self, state, weight=0.0):
        self.final_weights[state] = weight

    def shortest_path(self):
        """Dijkstra's algorithm to find the shortest (lowest-cost) path.

        Returns (total_cost, input_string, output_string, path).
        """
        # Priority queue: (cost, state, input_so_far, output_so_far, path)
        pq = [(0.0, self.start, '', '', [self.start])]
        visited = set()

        while pq:
            cost, state, inp_str, out_str, path = heapq.heappop(pq)

            if state in visited:
                continue
            visited.add(state)

            # Check if this is a final state
            if state in self.final_weights:
                total = cost + self.final_weights[state]
                return total, inp_str, out_str, path

            # Explore neighbors
            for next_state, inp, out, weight in self.edges[state]:
                if next_state not in visited:
                    new_cost = cost + weight
                    heapq.heappush(pq, (
                        new_cost,
                        next_state,
                        inp_str + inp,
                        out_str + out,
                        path + [next_state]
                    ))

        return float('inf'), '', '', []

    def n_shortest_paths(self, n=5):
        """Find the n shortest paths using Yen's/Eppstein-style k-shortest.

        Tracks (state, count) pairs to allow a state to appear in
        multiple distinct paths while avoiding duplicate results.
        Returns list of (total_cost, input_string, output_string).
        """
        # Priority queue: (cost, state, input, output)
        pq = [(0.0, self.start, '', '')]
        results = []
        seen_paths = set()       # track (input, output, cost) to skip duplicates
        pop_count = defaultdict(int)  # how many times each state has been popped

        while pq and len(results) < n:
            cost, state, inp_str, out_str = heapq.heappop(pq)
            pop_count[state] += 1

            # If we've popped this state more than n times, skip
            if pop_count[state] > n:
                continue

            # Check if this is a final state
            if state in self.final_weights:
                total = cost + self.final_weights[state]
                path_key = (inp_str, out_str, round(total, 10))
                if path_key not in seen_paths:
                    seen_paths.add(path_key)
                    results.append((total, inp_str, out_str))

            # Explore neighbors
            for next_state, inp, out, weight in self.edges[state]:
                new_cost = cost + weight
                heapq.heappush(pq, (
                    new_cost,
                    next_state,
                    inp_str + inp,
                    out_str + out
                ))

        return results


# Build a WFST graph for spell correction
# Input: misspelled word, Output: corrected word
# Weight: edit distance (lower = fewer edits = better correction)
graph = WFSTGraph()

# The misspelled word "teh" can be corrected to:
# "the" (1 transposition, cost 1.0)
# "ten" (1 substitution, cost 1.5)
# "tea" (1 substitution, cost 1.5)
# "tech" (1 insertion, cost 2.0)
# "them" (1 transposition + 1 insertion, cost 3.0)

graph.add_edge('START', 's1', 't', 't', 0.0)

# Path to "the": t-e-h -> t-h-e (transposition)
graph.add_edge('s1', 's_the_1', 'e', 'h', 0.5)
graph.add_edge('s_the_1', 's_the_2', 'h', 'e', 0.5)
graph.set_final('s_the_2', 0.0)

# Path to "ten": t-e-h -> t-e-n (substitute h->n)
graph.add_edge('s1', 's_ten_1', 'e', 'e', 0.0)
graph.add_edge('s_ten_1', 's_ten_2', 'h', 'n', 1.5)
graph.set_final('s_ten_2', 0.0)

# Path to "tea": t-e-h -> t-e-a (substitute h->a)
graph.add_edge('s1', 's_tea_1', 'e', 'e', 0.0)
graph.add_edge('s_tea_1', 's_tea_2', 'h', 'a', 1.5)
graph.set_final('s_tea_2', 0.0)

# Path to "tech": t-e-h -> t-e-c-h (insert c before h)
graph.add_edge('s1', 's_tech_1', 'e', 'e', 0.0)
graph.add_edge('s_tech_1', 's_tech_2', '', 'c', 1.0)
graph.add_edge('s_tech_2', 's_tech_3', 'h', 'h', 1.0)
graph.set_final('s_tech_3', 0.0)

print("Shortest Path on WFST: Spell Correction")
print("=" * 50)
print(f"Input: 'teh'\n")

# Find the single best correction
cost, inp, out, path = graph.shortest_path()
print(f"Best correction: '{out}' (cost: {cost:.1f})")
print(f"  Path: {' -> '.join(path)}")

# Find top-5 corrections
print(f"\nTop corrections (n-shortest paths):")
results = graph.n_shortest_paths(n=5)
for i, (cost, inp, out) in enumerate(results, 1):
    print(f"  {i}. '{out}' (cost: {cost:.1f})")</code></pre>
                </div>

                <!-- Code Example 3 -->
                <h3>3. Weight Pushing</h3>
                <p>
                    Redistribute weights toward the start state without changing total path weights. This is a key optimization step before determinization.
                </p>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-lang">python</span>
                        <button class="code-block-copy">Copy</button>
                    </div>
                    <pre><code class="language-python">from collections import defaultdict
import heapq

class PushableWFST:
    """WFST with weight pushing capability (tropical semiring)."""

    def __init__(self):
        self.states = set()
        self.transitions = []  # [(src, inp, out, weight, dst)]
        self.start = None
        self.final_weights = {}  # state -> final_weight

    def add_state(self, state, final_weight=None):
        self.states.add(state)
        if final_weight is not None:
            self.final_weights[state] = final_weight

    def set_start(self, state):
        self.start = state
        self.states.add(state)

    def add_transition(self, src, inp, out, weight, dst):
        self.states.add(src)
        self.states.add(dst)
        self.transitions.append((src, inp, out, weight, dst))

    def shortest_distance_to_final(self):
        """Compute shortest distance from each state to any final state.

        Uses reverse Dijkstra (BFS from final states backward).
        """
        # Build reverse adjacency list
        reverse_adj = defaultdict(list)
        for src, inp, out, weight, dst in self.transitions:
            reverse_adj[dst].append((src, weight))

        dist = {s: float('inf') for s in self.states}

        # Initialize final states
        pq = []
        for state, fw in self.final_weights.items():
            dist[state] = fw
            heapq.heappush(pq, (fw, state))

        # Reverse Dijkstra
        while pq:
            d, state = heapq.heappop(pq)
            if d > dist[state]:
                continue
            for prev_state, w in reverse_adj[state]:
                new_dist = d + w
                if new_dist < dist[prev_state]:
                    dist[prev_state] = new_dist
                    heapq.heappush(pq, (new_dist, prev_state))

        return dist

    def push_weights(self):
        """Apply weight pushing: redistribute weights toward start.

        Returns a new WFST with pushed weights.
        """
        dist = self.shortest_distance_to_final()

        pushed = PushableWFST()
        pushed.set_start(self.start)

        # Push transition weights
        new_transitions = []
        for src, inp, out, weight, dst in self.transitions:
            if dist[src] == float('inf') or dist[dst] == float('inf'):
                continue  # Unreachable state, skip
            # Pushed weight: w' = w + d(dst) - d(src)
            pushed_weight = weight + dist[dst] - dist[src]
            new_transitions.append((src, inp, out, pushed_weight, dst))
            pushed.add_transition(src, inp, out, round(pushed_weight, 6), dst)

        # Push final weights: rho'(q) = rho(q) - d(q)
        for state, fw in self.final_weights.items():
            if dist[state] != float('inf'):
                pushed_fw = fw - dist[state]
                pushed.add_state(state, round(pushed_fw, 6))
            else:
                pushed.add_state(state, fw)

        return pushed, dist

    def path_weight(self, path_transitions):
        """Compute total weight of a path (list of transition indices)."""
        total = 0.0
        for idx in path_transitions:
            total += self.transitions[idx][3]
        # Add final weight if last state is final
        last_state = self.transitions[path_transitions[-1]][4]
        if last_state in self.final_weights:
            total += self.final_weights[last_state]
        return total

    def display(self, label="WFST"):
        """Pretty-print the WFST."""
        print(f"\n{label}:")
        print(f"  Start: {self.start}")
        print(f"  Transitions:")
        for src, inp, out, w, dst in self.transitions:
            print(f"    {src} --{inp}:{out}/{w:.2f}--> {dst}")
        print(f"  Final weights:")
        for state, fw in self.final_weights.items():
            print(f"    {state}: {fw:.2f}")


# Build example WFST
wfst = PushableWFST()
wfst.set_start('A')
wfst.add_transition('A', 'x', 'p', 1.0, 'B')
wfst.add_transition('A', 'x', 'q', 3.0, 'C')
wfst.add_transition('B', 'y', 'r', 5.0, 'D')
wfst.add_transition('B', 'y', 's', 2.0, 'E')
wfst.add_transition('C', 'y', 't', 1.0, 'D')
wfst.add_state('D', final_weight=0.0)
wfst.add_state('E', final_weight=0.0)

wfst.display("Original WFST")

# Compute shortest distances
dist = wfst.shortest_distance_to_final()
print("\nShortest distance to final from each state:")
for state in sorted(dist):
    print(f"  d({state}) = {dist[state]:.1f}")

# Push weights
pushed, _ = wfst.push_weights()
pushed.display("Pushed WFST")

# Verify: total path weights are preserved
print("\nVerification: path weights preserved after pushing")
print("=" * 55)

paths = [
    ("A->B->D", [0, 2]),   # x:p/1 then y:r/5, final D/0
    ("A->B->E", [0, 3]),   # x:p/1 then y:s/2, final E/0
    ("A->C->D", [1, 4]),   # x:q/3 then y:t/1, final D/0
]

for name, indices in paths:
    orig_weight = wfst.path_weight(indices)
    pushed_weight = pushed.path_weight(indices)
    print(f"  Path {name}: original={orig_weight:.1f}, pushed={pushed_weight:.1f}")</code></pre>
                </div>

                <!-- Code Example 4 -->
                <h3>4. Composition with Weights</h3>
                <p>
                    Compose two WFSTs and compute the output weights. This demonstrates the core operation used in speech recognition pipelines.
                </p>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-lang">python</span>
                        <button class="code-block-copy">Copy</button>
                    </div>
                    <pre><code class="language-python">from collections import defaultdict
from itertools import product

class ComposableWFST:
    """WFST that supports weighted composition."""

    def __init__(self, name="WFST"):
        self.name = name
        self.transitions = []  # [(src, inp, out, weight, dst)]
        self.start = None
        self.final_weights = {}

    def set_start(self, state):
        self.start = state

    def add_transition(self, src, inp, out, weight, dst):
        self.transitions.append((src, inp, out, weight, dst))

    def set_final(self, state, weight=0.0):
        self.final_weights[state] = weight

    def get_transitions_from(self, state):
        """Get all transitions from a given state."""
        return [(i, o, w, d) for s, i, o, w, d in self.transitions if s == state]

    def display(self):
        print(f"\n{self.name}:")
        print(f"  Start: {self.start}")
        for src, inp, out, w, dst in self.transitions:
            inp_str = inp if inp else 'eps'
            out_str = out if out else 'eps'
            print(f"    {src} --{inp_str}:{out_str}/{w:.2f}--> {dst}")
        for state, fw in self.final_weights.items():
            print(f"  Final: {state} (weight={fw:.2f})")

    @staticmethod
    def compose(t1, t2, name="T1 o T2"):
        """Compose two WFSTs: T1 o T2.

        For each transition (q1, a, b, w1, q1') in T1 and
        (q2, b, c, w2, q2') in T2 matching on intermediate symbol b,
        create transition ((q1,q2), a, c, w1+w2, (q1',q2')) in the result.

        # Note: This simplified composition ignores epsilon transitions.
        # For production use, see pynini.compose() which handles epsilons correctly.
        """
        result = ComposableWFST(name)
        start = (t1.start, t2.start)
        result.set_start(start)

        # BFS to discover reachable composed states
        visited = set()
        queue = [start]

        while queue:
            q1, q2 = queue.pop(0)
            if (q1, q2) in visited:
                continue
            visited.add((q1, q2))

            state_name = f"({q1},{q2})"

            # Check if this is a final state
            if q1 in t1.final_weights and q2 in t2.final_weights:
                fw = t1.final_weights[q1] + t2.final_weights[q2]
                result.set_final(state_name, fw)

            # Match transitions: T1's output must equal T2's input
            # Note: This simplified composition ignores epsilon transitions.
            # For production use, see pynini.compose() which handles epsilons correctly.
            t1_trans = t1.get_transitions_from(q1)
            t2_trans = t2.get_transitions_from(q2)

            for inp1, out1, w1, dst1 in t1_trans:
                for inp2, out2, w2, dst2 in t2_trans:
                    # Match: T1's output (out1) == T2's input (inp2)
                    if out1 == inp2 and out1 != '':
                        composed_weight = w1 + w2  # tropical: addition
                        src_name = f"({q1},{q2})"
                        dst_name = f"({dst1},{dst2})"
                        result.add_transition(
                            src_name, inp1, out2,
                            round(composed_weight, 4), dst_name
                        )
                        if (dst1, dst2) not in visited:
                            queue.append((dst1, dst2))

        return result


# Example: Speech recognition pipeline (simplified)
# T1: Acoustic model (features -> phonemes)
# T2: Lexicon (phonemes -> words)

# T1: Maps acoustic features to phonemes with costs
t1 = ComposableWFST("T1: Acoustic Model")
t1.set_start('a0')
t1.add_transition('a0', 'f1', 'K',  0.2, 'a1')   # feature f1 -> /K/ with cost 0.2
t1.add_transition('a0', 'f1', 'G',  1.5, 'a1')   # feature f1 -> /G/ with cost 1.5
t1.add_transition('a1', 'f2', 'AE', 0.3, 'a2')   # feature f2 -> /AE/ with cost 0.3
t1.add_transition('a1', 'f2', 'AH', 1.2, 'a2')   # feature f2 -> /AH/ with cost 1.2
t1.add_transition('a2', 'f3', 'T',  0.1, 'a3')   # feature f3 -> /T/ with cost 0.1
t1.add_transition('a2', 'f3', 'D',  1.8, 'a3')   # feature f3 -> /D/ with cost 1.8
t1.set_final('a3', 0.0)

# T2: Maps phonemes to words with costs
t2 = ComposableWFST("T2: Lexicon")
t2.set_start('l0')
t2.add_transition('l0', 'K',  'c',   0.0, 'l1')
t2.add_transition('l0', 'G',  'g',   0.0, 'l1')
t2.add_transition('l1', 'AE', 'a',   0.0, 'l2')
t2.add_transition('l1', 'AH', 'u',   0.0, 'l2')
t2.add_transition('l2', 'T',  't',   0.0, 'l3')
t2.add_transition('l2', 'D',  'd',   0.0, 'l3')
t2.set_final('l3', 0.0)

print("Weighted Composition: Speech Recognition Pipeline")
print("=" * 55)

t1.display()
t2.display()

# Compose T1 and T2
composed = ComposableWFST.compose(t1, t2, "T1 o T2: Features -> Words")
composed.display()

# Find all paths in the composed WFST
print("\nAll paths through composed WFST (features -> words):")
print("-" * 55)

def enumerate_paths(wfst, state, input_so_far, output_so_far, cost):
    """Recursively enumerate all paths."""
    results = []
    state_str = state if isinstance(state, str) else str(state)

    if state_str in wfst.final_weights:
        total = cost + wfst.final_weights[state_str]
        results.append((input_so_far, output_so_far, total))

    for src, inp, out, w, dst in wfst.transitions:
        if src == state_str:
            results.extend(enumerate_paths(
                wfst, dst,
                input_so_far + inp,
                output_so_far + out,
                cost + w
            ))
    return results

paths = enumerate_paths(composed, f"({t1.start},{t2.start})", '', '', 0.0)
paths.sort(key=lambda x: x[2])

for inp, out, cost in paths:
    print(f"  {inp} -> '{out}' (cost: {cost:.1f})")

print(f"\nBest path: '{paths[0][0]}' -> '{paths[0][1]}' (cost: {paths[0][2]:.1f})")
print("The composed WFST finds 'cat' as the most likely word!")</code></pre>
                </div>

            </article>

            <!-- ==================== EXERCISES TAB ==================== -->
            <article class="article-content" id="exercises" style="display: none;">
                <h2>Exercises</h2>
                <p>Test your understanding of weighted FSTs, semirings, and WFST algorithms. Exercises progress from basic weight computation through semiring verification to advanced proofs and system design.</p>

                <div class="exercise-list">

                    <!-- Easy -->
                    <h3 style="margin-top: 1rem; border-bottom: 1px solid var(--color-border); padding-bottom: 0.5rem;">Easy</h3>

                    <!-- Exercise 1 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">1. Compute Output Weight for a Path</span>
                            <span class="exercise-toggle">&darr;</span>
                        </div>
                        <div class="exercise-body">
                            <p>Consider a WFST over the tropical semiring with the following transitions:</p>
                            <ul>
                                <li>$q_0 \xrightarrow{a:x \;/\; 2} q_1$</li>
                                <li>$q_1 \xrightarrow{b:y \;/\; 3} q_2$</li>
                                <li>$q_2 \xrightarrow{c:z \;/\; 1} q_3$</li>
                                <li>$q_0 \xrightarrow{a:x \;/\; 4} q_4$</li>
                                <li>$q_4 \xrightarrow{b:y \;/\; 1} q_5$</li>
                                <li>$q_5 \xrightarrow{c:z \;/\; 1} q_3$</li>
                            </ul>
                            <p>Final state: $q_3$ with final weight 0. Initial weight of $q_0$: 0.</p>
                            <p>(a) What is the weight of the path $q_0 \to q_1 \to q_2 \to q_3$?</p>
                            <p>(b) What is the weight of the path $q_0 \to q_4 \to q_5 \to q_3$?</p>
                            <p>(c) What is the total weight $W(\text{"abc"}, \text{"xyz"})$?</p>
                            <button class="btn btn-sm solution-toggle">Show Solution</button>
                            <div class="solution-content">
                                <p><strong>(a)</strong> In the tropical semiring, $\otimes = +$, so the path weight is the sum of transition weights plus initial and final weights:</p>
                                <div class="math-block">
                                    $$w(\pi_1) = \lambda(q_0) \otimes w(t_1) \otimes w(t_2) \otimes w(t_3) \otimes \rho(q_3) = 0 + 2 + 3 + 1 + 0 = 6$$
                                </div>
                                <p><strong>(b)</strong> Similarly:</p>
                                <div class="math-block">
                                    $$w(\pi_2) = 0 + 4 + 1 + 1 + 0 = 6$$
                                </div>
                                <p><strong>(c)</strong> The total weight is $\oplus = \min$ over all paths:</p>
                                <div class="math-block">
                                    $$W(\text{"abc"}, \text{"xyz"}) = w(\pi_1) \oplus w(\pi_2) = \min(6, 6) = 6$$
                                </div>
                                <p>Both paths happen to have the same total cost of 6, so the minimum is 6.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 2 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">2. Verify Tropical Semiring Axioms</span>
                            <span class="exercise-toggle">&darr;</span>
                        </div>
                        <div class="exercise-body">
                            <p>Verify that the tropical semiring $(\mathbb{R}_{\geq 0} \cup \{+\infty\}, \min, +, +\infty, 0)$ satisfies all the semiring axioms:</p>
                            <ol type="a">
                                <li>$\oplus$ is commutative and associative with identity $\bar{0} = +\infty$</li>
                                <li>$\otimes$ is associative with identity $\bar{1} = 0$</li>
                                <li>$\otimes$ distributes over $\oplus$ (both left and right)</li>
                                <li>$\bar{0}$ is an annihilator for $\otimes$</li>
                            </ol>
                            <button class="btn btn-sm solution-toggle">Show Solution</button>
                            <div class="solution-content">
                                <p><strong>(a) Commutativity:</strong> $\min(a, b) = \min(b, a)$ for all $a, b$. Trivially true.</p>
                                <p><strong>Associativity:</strong> $\min(\min(a, b), c) = \min(a, \min(b, c))$. Both equal the minimum of $\{a, b, c\}$.</p>
                                <p><strong>Identity:</strong> $\min(a, +\infty) = a$ for all $a \geq 0$. True since $a \leq +\infty$.</p>

                                <p><strong>(b) Associativity of $+$:</strong> $(a + b) + c = a + (b + c)$. Standard arithmetic.</p>
                                <p><strong>Identity:</strong> $a + 0 = a$. Standard arithmetic.</p>

                                <p><strong>(c) Left distributivity:</strong> $a + \min(b, c) = \min(a + b, a + c)$.</p>
                                <p>Proof: If $b \leq c$, then $\min(b, c) = b$, so LHS = $a + b$. Also $a + b \leq a + c$, so RHS = $\min(a+b, a+c) = a + b$.</p>
                                <p><strong>Right distributivity:</strong> $\min(a, b) + c = \min(a + c, b + c)$. Same argument by symmetry.</p>

                                <p><strong>(d) Annihilator:</strong> $a + (+\infty) = +\infty = \bar{0}$ for all $a$. Also $(+\infty) + a = +\infty$. True by definition of $+\infty$ in extended reals.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 3 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">3. Identify the Semiring for Max-Product</span>
                            <span class="exercise-toggle">&darr;</span>
                        </div>
                        <div class="exercise-body">
                            <p>You need to build a WFST where:</p>
                            <ul>
                                <li>The weight of a path is the <strong>product</strong> of all transition weights.</li>
                                <li>When multiple paths produce the same output, you want the <strong>maximum</strong> weight path (the most probable one).</li>
                            </ul>
                            <p>Identify the semiring $(K, \oplus, \otimes, \bar{0}, \bar{1})$ that achieves this. Verify it satisfies the semiring axioms.</p>
                            <button class="btn btn-sm solution-toggle">Show Solution</button>
                            <div class="solution-content">
                                <p><strong>The max-product (Viterbi) semiring:</strong></p>
                                <div class="math-block">
                                    $$(\mathbb{R}_{\geq 0}, \max, \times, 0, 1)$$
                                </div>
                                <ul>
                                    <li>$K = \mathbb{R}_{\geq 0}$ (non-negative reals)</li>
                                    <li>$\oplus = \max$ (take the best/most probable path)</li>
                                    <li>$\otimes = \times$ (multiply probabilities along a path)</li>
                                    <li>$\bar{0} = 0$ (identity for max over non-negative reals: $\max(a, 0) = a$ for all $a \geq 0$)</li>
                                    <li>$\bar{1} = 1$ (identity for multiplication: $a \times 1 = a$)</li>
                                </ul>
                                <p><strong>Why $\bar{0} = 0$ for the max operation:</strong> In the max-product semiring, $\bar{0} = 0$ because 0 is the identity element for max: $\max(x, 0) = x$ for all $x \geq 0$. This is analogous to $+\infty$ being the identity for min in the tropical semiring (where $\min(x, +\infty) = x$). Just as $+\infty$ represents "no path found yet" in the tropical semiring, 0 represents "no path found yet" in the max-product semiring &mdash; any actual path probability will be at least as large as 0, so taking the max with 0 leaves it unchanged. Additionally, 0 serves as the annihilator for $\otimes = \times$: $a \times 0 = 0$, meaning a path through a zero-probability transition has zero total probability.</p>
                                <p><strong>Verification:</strong></p>
                                <p>Commutativity of $\max$: $\max(a, b) = \max(b, a)$. True.</p>
                                <p>Associativity: both $\max$ and $\times$ are associative. True.</p>
                                <p>Distributivity: $a \times \max(b, c) = \max(a \times b, a \times c)$ for $a \geq 0$. True because multiplication by a non-negative number preserves ordering.</p>
                                <p>Annihilator: $a \times 0 = 0 = \bar{0}$. True.</p>
                                <p>This semiring is used in the Viterbi algorithm for finding the most probable state sequence in HMMs.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Medium -->
                    <h3 style="margin-top: 2rem; border-bottom: 1px solid var(--color-border); padding-bottom: 0.5rem;">Medium</h3>

                    <!-- Exercise 4 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">4. Prove Composition Associativity for WFSTs</span>
                            <span class="exercise-toggle">&darr;</span>
                        </div>
                        <div class="exercise-body">
                            <p>Prove that weighted composition is associative: for WFSTs $T_1$, $T_2$, $T_3$ over the same semiring, $(T_1 \circ T_2) \circ T_3 = T_1 \circ (T_2 \circ T_3)$. Your proof must account for weights, not just the input/output relation.</p>
                            <button class="btn btn-sm solution-toggle">Show Solution</button>
                            <div class="solution-content">
                                <p><strong>Proof:</strong> Let $T_1: \Sigma^* \to_K \Gamma^*$, $T_2: \Gamma^* \to_K \Delta^*$, $T_3: \Delta^* \to_K \Omega^*$ be WFSTs over semiring $(K, \oplus, \otimes, \bar{0}, \bar{1})$.</p>
                                <p>For any input $x \in \Sigma^*$ and output $z \in \Omega^*$, we need to show that both compositions assign the same weight.</p>
                                <p><strong>Left association $(T_1 \circ T_2) \circ T_3$:</strong></p>
                                <div class="math-block">
                                    $$W_{(T_1 \circ T_2) \circ T_3}(x, z) = \bigoplus_{y \in \Delta^*} W_{T_1 \circ T_2}(x, y) \otimes W_{T_3}(y, z)$$
                                </div>
                                <p>Expanding $W_{T_1 \circ T_2}(x, y)$:</p>
                                <div class="math-block">
                                    $$= \bigoplus_{y \in \Delta^*} \left(\bigoplus_{w \in \Gamma^*} W_{T_1}(x, w) \otimes W_{T_2}(w, y)\right) \otimes W_{T_3}(y, z)$$
                                </div>
                                <p>By distributivity of $\otimes$ over $\oplus$:</p>
                                <div class="math-block">
                                    $$= \bigoplus_{y \in \Delta^*} \bigoplus_{w \in \Gamma^*} W_{T_1}(x, w) \otimes W_{T_2}(w, y) \otimes W_{T_3}(y, z)$$
                                </div>
                                <p><strong>Right association $T_1 \circ (T_2 \circ T_3)$:</strong></p>
                                <div class="math-block">
                                    $$W_{T_1 \circ (T_2 \circ T_3)}(x, z) = \bigoplus_{w \in \Gamma^*} W_{T_1}(x, w) \otimes W_{T_2 \circ T_3}(w, z)$$
                                </div>
                                <p>Expanding and applying distributivity:</p>
                                <div class="math-block">
                                    $$= \bigoplus_{w \in \Gamma^*} \bigoplus_{y \in \Delta^*} W_{T_1}(x, w) \otimes W_{T_2}(w, y) \otimes W_{T_3}(y, z)$$
                                </div>
                                <p>Both expressions compute the same double sum (by commutativity of $\oplus$ and associativity of $\otimes$), so they are equal. Therefore $(T_1 \circ T_2) \circ T_3 = T_1 \circ (T_2 \circ T_3)$. $\square$</p>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 5 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">5. Implement Epsilon Removal</span>
                            <span class="exercise-toggle">&darr;</span>
                        </div>
                        <div class="exercise-body">
                            <p>Given a WFST over the tropical semiring with the following transitions:</p>
                            <ul>
                                <li>$q_0 \xrightarrow{a:x \;/\; 2} q_1$</li>
                                <li>$q_1 \xrightarrow{\varepsilon:\varepsilon \;/\; 1} q_2$</li>
                                <li>$q_2 \xrightarrow{b:y \;/\; 3} q_3$</li>
                                <li>$q_1 \xrightarrow{b:y \;/\; 5} q_3$</li>
                            </ul>
                            <p>Final state: $q_3$ (weight 0).</p>
                            <p>(a) Compute the epsilon-closure of each state with accumulated weights.</p>
                            <p>(b) Write out the epsilon-free WFST with equivalent behavior.</p>
                            <p>(c) Verify by computing the weight of "ab" $\to$ "xy" in both the original and epsilon-free versions.</p>
                            <button class="btn btn-sm solution-toggle">Show Solution</button>
                            <div class="solution-content">
                                <p><strong>(a) Epsilon-closure:</strong></p>
                                <ul>
                                    <li>$\text{E-close}(q_0) = \{(q_0, 0)\}$ &mdash; no epsilon transitions from $q_0$.</li>
                                    <li>$\text{E-close}(q_1) = \{(q_1, 0), (q_2, 1)\}$ &mdash; epsilon transition to $q_2$ with weight 1.</li>
                                    <li>$\text{E-close}(q_2) = \{(q_2, 0)\}$ &mdash; no epsilon transitions from $q_2$.</li>
                                    <li>$\text{E-close}(q_3) = \{(q_3, 0)\}$ &mdash; no epsilon transitions from $q_3$.</li>
                                </ul>

                                <p><strong>(b) Epsilon-free WFST:</strong></p>
                                <p>Keep all non-epsilon transitions. For each non-epsilon transition from a state in the epsilon-closure, add a new transition with the accumulated weight:</p>
                                <ul>
                                    <li>$q_0 \xrightarrow{a:x \;/\; 2} q_1$ (original, kept)</li>
                                    <li>$q_1 \xrightarrow{b:y \;/\; 5} q_3$ (original, kept)</li>
                                    <li>$q_2 \xrightarrow{b:y \;/\; 3} q_3$ (original, kept)</li>
                                    <li>$q_1 \xrightarrow{b:y \;/\; 4} q_3$ (NEW: from $q_1$, via epsilon to $q_2$ with weight 1, then $b:y$ to $q_3$ with weight 3; total = $1 + 3 = 4$)</li>
                                </ul>
                                <p>Now $q_1$ has two transitions on $b:y$: one with weight 5 (direct) and one with weight 4 (via eliminated epsilon). This is a non-deterministic WFST.</p>

                                <p><strong>(c) Verification on "ab" $\to$ "xy":</strong></p>
                                <p><em>Original:</em></p>
                                <ul>
                                    <li>Path 1: $q_0 \xrightarrow{a:x/2} q_1 \xrightarrow{\varepsilon:\varepsilon/1} q_2 \xrightarrow{b:y/3} q_3$. Weight: $2 + 1 + 3 = 6$.</li>
                                    <li>Path 2: $q_0 \xrightarrow{a:x/2} q_1 \xrightarrow{b:y/5} q_3$. Weight: $2 + 5 = 7$.</li>
                                    <li>Total: $\min(6, 7) = 6$.</li>
                                </ul>
                                <p><em>Epsilon-free:</em></p>
                                <ul>
                                    <li>Path 1: $q_0 \xrightarrow{a:x/2} q_1 \xrightarrow{b:y/4} q_3$. Weight: $2 + 4 = 6$.</li>
                                    <li>Path 2: $q_0 \xrightarrow{a:x/2} q_1 \xrightarrow{b:y/5} q_3$. Weight: $2 + 5 = 7$.</li>
                                    <li>Total: $\min(6, 7) = 6$. Matches!</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 6 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">6. Design a Spell-Correction WFST with Edit Distances</span>
                            <span class="exercise-toggle">&darr;</span>
                        </div>
                        <div class="exercise-body">
                            <p>Design a WFST over the tropical semiring that corrects the misspelled word "recieve" to the correct spelling "receive." The WFST should model the following edit operations with costs:</p>
                            <ul>
                                <li>Correct character (match): cost 0</li>
                                <li>Transposition of adjacent characters: cost 1</li>
                                <li>Substitution: cost 1.5</li>
                                <li>Insertion: cost 2</li>
                                <li>Deletion: cost 2</li>
                            </ul>
                            <p>List the states, transitions, and compute the total weight of the correction path.</p>
                            <button class="btn btn-sm solution-toggle">Show Solution</button>
                            <div class="solution-content">
                                <p>The misspelling "recieve" differs from "receive" in positions 4-5: "ie" should be "ei" (a transposition).</p>
                                <p><strong>States:</strong> $q_0$ through $q_7$ (one for each character position).</p>
                                <p><strong>Transitions:</strong></p>
                                <ul>
                                    <li>$q_0 \xrightarrow{\text{r}:\text{r} \;/\; 0} q_1$ (match)</li>
                                    <li>$q_1 \xrightarrow{\text{e}:\text{e} \;/\; 0} q_2$ (match)</li>
                                    <li>$q_2 \xrightarrow{\text{c}:\text{c} \;/\; 0} q_3$ (match)</li>
                                    <li>$q_3 \xrightarrow{\text{i}:\text{e} \;/\; 0.5} q_4$ (transposition part 1: 'i' maps to 'e')</li>
                                    <li>$q_4 \xrightarrow{\text{e}:\text{i} \;/\; 0.5} q_5$ (transposition part 2: 'e' maps to 'i')</li>
                                    <li>$q_5 \xrightarrow{\text{v}:\text{v} \;/\; 0} q_6$ (match)</li>
                                    <li>$q_6 \xrightarrow{\text{e}:\text{e} \;/\; 0} q_7$ (match)</li>
                                </ul>
                                <p>Final state: $q_7$ with weight 0.</p>
                                <p><strong>Total weight:</strong> $0 + 0 + 0 + 0.5 + 0.5 + 0 + 0 + 0 = 1.0$ (one transposition).</p>
                                <p>The WFST assigns cost 1.0 to this correction, which is less than the cost of two substitutions (3.0), confirming that transposition is the preferred edit operation.</p>
                                <p><strong>Note:</strong> In practice, a spell-correction WFST would have transitions for all possible edits at each position, creating a much larger graph. The shortest path algorithm then finds the minimum-cost correction automatically.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 7 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">7. Analyze Determinization Complexity</span>
                            <span class="exercise-toggle">&darr;</span>
                        </div>
                        <div class="exercise-body">
                            <p>Consider a WFST over the tropical semiring with $n$ states where each state has two transitions on the same input symbol but with different output symbols and weights:</p>
                            <ul>
                                <li>$q_i \xrightarrow{a:x \;/\; w_1} q_{i+1}$ and $q_i \xrightarrow{a:y \;/\; w_2} q_{i+1}$ for $i = 0, \ldots, n-2$</li>
                            </ul>
                            <p>(a) How many states could the determinized WFST have in the worst case?</p>
                            <p>(b) Explain why this WFST is non-deterministic and what makes determinization expensive.</p>
                            <p>(c) Does this WFST satisfy the twins property? Can it be determinized?</p>
                            <button class="btn btn-sm solution-toggle">Show Solution</button>
                            <div class="solution-content">
                                <p><strong>(a)</strong> In the worst case, the determinized WFST can have exponentially many states: up to $O(2^n)$. This is because determinization of weighted transducers constructs "subset states" where each subset state tracks the possible (state, residual-output, residual-weight) triples that the original non-deterministic WFST could be in.</p>

                                <p><strong>(b)</strong> The WFST is non-deterministic because each state $q_i$ has two transitions on the same input $a$ but with different outputs ($x$ vs $y$). The determinizer must track which output string "remainder" is pending for each possible branch. After $k$ steps of input $a^k$, the transducer could be on any of $2^k$ different output trajectories (each choosing $x$ or $y$ at each step), leading to exponential blowup.</p>

                                <p><strong>(c)</strong> The twins property requires: for any two paths from the start state reading the same input and arriving at the same state, the residual outputs must be compatible (one must be a prefix of the other). In this WFST, from $q_0$, reading input "a" leads to $q_1$ with output "x" (weight $w_1$) or output "y" (weight $w_2$). Since "x" and "y" are different and neither is a prefix of the other, the twins property is violated. <strong>This WFST cannot be determinized.</strong></p>

                                <p>The key insight: determinization of transducers is harder than determinization of acceptors because of the output tape. A weighted acceptor (no output) can always be determinized, but a weighted transducer may not be.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Hard -->
                    <h3 style="margin-top: 2rem; border-bottom: 1px solid var(--color-border); padding-bottom: 0.5rem;">Hard</h3>

                    <!-- Exercise 8 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">8. Prove Weight Pushing Preserves Output Weights</span>
                            <span class="exercise-toggle">&darr;</span>
                        </div>
                        <div class="exercise-body">
                            <p>Prove that weight pushing preserves the total weight of every path. Specifically, for a WFST $T$ over a semiring with inverses and its pushed version $T'$, show that for every path $\pi = t_1 t_2 \cdots t_n$ from $q_0$ to $q_f$:</p>
                            <div class="math-block">
                                $$w_T(\pi) = w_{T'}(\pi)$$
                            </div>
                            <p>where $w_T(\pi)$ and $w_{T'}(\pi)$ denote the path weight in the original and pushed WFSTs respectively.</p>
                            <button class="btn btn-sm solution-toggle">Show Solution</button>
                            <div class="solution-content">
                                <p><strong>Proof:</strong> Let $d(q)$ be the shortest distance from state $q$ to any final state. Weight pushing transforms each transition weight $w(t_i)$ for transition $q_{i-1} \to q_i$ into:</p>
                                <div class="math-block">
                                    $$w'(t_i) = d(q_{i-1})^{-1} \otimes w(t_i) \otimes d(q_i)$$
                                </div>
                                <p>The pushed initial weight is $\lambda'(q_0) = \lambda(q_0) \otimes d(q_0)$, and the pushed final weight is $\rho'(q_f) = d(q_f)^{-1} \otimes \rho(q_f)$.</p>
                                <p>The path weight in $T'$:</p>
                                <div class="math-block">
                                    $$w_{T'}(\pi) = \lambda'(q_0) \otimes w'(t_1) \otimes w'(t_2) \otimes \cdots \otimes w'(t_n) \otimes \rho'(q_f)$$
                                </div>
                                <p>Substituting:</p>
                                <div class="math-block">
                                    $$= \lambda(q_0) \otimes d(q_0) \otimes \left[d(q_0)^{-1} \otimes w(t_1) \otimes d(q_1)\right] \otimes \left[d(q_1)^{-1} \otimes w(t_2) \otimes d(q_2)\right] \otimes \cdots$$
                                </div>
                                <div class="math-block">
                                    $$\cdots \otimes \left[d(q_{n-1})^{-1} \otimes w(t_n) \otimes d(q_n)\right] \otimes d(q_f)^{-1} \otimes \rho(q_f)$$
                                </div>
                                <p>By associativity, the $d(q_i)$ and $d(q_i)^{-1}$ terms form a <strong>telescoping product</strong>:</p>
                                <div class="math-block">
                                    $$d(q_0) \otimes d(q_0)^{-1} = \bar{1}, \quad d(q_1) \otimes d(q_1)^{-1} = \bar{1}, \quad \ldots, \quad d(q_n) \otimes d(q_f)^{-1} = \bar{1}$$
                                </div>
                                <p>(noting that $q_n = q_f$). After cancellation:</p>
                                <div class="math-block">
                                    $$w_{T'}(\pi) = \lambda(q_0) \otimes w(t_1) \otimes w(t_2) \otimes \cdots \otimes w(t_n) \otimes \rho(q_f) = w_T(\pi)$$
                                </div>
                                <p>Therefore weight pushing preserves the weight of every individual path, and consequently preserves the total weight $W(x, y) = \bigoplus_\pi w(\pi)$ for all (input, output) pairs. $\square$</p>
                                <p><strong>Note:</strong> This proof requires the semiring to have a multiplicative inverse. In the tropical semiring, the inverse of $a$ under $+$ is $-a$, which exists in $\mathbb{R}$. For semirings without inverses, weight pushing can still be defined but requires a weaker condition.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 9 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">9. Design a Log-Semiring WFST for a Language Model</span>
                            <span class="exercise-toggle">&darr;</span>
                        </div>
                        <div class="exercise-body">
                            <p>Design a bigram language model as a WFST over the log semiring. The vocabulary is $\{$the, cat, sat, on, mat$\}$ with the following bigram probabilities:</p>
                            <ul>
                                <li>$P(\text{cat} \mid \text{the}) = 0.4$, $P(\text{mat} \mid \text{the}) = 0.3$, $P(\text{on} \mid \text{the}) = 0.3$</li>
                                <li>$P(\text{sat} \mid \text{cat}) = 0.7$, $P(\text{on} \mid \text{cat}) = 0.3$</li>
                                <li>$P(\text{on} \mid \text{sat}) = 0.9$, $P(\text{the} \mid \text{sat}) = 0.1$</li>
                                <li>$P(\text{the} \mid \text{on}) = 0.8$, $P(\text{mat} \mid \text{on}) = 0.2$</li>
                                <li>$P(\langle\text{end}\rangle \mid \text{mat}) = 1.0$</li>
                            </ul>
                            <p>(a) Draw the WFST with states, transitions, and log-semiring weights ($w = -\log p$).</p>
                            <p>(b) Compute the weight of the sentence "the cat sat on the mat."</p>
                            <p>(c) Explain how the shortest path through this WFST gives the most likely sentence.</p>
                            <button class="btn btn-sm solution-toggle">Show Solution</button>
                            <div class="solution-content">
                                <p><strong>(a) WFST States and Transitions:</strong></p>
                                <p>States represent the most recently seen word: $\{q_\text{start}, q_\text{the}, q_\text{cat}, q_\text{sat}, q_\text{on}, q_\text{mat}\}$.</p>
                                <p>Transitions carry the word as both input and output (this is an acceptor/language model), with weights $w = -\log p$:</p>
                                <ul>
                                    <li>$q_\text{start} \xrightarrow{\text{the}:\text{the} \;/\; 0.0} q_\text{the}$ (assume "the" starts the sentence with probability 1)</li>
                                    <li>$q_\text{the} \xrightarrow{\text{cat}:\text{cat} \;/\; 0.916} q_\text{cat}$ ($-\log 0.4 \approx 0.916$)</li>
                                    <li>$q_\text{the} \xrightarrow{\text{mat}:\text{mat} \;/\; 1.204} q_\text{mat}$ ($-\log 0.3 \approx 1.204$)</li>
                                    <li>$q_\text{the} \xrightarrow{\text{on}:\text{on} \;/\; 1.204} q_\text{on}$ ($-\log 0.3 \approx 1.204$)</li>
                                    <li>$q_\text{cat} \xrightarrow{\text{sat}:\text{sat} \;/\; 0.357} q_\text{sat}$ ($-\log 0.7 \approx 0.357$)</li>
                                    <li>$q_\text{cat} \xrightarrow{\text{on}:\text{on} \;/\; 1.204} q_\text{on}$</li>
                                    <li>$q_\text{sat} \xrightarrow{\text{on}:\text{on} \;/\; 0.105} q_\text{on}$ ($-\log 0.9 \approx 0.105$)</li>
                                    <li>$q_\text{sat} \xrightarrow{\text{the}:\text{the} \;/\; 2.303} q_\text{the}$ ($-\log 0.1 \approx 2.303$)</li>
                                    <li>$q_\text{on} \xrightarrow{\text{the}:\text{the} \;/\; 0.223} q_\text{the}$ ($-\log 0.8 \approx 0.223$)</li>
                                    <li>$q_\text{on} \xrightarrow{\text{mat}:\text{mat} \;/\; 1.609} q_\text{mat}$ ($-\log 0.2 \approx 1.609$)</li>
                                    <li>$q_\text{mat}$ is a final state with weight $-\log 1.0 = 0.0$.</li>
                                </ul>

                                <p><strong>(b) Weight of "the cat sat on the mat":</strong></p>
                                <p>Path: $q_\text{start} \to q_\text{the} \to q_\text{cat} \to q_\text{sat} \to q_\text{on} \to q_\text{the} \to q_\text{mat}$.</p>
                                <div class="math-block">
                                    $$w = 0.0 + 0.916 + 0.357 + 0.105 + 0.223 + 1.204 + 0.0 = 2.805$$
                                </div>
                                <p>This corresponds to probability $e^{-2.805} \approx 0.0605 = 0.4 \times 0.7 \times 0.9 \times 0.8 \times 0.3 \times 1.0$.</p>

                                <p><strong>(c) Shortest path = most likely sentence:</strong> In the log semiring, path weights are $-\log p$ values summed along the path ($\otimes = +$). Since $-\log$ is a decreasing function, the path with the <em>smallest</em> total weight corresponds to the <em>highest</em> probability. The shortest path algorithm (which minimizes total weight) therefore finds the most probable sentence &mdash; this is exactly why the log semiring is used for probabilistic models.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Exercise 10 -->
                    <div class="exercise-item">
                        <div class="exercise-header">
                            <span class="exercise-title">10. Optimize Composition Order for a 3-Way Cascade</span>
                            <span class="exercise-toggle">&darr;</span>
                        </div>
                        <div class="exercise-body">
                            <p>In a speech recognition pipeline, you need to compose three WFSTs:</p>
                            <ul>
                                <li>$L$ (Lexicon): 50,000 states, maps phoneme sequences to words</li>
                                <li>$G$ (Grammar): 1,000,000 states, a bigram language model</li>
                                <li>$C$ (Context-dependency): 5,000 states, maps context-dependent to context-independent phonemes</li>
                            </ul>
                            <p>(a) Composition is associative, so $(C \circ L) \circ G = C \circ (L \circ G)$. Analyze the intermediate WFST sizes for both orderings and determine which is more efficient.</p>
                            <p>(b) If you can apply determinization and minimization between compositions, how does this change your analysis?</p>
                            <p>(c) In general, what heuristic should you use to choose composition order?</p>
                            <button class="btn btn-sm solution-toggle">Show Solution</button>
                            <div class="solution-content">
                                <p><strong>(a) Size analysis:</strong></p>
                                <p><em>Order 1: $(C \circ L) \circ G$</em></p>
                                <ul>
                                    <li>$C \circ L$: up to $5{,}000 \times 50{,}000 = 250{,}000{,}000$ states (but typically much smaller due to sparsity).</li>
                                    <li>$(C \circ L) \circ G$: up to $|C \circ L| \times 1{,}000{,}000$ states. The intermediate $C \circ L$ is likely manageable (maybe 100,000 states after optimization), giving a final size of $\sim 10^{11}$ in the worst case but $\sim 10^8$ in practice.</li>
                                </ul>
                                <p><em>Order 2: $C \circ (L \circ G)$</em></p>
                                <ul>
                                    <li>$L \circ G$: up to $50{,}000 \times 1{,}000{,}000 = 5 \times 10^{10}$ states. This intermediate result is enormous because the grammar $G$ is large.</li>
                                    <li>$C \circ (L \circ G)$: up to $5{,}000 \times |L \circ G|$, which is even larger.</li>
                                </ul>
                                <p><strong>Order 1 is more efficient</strong> because it composes the two smaller WFSTs first, keeping the intermediate result manageable.</p>

                                <p><strong>(b) With optimization between compositions:</strong></p>
                                <p>After computing $C \circ L$, we can apply determinization, weight pushing, and minimization to shrink it significantly (perhaps from 100,000 to 10,000 states). Then composing with $G$ produces a much smaller result. This "optimize early" strategy is standard in speech recognition &mdash; the pipeline is: compose $C \circ L$, optimize, then compose with $G$, optimize again.</p>
                                <p>For Order 2, even with optimization, the $L \circ G$ intermediate is so large that it may not fit in memory before optimization can be applied.</p>

                                <p><strong>(c) General heuristic:</strong></p>
                                <ol>
                                    <li><strong>Compose smaller WFSTs first:</strong> The product of two small WFSTs is smaller than the product of a small and a large one.</li>
                                    <li><strong>Optimize between compositions:</strong> Determinize and minimize intermediate results to prevent blowup from propagating.</li>
                                    <li><strong>Consider sparsity:</strong> If two WFSTs share a small intermediate alphabet (few matching symbols), their composition is sparse regardless of state counts. Compose WFSTs with small shared alphabets first.</li>
                                    <li><strong>Profile empirically:</strong> Worst-case bounds are often loose. Measure actual sizes on your data.</li>
                                </ol>
                                <p>In speech recognition, the standard order is $H \circ C \circ L \circ G$ (left to right), composing and optimizing incrementally.</p>
                            </div>
                        </div>
                    </div>

                </div>
            </article>

        </main>

        <!-- TOC (Right Side) -->
        <aside class="toc-container">
            <h4 class="toc-title">Contents</h4>
            <nav class="toc-list">
                <a href="#motivation" class="toc-link">Why Weighted FSTs?</a>
                <a href="#semirings" class="toc-link">Semirings</a>
                <a href="#wfst-definition" class="toc-link">Weighted FST Definition</a>
                <a href="#shortest-path" class="toc-link">Shortest Path Algorithm</a>
                <a href="#determinization" class="toc-link">Determinization & Minimization</a>
                <a href="#composition-revisited" class="toc-link">Weighted Composition</a>
                <a href="#applications-preview" class="toc-link">Applications Preview</a>
                <a href="#summary" class="toc-link">Summary</a>
            </nav>
        </aside>
    </div>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-brand">
                    <span class="logo-symbol">&nabla;</span>
                    <span>ML Fundamentals</span>
                </div>
                <p class="footer-tagline">Deep understanding through first principles.</p>
            </div>
            <div class="footer-links">
                <a href="../../../index.html">Home</a>
                <a href="https://github.com/ml-entropy/ml-entropy.github.io" target="_blank">GitHub</a>
            </div>
        </div>
    </footer>

    <!-- Scripts -->
    <script src="../../../js/main.js"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            // KaTeX Rendering
            if (typeof renderMathInElement === 'function') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }

            // Tab Switching Logic
            const tabs = document.querySelectorAll('.tutorial-tab');
            const articles = document.querySelectorAll('.article-content');

            function switchTab(targetId) {
                if (!targetId || targetId === '#') targetId = '#theory';

                tabs.forEach(tab => {
                    if (tab.getAttribute('href') === targetId) {
                        tab.classList.add('active');
                    } else {
                        tab.classList.remove('active');
                    }
                });

                articles.forEach(article => {
                    const articleId = '#' + article.id;
                    if (articleId === targetId) {
                        article.style.display = 'block';
                    } else {
                        article.style.display = 'none';
                    }
                });

                if (typeof renderMathInElement === 'function') {
                    renderMathInElement(document.body, {
                        delimiters: [
                            {left: '$$', right: '$$', display: true},
                            {left: '$', right: '$', display: false},
                            {left: '\\[', right: '\\]', display: true},
                            {left: '\\(', right: '\\)', display: false}
                        ],
                        throwOnError: false
                    });
                }

                const toc = document.querySelector('.toc-container');
                if (toc) {
                    if (targetId === '#theory') {
                        toc.style.display = 'block';
                        setTimeout(() => toc.classList.add('visible'), 100);
                    } else {
                        toc.classList.remove('visible');
                        setTimeout(() => toc.style.display = 'none', 300);
                    }
                }
            }

            tabs.forEach(tab => {
                tab.addEventListener('click', (e) => {
                    e.preventDefault();
                    const targetId = tab.getAttribute('href');
                    history.pushState(null, null, targetId);
                    switchTab(targetId);
                });
            });

            window.addEventListener('popstate', () => {
                switchTab(window.location.hash);
            });

            switchTab(window.location.hash);
        });
    </script>
</body>
</html>
