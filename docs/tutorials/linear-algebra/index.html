<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Linear Algebra Tutorials | ML Fundamentals</title>
    <meta name="description" content="Linear algebra fundamentals for machine learning: vectors, matrices, eigenvalues, SVD, and more.">
    
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Playfair+Display:wght@400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}, {left: '\\\\[', right: '\\\\]', display: true}, {left: '\\\\(', right: '\\\\)', display: false}], throwOnError: false});"></script>
    
    <!-- Styles -->
    <link rel="stylesheet" href="../../css/main.css">
    <link rel="stylesheet" href="../../css/components.css">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>‚àû</text></svg>">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar" id="navbar">
        <div class="nav-container">
            <a href="../../index.html" class="nav-logo">
                <span class="logo-symbol">‚àá</span>
                <span class="logo-text">ML Fundamentals</span>
            </a>
            
            <button class="nav-toggle" id="navToggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            
            <div class="nav-menu" id="navMenu">
                <div class="nav-links">
                    <a href="../../tutorials/ml/index.html" class="nav-link">Machine Learning</a>
                    <a href="../../tutorials/linear-algebra/index.html" class="nav-link active">Linear Algebra</a>
                    <a href="../../tutorials/calculus/index.html" class="nav-link">Calculus</a>
                    <a href="../../tutorials/physics/index.html" class="nav-link">Physics</a>
                    <a href="../../index.html#philosophy" class="nav-link">Philosophy</a>
                    <a href="../../index.html#roadmap" class="nav-link">Roadmap</a>
                    <a href="https://github.com/ml-entropy/ml-entropy.github.io" class="nav-link" target="_blank">GitHub</a>
                </div>
                
                <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
                    <svg class="sun-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <circle cx="12" cy="12" r="5"/>
                        <path d="M12 1v2M12 21v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M1 12h2M21 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42"/>
                    </svg>
                    <svg class="moon-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                    </svg>
                </button>
            </div>
        </div>
    </nav>

    <!-- Header -->
    <header class="tutorial-header">
        <div class="container">
            <nav class="breadcrumb">
                <a href="../../index.html">Home</a>
                <span class="breadcrumb-separator">‚Üí</span>
                <span>Linear Algebra</span>
            </nav>
            
            <h1>Linear Algebra Tutorials</h1>
            <p class="lead">
                The mathematical backbone of machine learning. From vectors to spectral decomposition, 
                with geometric intuition and ML applications throughout.
            </p>
            
            <div class="featured-equation" style="margin-top: 2rem;">
                $$A = U \Sigma V^T$$
            </div>
        </div>
    </header>

    <!-- Tutorial List -->
    <main class="tutorial-list">
        <div class="container">
            <!-- Foundations -->
            <h2 style="margin-bottom: 1.5rem; font-size: 1.25rem; color: var(--color-text-secondary);">
                Part I: Foundations
            </h2>
            
            <a href="01-vectors/index.html" class="tutorial-item">
                <div class="tutorial-number">01</div>
                <div class="tutorial-content">
                    <h3>Vectors and Vector Spaces</h3>
                    <p>Vectors as arrows and lists, dot products, norms, angles, basis, span, and linear independence.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Code + Exercises</span>
                        <span>‚è± ~60 min</span>
                    </div>
                </div>
            </a>
            
            <a href="02-matrices/index.html" class="tutorial-item">
                <div class="tutorial-number">02</div>
                <div class="tutorial-content">
                    <h3>Matrices and Linear Transformations</h3>
                    <p>Matrices as functions, rotations, scaling, shearing. Column and row space interpretations.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Visualizations + Code</span>
                        <span>‚è± ~75 min</span>
                    </div>
                </div>
            </a>
            
            <a href="03-systems/index.html" class="tutorial-item">
                <div class="tutorial-number">03</div>
                <div class="tutorial-content">
                    <h3>Systems of Linear Equations</h3>
                    <p>Gaussian elimination, row echelon form, rank, nullspace, and solution existence.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Algorithms + Code</span>
                        <span>‚è± ~60 min</span>
                    </div>
                </div>
            </a>
            
            <a href="04-determinants/index.html" class="tutorial-item">
                <div class="tutorial-number">04</div>
                <div class="tutorial-content">
                    <h3>Determinants</h3>
                    <p>Geometric meaning as volume scaling, properties, computation, and Cramer's rule.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Derivations + Code</span>
                        <span>‚è± ~50 min</span>
                    </div>
                </div>
            </a>
            
            <!-- Advanced Topics -->
            <h2 style="margin: 3rem 0 1.5rem; font-size: 1.25rem; color: var(--color-text-secondary);">
                Part II: Advanced Topics
            </h2>
            
            <a href="05-eigenvalues/index.html" class="tutorial-item">
                <div class="tutorial-number">05</div>
                <div class="tutorial-content">
                    <h3>Eigenvalues and Eigenvectors</h3>
                    <p>The directions that don't rotate. Diagonalization, spectral decomposition, PCA connection.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Code + Exercises</span>
                        <span>‚è± ~90 min</span>
                    </div>
                </div>
            </a>
            
            <a href="06-svd/index.html" class="tutorial-item">
                <div class="tutorial-number">06</div>
                <div class="tutorial-content">
                    <h3>Singular Value Decomposition</h3>
                    <p>The most important factorization. Low-rank approximation, image compression, pseudoinverse.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Applications + Code</span>
                        <span>‚è± ~90 min</span>
                    </div>
                </div>
            </a>
            
            <a href="07-orthogonality/index.html" class="tutorial-item">
                <div class="tutorial-number">07</div>
                <div class="tutorial-content">
                    <h3>Orthogonality and Projections</h3>
                    <p>Orthogonal matrices, Gram-Schmidt, QR decomposition, least squares via projection.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Code + Exercises</span>
                        <span>‚è± ~75 min</span>
                    </div>
                </div>
            </a>
            
            <a href="08-positive-definite/index.html" class="tutorial-item">
                <div class="tutorial-number">08</div>
                <div class="tutorial-content">
                    <h3>Positive Definite Matrices</h3>
                    <p>Tests for positive definiteness, Cholesky decomposition, optimization, covariance matrices.</p>
                    <div class="tutorial-meta">
                        <span>üìñ Theory + Applications + Code</span>
                        <span>‚è± ~60 min</span>
                    </div>
                </div>
            </a>
            
            <!-- ML Applications -->
            <h2 style="margin: 3rem 0 1.5rem; font-size: 1.25rem; color: var(--color-text-secondary);">
                ML Applications
            </h2>
            
            <div class="note-box" style="margin-bottom: 2rem;">
                <div class="box-title">Applied Throughout</div>
                <p style="margin-bottom: 0;">Each tutorial includes ML applications: PCA uses eigendecomposition, neural network weights are matrices, 
                covariance matrices must be positive semi-definite, and SVD powers recommendation systems.</p>
            </div>
        </div>
    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-brand">
                    <span class="logo-symbol">‚àá</span>
                    <span>ML Fundamentals</span>
                </div>
                <p class="footer-tagline">Deep understanding through first principles.</p>
            </div>
            <div class="footer-links">
                <a href="../../index.html">Home</a>
                <a href="https://github.com/ml-entropy/ml-entropy.github.io" target="_blank">GitHub</a>
            </div>
        </div>
    </footer>

    <!-- Scripts -->
    <script src="../../js/main.js"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            if (typeof renderMathInElement === 'function') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
    </script>
</body>
</html>
