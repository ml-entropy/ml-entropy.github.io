{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 09: Regularization — Preventing Overfitting\n",
    "\n",
    "This notebook demonstrates regularization techniques: L1, L2, Dropout, and their effects on training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Create a Dataset That's Easy to Overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate small, noisy dataset\n",
    "X, y = make_moons(n_samples=200, noise=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert to PyTorch\n",
    "X_train_t = torch.FloatTensor(X_train)\n",
    "y_train_t = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "X_test_t = torch.FloatTensor(X_test)\n",
    "y_test_t = torch.FloatTensor(y_test).unsqueeze(1)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], c='blue', label='Class 0')\n",
    "plt.scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], c='red', label='Class 1')\n",
    "plt.title(f'Training Data ({len(X_train)} samples)')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test[y_test==0, 0], X_test[y_test==0, 1], c='blue', label='Class 0')\n",
    "plt.scatter(X_test[y_test==1, 0], X_test[y_test==1, 1], c='red', label='Class 1')\n",
    "plt.title(f'Test Data ({len(X_test)} samples)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Models with Different Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Overparameterized MLP for demonstrating overfitting\"\"\"\n",
    "    def __init__(self, hidden_size=128, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, \n",
    "                epochs=500, lr=0.01, weight_decay=0.0, l1_lambda=0.0):\n",
    "    \"\"\"Train model and return history\"\"\"\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    train_accs, test_accs = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        \n",
    "        # Add L1 regularization manually\n",
    "        if l1_lambda > 0:\n",
    "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "            loss = loss + l1_lambda * l1_norm\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_pred = model(X_train)\n",
    "            test_pred = model(X_test)\n",
    "            \n",
    "            train_losses.append(criterion(train_pred, y_train).item())\n",
    "            test_losses.append(criterion(test_pred, y_test).item())\n",
    "            \n",
    "            train_accs.append(((train_pred > 0.5) == y_train).float().mean().item())\n",
    "            test_accs.append(((test_pred > 0.5) == y_test).float().mean().item())\n",
    "    \n",
    "    return train_losses, test_losses, train_accs, test_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Compare No Regularization vs L2 (Weight Decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No regularization\n",
    "model_none = MLP()\n",
    "train_loss_none, test_loss_none, train_acc_none, test_acc_none = train_model(\n",
    "    model_none, X_train_t, y_train_t, X_test_t, y_test_t)\n",
    "\n",
    "# L2 regularization (weight_decay in Adam)\n",
    "model_l2 = MLP()\n",
    "train_loss_l2, test_loss_l2, train_acc_l2, test_acc_l2 = train_model(\n",
    "    model_l2, X_train_t, y_train_t, X_test_t, y_test_t, weight_decay=0.01)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(train_loss_none, 'b-', label='Train (No reg)', alpha=0.7)\n",
    "axes[0].plot(test_loss_none, 'b--', label='Test (No reg)', alpha=0.7)\n",
    "axes[0].plot(train_loss_l2, 'r-', label='Train (L2)', alpha=0.7)\n",
    "axes[0].plot(test_loss_l2, 'r--', label='Test (L2)', alpha=0.7)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss: No Regularization vs L2')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(train_acc_none, 'b-', label='Train (No reg)', alpha=0.7)\n",
    "axes[1].plot(test_acc_none, 'b--', label='Test (No reg)', alpha=0.7)\n",
    "axes[1].plot(train_acc_l2, 'r-', label='Train (L2)', alpha=0.7)\n",
    "axes[1].plot(test_acc_l2, 'r--', label='Test (L2)', alpha=0.7)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy: No Regularization vs L2')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Test Accuracy - No Reg: {test_acc_none[-1]:.2%}, L2: {test_acc_l2[-1]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visualize Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, title):\n",
    "    \"\"\"Plot decision boundary of a model\"\"\"\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        grid = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = model(grid).numpy().reshape(xx.shape)\n",
    "    \n",
    "    plt.contourf(xx, yy, Z, levels=50, cmap='RdBu', alpha=0.7)\n",
    "    plt.colorbar(label='P(class=1)')\n",
    "    plt.scatter(X[y==0, 0], X[y==0, 1], c='blue', edgecolor='white', s=50)\n",
    "    plt.scatter(X[y==1, 0], X[y==1, 1], c='red', edgecolor='white', s=50)\n",
    "    plt.title(title)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plot_decision_boundary(model_none, X_test, y_test, 'No Regularization (Overfitting)')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_decision_boundary(model_l2, X_test, y_test, 'L2 Regularization (Smoother)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice: Without regularization, boundary is more complex (overfitting to noise)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: L1 Regularization (Sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 regularization\n",
    "model_l1 = MLP()\n",
    "train_loss_l1, test_loss_l1, train_acc_l1, test_acc_l1 = train_model(\n",
    "    model_l1, X_train_t, y_train_t, X_test_t, y_test_t, l1_lambda=0.001)\n",
    "\n",
    "# Compare weight distributions\n",
    "def get_weights(model):\n",
    "    return torch.cat([p.flatten() for p in model.parameters()]).detach().numpy()\n",
    "\n",
    "weights_none = get_weights(model_none)\n",
    "weights_l1 = get_weights(model_l1)\n",
    "weights_l2 = get_weights(model_l2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "axes[0].hist(weights_none, bins=50, alpha=0.7, color='blue')\n",
    "axes[0].set_title(f'No Regularization\\n{np.sum(np.abs(weights_none) < 0.01)} near-zero weights')\n",
    "axes[0].set_xlabel('Weight value')\n",
    "\n",
    "axes[1].hist(weights_l2, bins=50, alpha=0.7, color='green')\n",
    "axes[1].set_title(f'L2 Regularization\\n{np.sum(np.abs(weights_l2) < 0.01)} near-zero weights')\n",
    "axes[1].set_xlabel('Weight value')\n",
    "\n",
    "axes[2].hist(weights_l1, bins=50, alpha=0.7, color='red')\n",
    "axes[2].set_title(f'L1 Regularization\\n{np.sum(np.abs(weights_l1) < 0.01)} near-zero weights')\n",
    "axes[2].set_xlabel('Weight value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"L1 creates SPARSE weights (many exactly zero) - useful for feature selection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout\n",
    "model_dropout = MLP(dropout_rate=0.5)\n",
    "train_loss_drop, test_loss_drop, train_acc_drop, test_acc_drop = train_model(\n",
    "    model_dropout, X_train_t, y_train_t, X_test_t, y_test_t)\n",
    "\n",
    "# Compare all methods\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "methods = ['No Reg', 'L2', 'L1', 'Dropout']\n",
    "train_accs = [train_acc_none[-1], train_acc_l2[-1], train_acc_l1[-1], train_acc_drop[-1]]\n",
    "test_accs = [test_acc_none[-1], test_acc_l2[-1], test_acc_l1[-1], test_acc_drop[-1]]\n",
    "gaps = [t - te for t, te in zip(train_accs, test_accs)]\n",
    "\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, train_accs, width, label='Train Accuracy', color='blue', alpha=0.7)\n",
    "ax.bar(x + width/2, test_accs, width, label='Test Accuracy', color='green', alpha=0.7)\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Regularization Method')\n",
    "ax.set_title('Train vs Test Accuracy by Regularization Method')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(methods)\n",
    "ax.legend()\n",
    "ax.set_ylim(0.5, 1.0)\n",
    "\n",
    "# Annotate gaps\n",
    "for i, gap in enumerate(gaps):\n",
    "    ax.annotate(f'Gap: {gap:.1%}', (i, max(train_accs[i], test_accs[i]) + 0.02), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Smaller train-test gap = less overfitting = better generalization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: The Bayesian Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize L1 vs L2 priors\n",
    "x = np.linspace(-3, 3, 1000)\n",
    "\n",
    "# Gaussian prior (L2)\n",
    "gaussian = np.exp(-x**2 / 2) / np.sqrt(2 * np.pi)\n",
    "\n",
    "# Laplace prior (L1)\n",
    "laplace = np.exp(-np.abs(x)) / 2\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x, gaussian, 'b-', linewidth=2, label='Gaussian (L2 prior)')\n",
    "plt.plot(x, laplace, 'r-', linewidth=2, label='Laplace (L1 prior)')\n",
    "plt.axvline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('Weight value θ')\n",
    "plt.ylabel('Prior probability P(θ)')\n",
    "plt.title('Bayesian Interpretation: L2 = Gaussian Prior, L1 = Laplace Prior')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Laplace (L1) has a SPIKE at zero → encourages exact sparsity\")\n",
    "print(\"Gaussian (L2) is smooth at zero → shrinks but doesn't zero out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Key takeaways:**\n",
    "1. **No regularization** → model memorizes training data (overfits)\n",
    "2. **L2 (weight decay)** → shrinks all weights, smoother decision boundary\n",
    "3. **L1** → creates sparse weights (some exactly zero)\n",
    "4. **Dropout** → trains ensemble of sub-networks\n",
    "\n",
    "All methods reduce the train-test gap by limiting model capacity!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
